{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle\n",
    "import wandb\n",
    "\n",
    "from transformers import BertConfig, BertTokenizerFast\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "from models import BertForDiffusion, DiffusionLM, ConditionalDiffusionLM\n",
    "from data_utils import load_qqp_dataset_and_tokenizer_from_disk, QQPParaphraseDataset, load_split_qqp_dataset_and_tokenizer_from_disk\n",
    "from noise_schedule import get_named_beta_schedule\n",
    "from train_utils import train_conditional, evaluate_conditional\n",
    "from metric_utils import calculate_bleu, calculate_rouge\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataset args\n",
    "max_len = 32\n",
    "\n",
    "# training args\n",
    "batch_size = 64\n",
    "device = torch.device(\"cuda:2\")\n",
    "lr = 1e-4\n",
    "num_epoch = 30\n",
    "weight_decay = 0\n",
    "num_warmup_steps = 100\n",
    "\n",
    "# model args\n",
    "word_embedding_dim = 512\n",
    "# hidden_size = 768\n",
    "# num_hidden_layers = 12\n",
    "# num_attention_heads = 12\n",
    "# intermediate_size = 3072\n",
    "hidden_size = 512\n",
    "num_hidden_layers = 4\n",
    "num_attention_heads = 8\n",
    "intermediate_size = 2048\n",
    "max_position_embeddings = max_len\n",
    "\n",
    "encoder_type = 'from-scratch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocab size: 15672\n",
      "Training set size: 120940\n",
      "Evaluation set size: 13438\n"
     ]
    }
   ],
   "source": [
    "train_dataset, eval_dataset, tokenizer = load_split_qqp_dataset_and_tokenizer_from_disk(data_path=\"data\")\n",
    "\n",
    "# tokenized_qqp_train, tokenized_qqp_eval, tokenizer = load_qqp_dataset_and_tokenizer_from_disk(data_path=\"data\")\n",
    "\n",
    "rev_tokenizer = {v: k for k, v in tokenizer.items()}\n",
    "\n",
    "print(\"Tokenizer vocab size:\", len(tokenizer))\n",
    "\n",
    "# train_dataset = QQPParaphraseDataset(dataset=tokenized_qqp_train, random_swap=True)\n",
    "print(\"Training set size:\", len(train_dataset))\n",
    "# eval_dataset = QQPParaphraseDataset(dataset=tokenized_qqp_eval, random_swap=False)\n",
    "print(\"Evaluation set size:\", len(eval_dataset))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"T\": 2000,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 32,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 15672\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = BertConfig(vocab_size=len(tokenizer), hidden_size=hidden_size, num_hidden_layers=num_hidden_layers, num_attention_heads=num_attention_heads, intermediate_size=intermediate_size, max_position_embeddings=max_position_embeddings, pad_token_id=tokenizer['[PAD]'])\n",
    "\n",
    "config.T = 2000\n",
    "# comment next line if using bit word embedding\n",
    "config.word_embedding_dim = word_embedding_dim\n",
    "\n",
    "print(config)\n",
    "\n",
    "betas = torch.Tensor(get_named_beta_schedule(schedule_name=\"cosine\", num_diffusion_timesteps=config.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using learned word embedding\n",
      "set word_embedding_dim to: 512\n",
      "Diffusion model #parameters:\n",
      "55452472\n",
      "Diffusion model #trainable parameters\n",
      "55452472\n"
     ]
    }
   ],
   "source": [
    "diffusion_model = ConditionalDiffusionLM(\n",
    "    config=config, \n",
    "    betas=betas, \n",
    "    use_shared_weight=False, \n",
    "    lm_head_bias=True, \n",
    "    add_emb_noise=False, \n",
    "    conditional_gen=True, \n",
    "    encoder_type=encoder_type, \n",
    "    encoder_name_or_path='bert-base-uncased', \n",
    "    emb_type='learned',\n",
    ").to(device)\n",
    "\n",
    "print(\"Diffusion model #parameters:\")\n",
    "print(sum([p.numel() for p in diffusion_model.parameters()]))\n",
    "\n",
    "print(\"Diffusion model #trainable parameters\")\n",
    "print(sum([p.numel() for p in filter(lambda p:p.requires_grad, diffusion_model.parameters())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(filter(lambda p:p.requires_grad, diffusion_model.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer=optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_epoch*len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ebe2dafd824a4a8ef8067f1a7e504c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "step: 100\n",
      "mse  training loss=0.70365\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=8.94612\n",
      "step: 200\n",
      "mse  training loss=0.35716\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=4.37584\n",
      "step: 300\n",
      "mse  training loss=0.30703\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=1.74582\n",
      "step: 400\n",
      "mse  training loss=0.28241\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=1.02338\n",
      "step: 500\n",
      "mse  training loss=0.26434\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.76507\n",
      "step: 600\n",
      "mse  training loss=0.24443\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.60915\n",
      "step: 700\n",
      "mse  training loss=0.23552\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.51759\n",
      "step: 800\n",
      "mse  training loss=0.22217\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.44281\n",
      "step: 900\n",
      "mse  training loss=0.21193\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.38758\n",
      "step: 1000\n",
      "mse  training loss=0.20430\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.33558\n",
      "step: 1100\n",
      "mse  training loss=0.20263\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.30539\n",
      "step: 1200\n",
      "mse  training loss=0.19417\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.27267\n",
      "step: 1300\n",
      "mse  training loss=0.18997\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.25082\n",
      "step: 1400\n",
      "mse  training loss=0.18614\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.22678\n",
      "step: 1500\n",
      "mse  training loss=0.18417\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.21214\n",
      "step: 1600\n",
      "mse  training loss=0.17676\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.19168\n",
      "step: 1700\n",
      "mse  training loss=0.17412\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.17515\n",
      "step: 1800\n",
      "mse  training loss=0.17248\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.16356\n",
      "Evaluating...\n",
      "eval loss=0.30585\n",
      "epoch: 2\n",
      "step: 100\n",
      "mse  training loss=0.16300\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.13644\n",
      "step: 200\n",
      "mse  training loss=0.16025\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.12865\n",
      "step: 300\n",
      "mse  training loss=0.15761\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.11802\n",
      "step: 400\n",
      "mse  training loss=0.15746\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.11172\n",
      "step: 500\n",
      "mse  training loss=0.15224\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.10502\n",
      "step: 600\n",
      "mse  training loss=0.15419\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.09875\n",
      "step: 700\n",
      "mse  training loss=0.14657\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.09546\n",
      "step: 800\n",
      "mse  training loss=0.14628\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.09081\n",
      "step: 900\n",
      "mse  training loss=0.14344\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.08359\n",
      "step: 1000\n",
      "mse  training loss=0.14481\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.07796\n",
      "step: 1100\n",
      "mse  training loss=0.14418\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.07550\n",
      "step: 1200\n",
      "mse  training loss=0.14084\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.07162\n",
      "step: 1300\n",
      "mse  training loss=0.13827\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.06847\n",
      "step: 1400\n",
      "mse  training loss=0.13338\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.06412\n",
      "step: 1500\n",
      "mse  training loss=0.13156\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.06096\n",
      "step: 1600\n",
      "mse  training loss=0.13451\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.05673\n",
      "step: 1700\n",
      "mse  training loss=0.12864\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.05625\n",
      "step: 1800\n",
      "mse  training loss=0.13086\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.05309\n",
      "Evaluating...\n",
      "eval loss=0.17694\n",
      "epoch: 3\n",
      "step: 100\n",
      "mse  training loss=0.12764\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.04139\n",
      "step: 200\n",
      "mse  training loss=0.12611\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.04097\n",
      "step: 300\n",
      "mse  training loss=0.12304\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.03906\n",
      "step: 400\n",
      "mse  training loss=0.12394\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.03791\n",
      "step: 500\n",
      "mse  training loss=0.12098\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.03562\n",
      "step: 600\n",
      "mse  training loss=0.12103\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.03694\n",
      "step: 700\n",
      "mse  training loss=0.12001\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.03484\n",
      "step: 800\n",
      "mse  training loss=0.11811\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.03288\n",
      "step: 900\n",
      "mse  training loss=0.11522\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.03176\n",
      "step: 1000\n",
      "mse  training loss=0.11565\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.03035\n",
      "step: 1100\n",
      "mse  training loss=0.11446\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.02929\n",
      "step: 1200\n",
      "mse  training loss=0.11665\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.02889\n",
      "step: 1300\n",
      "mse  training loss=0.11666\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.02651\n",
      "step: 1400\n",
      "mse  training loss=0.11075\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.02565\n",
      "step: 1500\n",
      "mse  training loss=0.11035\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.02349\n",
      "step: 1600\n",
      "mse  training loss=0.11142\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.02365\n",
      "step: 1700\n",
      "mse  training loss=0.10890\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.02247\n",
      "step: 1800\n",
      "mse  training loss=0.10865\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.02262\n",
      "Evaluating...\n",
      "eval loss=0.12776\n",
      "epoch: 4\n",
      "step: 100\n",
      "mse  training loss=0.10691\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.01685\n",
      "step: 200\n",
      "mse  training loss=0.10687\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.01602\n",
      "step: 300\n",
      "mse  training loss=0.10567\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.01625\n",
      "step: 400\n",
      "mse  training loss=0.10444\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.01465\n",
      "step: 500\n",
      "mse  training loss=0.10456\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.01462\n",
      "step: 600\n",
      "mse  training loss=0.09966\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.01404\n",
      "step: 700\n",
      "mse  training loss=0.10008\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.01401\n",
      "step: 800\n",
      "mse  training loss=0.10082\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.01354\n",
      "step: 900\n",
      "mse  training loss=0.10119\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.01377\n",
      "step: 1000\n",
      "mse  training loss=0.09914\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.01234\n",
      "step: 1100\n",
      "mse  training loss=0.10034\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.01232\n",
      "step: 1200\n",
      "mse  training loss=0.09894\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.01244\n",
      "step: 1300\n",
      "mse  training loss=0.09771\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.01123\n",
      "step: 1400\n",
      "mse  training loss=0.09765\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.01130\n",
      "step: 1500\n",
      "mse  training loss=0.09858\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.01028\n",
      "step: 1600\n",
      "mse  training loss=0.09774\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.01141\n",
      "step: 1700\n",
      "mse  training loss=0.09455\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.01069\n",
      "step: 1800\n",
      "mse  training loss=0.09630\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00977\n",
      "Evaluating...\n",
      "eval loss=0.10397\n",
      "epoch: 5\n",
      "step: 100\n",
      "mse  training loss=0.09480\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00713\n",
      "step: 200\n",
      "mse  training loss=0.09301\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00675\n",
      "step: 300\n",
      "mse  training loss=0.09158\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00727\n",
      "step: 400\n",
      "mse  training loss=0.09035\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00656\n",
      "step: 500\n",
      "mse  training loss=0.09179\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00647\n",
      "step: 600\n",
      "mse  training loss=0.09002\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00686\n",
      "step: 700\n",
      "mse  training loss=0.08856\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00593\n",
      "step: 800\n",
      "mse  training loss=0.08960\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00596\n",
      "step: 900\n",
      "mse  training loss=0.09043\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00634\n",
      "step: 1000\n",
      "mse  training loss=0.08975\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00594\n",
      "step: 1100\n",
      "mse  training loss=0.08858\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00540\n",
      "step: 1200\n",
      "mse  training loss=0.08959\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00549\n",
      "step: 1300\n",
      "mse  training loss=0.08538\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00489\n",
      "step: 1400\n",
      "mse  training loss=0.08700\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00572\n",
      "step: 1500\n",
      "mse  training loss=0.08365\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00470\n",
      "step: 1600\n",
      "mse  training loss=0.08597\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00489\n",
      "step: 1700\n",
      "mse  training loss=0.08513\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00485\n",
      "step: 1800\n",
      "mse  training loss=0.08451\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00467\n",
      "Evaluating...\n",
      "eval loss=0.08789\n",
      "epoch: 6\n",
      "step: 100\n",
      "mse  training loss=0.08333\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00345\n",
      "step: 200\n",
      "mse  training loss=0.08367\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00276\n",
      "step: 300\n",
      "mse  training loss=0.08157\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00297\n",
      "step: 400\n",
      "mse  training loss=0.08205\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00326\n",
      "step: 500\n",
      "mse  training loss=0.08265\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00298\n",
      "step: 600\n",
      "mse  training loss=0.08287\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00307\n",
      "step: 700\n",
      "mse  training loss=0.08066\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00307\n",
      "step: 800\n",
      "mse  training loss=0.08137\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00287\n",
      "step: 900\n",
      "mse  training loss=0.07972\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00294\n",
      "step: 1000\n",
      "mse  training loss=0.07949\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00288\n",
      "step: 1100\n",
      "mse  training loss=0.07963\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00263\n",
      "step: 1200\n",
      "mse  training loss=0.08002\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00258\n",
      "step: 1300\n",
      "mse  training loss=0.08133\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00282\n",
      "step: 1400\n",
      "mse  training loss=0.07892\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00277\n",
      "step: 1500\n",
      "mse  training loss=0.07845\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00237\n",
      "step: 1600\n",
      "mse  training loss=0.07866\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00251\n",
      "step: 1700\n",
      "mse  training loss=0.07614\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00241\n",
      "step: 1800\n",
      "mse  training loss=0.07708\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00252\n",
      "Evaluating...\n",
      "eval loss=0.07896\n",
      "epoch: 7\n",
      "step: 100\n",
      "mse  training loss=0.07635\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00194\n",
      "step: 200\n",
      "mse  training loss=0.07522\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00177\n",
      "step: 300\n",
      "mse  training loss=0.07570\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00150\n",
      "step: 400\n",
      "mse  training loss=0.07516\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00169\n",
      "step: 500\n",
      "mse  training loss=0.07530\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00163\n",
      "step: 600\n",
      "mse  training loss=0.07506\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00163\n",
      "step: 700\n",
      "mse  training loss=0.07379\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00161\n",
      "step: 800\n",
      "mse  training loss=0.07495\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00137\n",
      "step: 900\n",
      "mse  training loss=0.07464\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00134\n",
      "step: 1000\n",
      "mse  training loss=0.07209\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00143\n",
      "step: 1100\n",
      "mse  training loss=0.07282\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00144\n",
      "step: 1200\n",
      "mse  training loss=0.07267\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00143\n",
      "step: 1300\n",
      "mse  training loss=0.07224\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00166\n",
      "step: 1400\n",
      "mse  training loss=0.07101\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00162\n",
      "step: 1500\n",
      "mse  training loss=0.07142\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00159\n",
      "step: 1600\n",
      "mse  training loss=0.07127\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00118\n",
      "step: 1700\n",
      "mse  training loss=0.07062\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00125\n",
      "step: 1800\n",
      "mse  training loss=0.07061\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00098\n",
      "Evaluating...\n",
      "eval loss=0.06993\n",
      "epoch: 8\n",
      "step: 100\n",
      "mse  training loss=0.07100\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00093\n",
      "step: 200\n",
      "mse  training loss=0.06744\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00096\n",
      "step: 300\n",
      "mse  training loss=0.06858\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00102\n",
      "step: 400\n",
      "mse  training loss=0.06848\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00100\n",
      "step: 500\n",
      "mse  training loss=0.06878\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00069\n",
      "step: 600\n",
      "mse  training loss=0.07011\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00100\n",
      "step: 700\n",
      "mse  training loss=0.06718\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00090\n",
      "step: 800\n",
      "mse  training loss=0.06894\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00105\n",
      "step: 900\n",
      "mse  training loss=0.06644\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00093\n",
      "step: 1000\n",
      "mse  training loss=0.06902\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00080\n",
      "step: 1100\n",
      "mse  training loss=0.06806\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00069\n",
      "step: 1200\n",
      "mse  training loss=0.06708\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00099\n",
      "step: 1300\n",
      "mse  training loss=0.06621\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00078\n",
      "step: 1400\n",
      "mse  training loss=0.06545\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00104\n",
      "step: 1500\n",
      "mse  training loss=0.06613\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00094\n",
      "step: 1600\n",
      "mse  training loss=0.06486\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00068\n",
      "step: 1700\n",
      "mse  training loss=0.06390\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00063\n",
      "step: 1800\n",
      "mse  training loss=0.06457\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00088\n",
      "Evaluating...\n",
      "eval loss=0.06576\n",
      "epoch: 9\n",
      "step: 100\n",
      "mse  training loss=0.06387\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00059\n",
      "step: 200\n",
      "mse  training loss=0.06572\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00047\n",
      "step: 300\n",
      "mse  training loss=0.06405\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00049\n",
      "step: 400\n",
      "mse  training loss=0.06350\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00052\n",
      "step: 500\n",
      "mse  training loss=0.06423\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00063\n",
      "step: 600\n",
      "mse  training loss=0.06276\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00052\n",
      "step: 700\n",
      "mse  training loss=0.06351\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00048\n",
      "step: 800\n",
      "mse  training loss=0.06235\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00059\n",
      "step: 900\n",
      "mse  training loss=0.06230\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00050\n",
      "step: 1000\n",
      "mse  training loss=0.06265\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00066\n",
      "step: 1100\n",
      "mse  training loss=0.06197\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00049\n",
      "step: 1200\n",
      "mse  training loss=0.06274\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00050\n",
      "step: 1300\n",
      "mse  training loss=0.06131\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00057\n",
      "step: 1400\n",
      "mse  training loss=0.06056\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00049\n",
      "step: 1500\n",
      "mse  training loss=0.06204\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00060\n",
      "step: 1600\n",
      "mse  training loss=0.06214\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00056\n",
      "step: 1700\n",
      "mse  training loss=0.06140\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00060\n",
      "step: 1800\n",
      "mse  training loss=0.06120\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00044\n",
      "Evaluating...\n",
      "eval loss=0.06155\n",
      "epoch: 10\n",
      "step: 100\n",
      "mse  training loss=0.06213\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00024\n",
      "step: 200\n",
      "mse  training loss=0.05968\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00039\n",
      "step: 300\n",
      "mse  training loss=0.05968\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00029\n",
      "step: 400\n",
      "mse  training loss=0.06131\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00032\n",
      "step: 500\n",
      "mse  training loss=0.05966\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00031\n",
      "step: 600\n",
      "mse  training loss=0.05999\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00036\n",
      "step: 700\n",
      "mse  training loss=0.05941\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00026\n",
      "step: 800\n",
      "mse  training loss=0.05866\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00029\n",
      "step: 900\n",
      "mse  training loss=0.05967\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00028\n",
      "step: 1000\n",
      "mse  training loss=0.05976\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00032\n",
      "step: 1100\n",
      "mse  training loss=0.05795\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00032\n",
      "step: 1200\n",
      "mse  training loss=0.05873\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00036\n",
      "step: 1300\n",
      "mse  training loss=0.05795\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00033\n",
      "step: 1400\n",
      "mse  training loss=0.05836\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00029\n",
      "step: 1500\n",
      "mse  training loss=0.05806\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00032\n",
      "step: 1600\n",
      "mse  training loss=0.05861\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00029\n",
      "step: 1700\n",
      "mse  training loss=0.05843\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00030\n",
      "step: 1800\n",
      "mse  training loss=0.05813\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00029\n",
      "Evaluating...\n",
      "eval loss=0.05646\n",
      "epoch: 11\n",
      "step: 100\n",
      "mse  training loss=0.05756\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00019\n",
      "step: 200\n",
      "mse  training loss=0.05699\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00016\n",
      "step: 300\n",
      "mse  training loss=0.05747\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00013\n",
      "step: 400\n",
      "mse  training loss=0.05715\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00021\n",
      "step: 500\n",
      "mse  training loss=0.05621\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00017\n",
      "step: 600\n",
      "mse  training loss=0.05798\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00017\n",
      "step: 700\n",
      "mse  training loss=0.05631\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00014\n",
      "step: 800\n",
      "mse  training loss=0.05590\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00014\n",
      "step: 900\n",
      "mse  training loss=0.05456\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00015\n",
      "step: 1000\n",
      "mse  training loss=0.05619\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00023\n",
      "step: 1100\n",
      "mse  training loss=0.05676\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00017\n",
      "step: 1200\n",
      "mse  training loss=0.05554\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00023\n",
      "step: 1300\n",
      "mse  training loss=0.05518\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00018\n",
      "step: 1400\n",
      "mse  training loss=0.05594\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00014\n",
      "step: 1500\n",
      "mse  training loss=0.05457\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00015\n",
      "step: 1600\n",
      "mse  training loss=0.05567\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00016\n",
      "step: 1700\n",
      "mse  training loss=0.05550\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00016\n",
      "step: 1800\n",
      "mse  training loss=0.05391\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00019\n",
      "Evaluating...\n",
      "eval loss=0.05308\n",
      "epoch: 12\n",
      "step: 100\n",
      "mse  training loss=0.05394\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00011\n",
      "step: 200\n",
      "mse  training loss=0.05364\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00007\n",
      "step: 300\n",
      "mse  training loss=0.05426\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00008\n",
      "step: 400\n",
      "mse  training loss=0.05324\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00009\n",
      "step: 500\n",
      "mse  training loss=0.05330\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00009\n",
      "step: 600\n",
      "mse  training loss=0.05375\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00009\n",
      "step: 700\n",
      "mse  training loss=0.05342\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00011\n",
      "step: 800\n",
      "mse  training loss=0.05225\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00012\n",
      "step: 900\n",
      "mse  training loss=0.05252\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00008\n",
      "step: 1000\n",
      "mse  training loss=0.05415\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00008\n",
      "step: 1100\n",
      "mse  training loss=0.05315\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00007\n",
      "step: 1200\n",
      "mse  training loss=0.05326\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00009\n",
      "step: 1300\n",
      "mse  training loss=0.05250\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00010\n",
      "step: 1400\n",
      "mse  training loss=0.05292\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00009\n",
      "step: 1500\n",
      "mse  training loss=0.05250\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00009\n",
      "step: 1600\n",
      "mse  training loss=0.05277\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00009\n",
      "step: 1700\n",
      "mse  training loss=0.05178\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00011\n",
      "step: 1800\n",
      "mse  training loss=0.05233\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00010\n",
      "Evaluating...\n",
      "eval loss=0.05084\n",
      "epoch: 13\n",
      "step: 100\n",
      "mse  training loss=0.05149\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00005\n",
      "step: 200\n",
      "mse  training loss=0.05083\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00005\n",
      "step: 300\n",
      "mse  training loss=0.05114\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00006\n",
      "step: 400\n",
      "mse  training loss=0.05268\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00005\n",
      "step: 500\n",
      "mse  training loss=0.05103\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00006\n",
      "step: 600\n",
      "mse  training loss=0.05080\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00005\n",
      "step: 700\n",
      "mse  training loss=0.04973\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00004\n",
      "step: 800\n",
      "mse  training loss=0.05126\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00004\n",
      "step: 900\n",
      "mse  training loss=0.05171\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00004\n",
      "step: 1000\n",
      "mse  training loss=0.05026\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00007\n",
      "step: 1100\n",
      "mse  training loss=0.05004\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00005\n",
      "step: 1200\n",
      "mse  training loss=0.05079\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00004\n",
      "step: 1300\n",
      "mse  training loss=0.04983\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00005\n",
      "step: 1400\n",
      "mse  training loss=0.04957\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00005\n",
      "step: 1500\n",
      "mse  training loss=0.04893\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00005\n",
      "step: 1600\n",
      "mse  training loss=0.05042\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00006\n",
      "step: 1700\n",
      "mse  training loss=0.05102\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00005\n",
      "step: 1800\n",
      "mse  training loss=0.04968\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00005\n",
      "Evaluating...\n",
      "eval loss=0.04898\n",
      "epoch: 14\n",
      "step: 100\n",
      "mse  training loss=0.04972\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00003\n",
      "step: 200\n",
      "mse  training loss=0.04966\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00003\n",
      "step: 300\n",
      "mse  training loss=0.04935\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00003\n",
      "step: 400\n",
      "mse  training loss=0.04973\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00003\n",
      "step: 500\n",
      "mse  training loss=0.04907\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00003\n",
      "step: 600\n",
      "mse  training loss=0.04883\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00004\n",
      "step: 700\n",
      "mse  training loss=0.04937\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00003\n",
      "step: 800\n",
      "mse  training loss=0.04651\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00002\n",
      "step: 900\n",
      "mse  training loss=0.04873\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00003\n",
      "step: 1000\n",
      "mse  training loss=0.04783\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00002\n",
      "step: 1100\n",
      "mse  training loss=0.04955\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00003\n",
      "step: 1200\n",
      "mse  training loss=0.04843\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00003\n",
      "step: 1300\n",
      "mse  training loss=0.04729\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00003\n",
      "step: 1400\n",
      "mse  training loss=0.04918\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00003\n",
      "step: 1500\n",
      "mse  training loss=0.04859\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00003\n",
      "step: 1600\n",
      "mse  training loss=0.04709\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00003\n",
      "step: 1700\n",
      "mse  training loss=0.04759\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00003\n",
      "step: 1800\n",
      "mse  training loss=0.04728\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00003\n",
      "Evaluating...\n",
      "eval loss=0.04797\n",
      "epoch: 15\n",
      "step: 100\n",
      "mse  training loss=0.04806\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00002\n",
      "step: 200\n",
      "mse  training loss=0.04713\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00002\n",
      "step: 300\n",
      "mse  training loss=0.04647\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00002\n",
      "step: 400\n",
      "mse  training loss=0.04720\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00002\n",
      "step: 500\n",
      "mse  training loss=0.04688\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00002\n",
      "step: 600\n",
      "mse  training loss=0.04573\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00002\n",
      "step: 700\n",
      "mse  training loss=0.04674\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00002\n",
      "step: 800\n",
      "mse  training loss=0.04723\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00002\n",
      "step: 900\n",
      "mse  training loss=0.04643\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00002\n",
      "step: 1000\n",
      "mse  training loss=0.04677\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1100\n",
      "mse  training loss=0.04642\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00002\n",
      "step: 1200\n",
      "mse  training loss=0.04710\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00002\n",
      "step: 1300\n",
      "mse  training loss=0.04734\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00002\n",
      "step: 1400\n",
      "mse  training loss=0.04584\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00002\n",
      "step: 1500\n",
      "mse  training loss=0.04714\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00002\n",
      "step: 1600\n",
      "mse  training loss=0.04587\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00002\n",
      "step: 1700\n",
      "mse  training loss=0.04566\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1800\n",
      "mse  training loss=0.04678\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00002\n",
      "Evaluating...\n",
      "eval loss=0.04523\n",
      "epoch: 16\n",
      "step: 100\n",
      "mse  training loss=0.04563\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 200\n",
      "mse  training loss=0.04471\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 300\n",
      "mse  training loss=0.04635\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 400\n",
      "mse  training loss=0.04501\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 500\n",
      "mse  training loss=0.04459\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 600\n",
      "mse  training loss=0.04567\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 700\n",
      "mse  training loss=0.04578\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 800\n",
      "mse  training loss=0.04564\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 900\n",
      "mse  training loss=0.04510\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1000\n",
      "mse  training loss=0.04562\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1100\n",
      "mse  training loss=0.04469\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1200\n",
      "mse  training loss=0.04576\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1300\n",
      "mse  training loss=0.04387\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1400\n",
      "mse  training loss=0.04549\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00002\n",
      "step: 1500\n",
      "mse  training loss=0.04540\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00002\n",
      "step: 1600\n",
      "mse  training loss=0.04466\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1700\n",
      "mse  training loss=0.04461\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1800\n",
      "mse  training loss=0.04447\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "Evaluating...\n",
      "eval loss=0.04432\n",
      "epoch: 17\n",
      "step: 100\n",
      "mse  training loss=0.04426\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 200\n",
      "mse  training loss=0.04405\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 300\n",
      "mse  training loss=0.04402\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 400\n",
      "mse  training loss=0.04526\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 500\n",
      "mse  training loss=0.04406\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 600\n",
      "mse  training loss=0.04396\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 700\n",
      "mse  training loss=0.04368\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 800\n",
      "mse  training loss=0.04378\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 900\n",
      "mse  training loss=0.04438\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1000\n",
      "mse  training loss=0.04310\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1100\n",
      "mse  training loss=0.04371\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1200\n",
      "mse  training loss=0.04285\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1300\n",
      "mse  training loss=0.04423\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1400\n",
      "mse  training loss=0.04342\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1500\n",
      "mse  training loss=0.04253\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1600\n",
      "mse  training loss=0.04305\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1700\n",
      "mse  training loss=0.04262\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1800\n",
      "mse  training loss=0.04297\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "Evaluating...\n",
      "eval loss=0.04316\n",
      "epoch: 18\n",
      "step: 100\n",
      "mse  training loss=0.04314\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 200\n",
      "mse  training loss=0.04394\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 300\n",
      "mse  training loss=0.04270\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 400\n",
      "mse  training loss=0.04273\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 500\n",
      "mse  training loss=0.04249\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 600\n",
      "mse  training loss=0.04274\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 700\n",
      "mse  training loss=0.04177\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 800\n",
      "mse  training loss=0.04236\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 900\n",
      "mse  training loss=0.04282\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1000\n",
      "mse  training loss=0.04246\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1100\n",
      "mse  training loss=0.04338\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1200\n",
      "mse  training loss=0.04232\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1300\n",
      "mse  training loss=0.04220\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1400\n",
      "mse  training loss=0.04167\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1500\n",
      "mse  training loss=0.04307\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1600\n",
      "mse  training loss=0.04217\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1700\n",
      "mse  training loss=0.04236\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1800\n",
      "mse  training loss=0.04236\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "Evaluating...\n",
      "eval loss=0.04218\n",
      "epoch: 19\n",
      "step: 100\n",
      "mse  training loss=0.04195\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 200\n",
      "mse  training loss=0.04142\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 300\n",
      "mse  training loss=0.04178\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 400\n",
      "mse  training loss=0.04186\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 500\n",
      "mse  training loss=0.04131\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 600\n",
      "mse  training loss=0.04106\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 700\n",
      "mse  training loss=0.04223\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 800\n",
      "mse  training loss=0.04204\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 900\n",
      "mse  training loss=0.04196\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1000\n",
      "mse  training loss=0.04161\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1100\n",
      "mse  training loss=0.04097\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1200\n",
      "mse  training loss=0.04182\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1300\n",
      "mse  training loss=0.04092\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1400\n",
      "mse  training loss=0.04127\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1500\n",
      "mse  training loss=0.04120\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 1600\n",
      "mse  training loss=0.04121\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1700\n",
      "mse  training loss=0.04207\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1800\n",
      "mse  training loss=0.04205\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "Evaluating...\n",
      "eval loss=0.04133\n",
      "epoch: 20\n",
      "step: 100\n",
      "mse  training loss=0.04037\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 200\n",
      "mse  training loss=0.04102\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 300\n",
      "mse  training loss=0.04124\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 400\n",
      "mse  training loss=0.04087\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 500\n",
      "mse  training loss=0.04116\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 600\n",
      "mse  training loss=0.04118\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00001\n",
      "step: 700\n",
      "mse  training loss=0.04167\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 800\n",
      "mse  training loss=0.04065\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 900\n",
      "mse  training loss=0.04125\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1000\n",
      "mse  training loss=0.04001\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1100\n",
      "mse  training loss=0.04092\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1200\n",
      "mse  training loss=0.04051\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1300\n",
      "mse  training loss=0.04091\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1400\n",
      "mse  training loss=0.03950\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1500\n",
      "mse  training loss=0.04093\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1600\n",
      "mse  training loss=0.04054\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1700\n",
      "mse  training loss=0.04056\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1800\n",
      "mse  training loss=0.04072\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "Evaluating...\n",
      "eval loss=0.04050\n",
      "epoch: 21\n",
      "step: 100\n",
      "mse  training loss=0.04149\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 200\n",
      "mse  training loss=0.04067\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 300\n",
      "mse  training loss=0.03978\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 400\n",
      "mse  training loss=0.04039\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 500\n",
      "mse  training loss=0.04018\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 600\n",
      "mse  training loss=0.04078\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 700\n",
      "mse  training loss=0.04050\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 800\n",
      "mse  training loss=0.04055\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 900\n",
      "mse  training loss=0.03939\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1000\n",
      "mse  training loss=0.03949\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1100\n",
      "mse  training loss=0.03992\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1200\n",
      "mse  training loss=0.04093\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1300\n",
      "mse  training loss=0.04122\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1400\n",
      "mse  training loss=0.03994\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1500\n",
      "mse  training loss=0.03933\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1600\n",
      "mse  training loss=0.03965\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1700\n",
      "mse  training loss=0.03996\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1800\n",
      "mse  training loss=0.04009\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "Evaluating...\n",
      "eval loss=0.03975\n",
      "epoch: 22\n",
      "step: 100\n",
      "mse  training loss=0.03952\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 200\n",
      "mse  training loss=0.04002\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 300\n",
      "mse  training loss=0.04039\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 400\n",
      "mse  training loss=0.03943\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 500\n",
      "mse  training loss=0.03959\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 600\n",
      "mse  training loss=0.03927\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 700\n",
      "mse  training loss=0.04000\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 800\n",
      "mse  training loss=0.03959\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 900\n",
      "mse  training loss=0.03930\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1000\n",
      "mse  training loss=0.03974\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1100\n",
      "mse  training loss=0.03964\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1200\n",
      "mse  training loss=0.03917\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1300\n",
      "mse  training loss=0.03948\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1400\n",
      "mse  training loss=0.03906\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1500\n",
      "mse  training loss=0.03881\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1600\n",
      "mse  training loss=0.03934\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1700\n",
      "mse  training loss=0.03888\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1800\n",
      "mse  training loss=0.03967\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "Evaluating...\n",
      "eval loss=0.03944\n",
      "epoch: 23\n",
      "step: 100\n",
      "mse  training loss=0.03819\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 200\n",
      "mse  training loss=0.04001\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 300\n",
      "mse  training loss=0.03924\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 400\n",
      "mse  training loss=0.03931\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 500\n",
      "mse  training loss=0.03990\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 600\n",
      "mse  training loss=0.03821\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 700\n",
      "mse  training loss=0.03862\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 800\n",
      "mse  training loss=0.03966\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 900\n",
      "mse  training loss=0.03922\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1000\n",
      "mse  training loss=0.03858\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1100\n",
      "mse  training loss=0.03824\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1200\n",
      "mse  training loss=0.03905\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1300\n",
      "mse  training loss=0.03960\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1400\n",
      "mse  training loss=0.03826\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1500\n",
      "mse  training loss=0.03889\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1600\n",
      "mse  training loss=0.03929\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1700\n",
      "mse  training loss=0.03935\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1800\n",
      "mse  training loss=0.03926\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "Evaluating...\n",
      "eval loss=0.03895\n",
      "epoch: 24\n",
      "step: 100\n",
      "mse  training loss=0.03958\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 200\n",
      "mse  training loss=0.03878\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 300\n",
      "mse  training loss=0.03849\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 400\n",
      "mse  training loss=0.03874\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 500\n",
      "mse  training loss=0.03828\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 600\n",
      "mse  training loss=0.03975\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 700\n",
      "mse  training loss=0.03842\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 800\n",
      "mse  training loss=0.03917\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 900\n",
      "mse  training loss=0.03935\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1000\n",
      "mse  training loss=0.03839\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1100\n",
      "mse  training loss=0.03840\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1200\n",
      "mse  training loss=0.03981\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1300\n",
      "mse  training loss=0.03829\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1400\n",
      "mse  training loss=0.03815\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1500\n",
      "mse  training loss=0.03823\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1600\n",
      "mse  training loss=0.03839\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1700\n",
      "mse  training loss=0.03861\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1800\n",
      "mse  training loss=0.03842\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "Evaluating...\n",
      "eval loss=0.03900\n",
      "epoch: 25\n",
      "step: 100\n",
      "mse  training loss=0.03776\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 200\n",
      "mse  training loss=0.03898\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 300\n",
      "mse  training loss=0.03915\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 400\n",
      "mse  training loss=0.03938\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 500\n",
      "mse  training loss=0.03893\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 600\n",
      "mse  training loss=0.03868\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 700\n",
      "mse  training loss=0.03819\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 800\n",
      "mse  training loss=0.03784\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 900\n",
      "mse  training loss=0.03843\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1000\n",
      "mse  training loss=0.03906\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1100\n",
      "mse  training loss=0.03836\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1200\n",
      "mse  training loss=0.03743\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1300\n",
      "mse  training loss=0.03857\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1400\n",
      "mse  training loss=0.03871\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1500\n",
      "mse  training loss=0.03908\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1600\n",
      "mse  training loss=0.03899\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1700\n",
      "mse  training loss=0.03797\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1800\n",
      "mse  training loss=0.03941\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "Evaluating...\n",
      "eval loss=0.03891\n",
      "epoch: 26\n",
      "step: 100\n",
      "mse  training loss=0.03778\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 200\n",
      "mse  training loss=0.03828\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 300\n",
      "mse  training loss=0.03741\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 400\n",
      "mse  training loss=0.03853\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 500\n",
      "mse  training loss=0.03903\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 600\n",
      "mse  training loss=0.03800\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 700\n",
      "mse  training loss=0.03787\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 800\n",
      "mse  training loss=0.03842\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 900\n",
      "mse  training loss=0.03781\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1000\n",
      "mse  training loss=0.03815\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1100\n",
      "mse  training loss=0.03832\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1200\n",
      "mse  training loss=0.03773\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1300\n",
      "mse  training loss=0.03805\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1400\n",
      "mse  training loss=0.03782\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1500\n",
      "mse  training loss=0.03923\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1600\n",
      "mse  training loss=0.03977\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1700\n",
      "mse  training loss=0.03851\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1800\n",
      "mse  training loss=0.03846\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "Evaluating...\n",
      "eval loss=0.03827\n",
      "epoch: 27\n",
      "step: 100\n",
      "mse  training loss=0.03806\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 200\n",
      "mse  training loss=0.03835\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 300\n",
      "mse  training loss=0.03834\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 400\n",
      "mse  training loss=0.03742\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 500\n",
      "mse  training loss=0.03889\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 600\n",
      "mse  training loss=0.03823\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 700\n",
      "mse  training loss=0.03850\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 800\n",
      "mse  training loss=0.03881\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 900\n",
      "mse  training loss=0.03787\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1000\n",
      "mse  training loss=0.03851\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1100\n",
      "mse  training loss=0.03842\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1200\n",
      "mse  training loss=0.03763\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1300\n",
      "mse  training loss=0.03859\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1400\n",
      "mse  training loss=0.03849\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1500\n",
      "mse  training loss=0.03859\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1600\n",
      "mse  training loss=0.03690\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1700\n",
      "mse  training loss=0.03785\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1800\n",
      "mse  training loss=0.03791\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "Evaluating...\n",
      "eval loss=0.03807\n",
      "epoch: 28\n",
      "step: 100\n",
      "mse  training loss=0.03785\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 200\n",
      "mse  training loss=0.03762\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 300\n",
      "mse  training loss=0.03844\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 400\n",
      "mse  training loss=0.03839\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 500\n",
      "mse  training loss=0.03841\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 600\n",
      "mse  training loss=0.03820\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 700\n",
      "mse  training loss=0.03780\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 800\n",
      "mse  training loss=0.03880\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 900\n",
      "mse  training loss=0.03843\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1000\n",
      "mse  training loss=0.03813\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1100\n",
      "mse  training loss=0.03847\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1200\n",
      "mse  training loss=0.03861\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1300\n",
      "mse  training loss=0.03826\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1400\n",
      "mse  training loss=0.03774\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1500\n",
      "mse  training loss=0.03848\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1600\n",
      "mse  training loss=0.03741\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1700\n",
      "mse  training loss=0.03849\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1800\n",
      "mse  training loss=0.03811\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "Evaluating...\n",
      "eval loss=0.03803\n",
      "epoch: 29\n",
      "step: 100\n",
      "mse  training loss=0.03752\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 200\n",
      "mse  training loss=0.03747\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 300\n",
      "mse  training loss=0.03762\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 400\n",
      "mse  training loss=0.03880\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 500\n",
      "mse  training loss=0.03760\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 600\n",
      "mse  training loss=0.03774\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 700\n",
      "mse  training loss=0.03802\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 800\n",
      "mse  training loss=0.03777\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 900\n",
      "mse  training loss=0.03848\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1000\n",
      "mse  training loss=0.03824\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1100\n",
      "mse  training loss=0.03779\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1200\n",
      "mse  training loss=0.03757\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1300\n",
      "mse  training loss=0.03873\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1400\n",
      "mse  training loss=0.03749\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1500\n",
      "mse  training loss=0.03778\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1600\n",
      "mse  training loss=0.03760\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1700\n",
      "mse  training loss=0.03933\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1800\n",
      "mse  training loss=0.03872\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "Evaluating...\n",
      "eval loss=0.03796\n",
      "epoch: 30\n",
      "step: 100\n",
      "mse  training loss=0.03800\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 200\n",
      "mse  training loss=0.03781\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 300\n",
      "mse  training loss=0.03896\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 400\n",
      "mse  training loss=0.03861\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 500\n",
      "mse  training loss=0.03905\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 600\n",
      "mse  training loss=0.03718\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 700\n",
      "mse  training loss=0.03825\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 800\n",
      "mse  training loss=0.03897\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 900\n",
      "mse  training loss=0.03757\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1000\n",
      "mse  training loss=0.03816\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1100\n",
      "mse  training loss=0.03800\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1200\n",
      "mse  training loss=0.03855\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1300\n",
      "mse  training loss=0.03814\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1400\n",
      "mse  training loss=0.03757\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1500\n",
      "mse  training loss=0.03889\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1600\n",
      "mse  training loss=0.03772\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1700\n",
      "mse  training loss=0.03768\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "step: 1800\n",
      "mse  training loss=0.03767\n",
      "L_T  training loss=0.00000\n",
      "rounding  training loss=0.00000\n",
      "Evaluating...\n",
      "eval loss=0.03794\n"
     ]
    }
   ],
   "source": [
    "# train loop\n",
    "# loss_terms_dict_lst = []\n",
    "loss_terms_dict = defaultdict(list)\n",
    "loss_terms_weights = None\n",
    "verbose = True\n",
    "print_steps=100\n",
    "progress_bar = tqdm(range(num_epoch*len(train_dataloader)))\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    print(\"epoch:\",epoch+1)\n",
    "    # loss_terms_dict_lst.append(train_conditional(diffusion_model=diffusion_model, dataloader=train_dataloader, optimizer=optimizer, scheduler=scheduler ,progress_bar=progress_bar ,verbose=True))\n",
    "    device = next(diffusion_model.parameters()).device\n",
    "\n",
    "    if loss_terms_weights is None:\n",
    "        loss_terms_weights = {}\n",
    "        for term_name in diffusion_model.loss_terms:\n",
    "            loss_terms_weights[term_name] = 1\n",
    "\n",
    "    training_loss = {}\n",
    "    for term_name in diffusion_model.loss_terms:\n",
    "        training_loss[term_name] = 0\n",
    "    sample_cnt = 0\n",
    "    diffusion_model.train()\n",
    "    for step, data in enumerate(train_dataloader):\n",
    "\n",
    "        if diffusion_model.model.encoder_type in ['frozen', 'fine-tune']:\n",
    "            # use input_ids and attention mask from bert tokenizer\n",
    "            # question1 as source, question2 as target\n",
    "            input_ids = data['question2_input_ids'].to(device)\n",
    "            attention_mask = data['question2_attention_mask'].to(device)\n",
    "            src_ids = data['question1_input_ids_bert'].to(device)\n",
    "            src_attention_mask = data['question1_attention_mask_bert'].to(device)\n",
    "            loss_terms = diffusion_model(input_ids=input_ids,\n",
    "                                            attention_mask=attention_mask,\n",
    "                                            src_ids=src_ids,\n",
    "                                            src_attention_mask=src_attention_mask)\n",
    "        elif diffusion_model.model.encoder_type in ['from-scratch']:\n",
    "            # use input_ids and attention mask from custom tokenizer\n",
    "            input_ids = data['question2_input_ids'].to(device)\n",
    "            attention_mask = data['question2_attention_mask'].to(device)\n",
    "            src_ids = data['question1_input_ids'].to(device)\n",
    "            src_attention_mask = data['question1_attention_mask'].to(device)\n",
    "            loss_terms = diffusion_model(input_ids=input_ids,\n",
    "                                            attention_mask=attention_mask,\n",
    "                                            src_ids=src_ids,\n",
    "                                            src_attention_mask=src_attention_mask)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        loss = sum([v.mean()*loss_terms_weights[k] for k, v in loss_terms.items()])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        bs = input_ids.shape[0]\n",
    "        sample_cnt += bs\n",
    "        # training_loss += loss.detach().cpu() * bs\n",
    "\n",
    "        for k, v in loss_terms.items():\n",
    "            loss_term = (v.detach().cpu().mean()*loss_terms_weights[k]).item()\n",
    "            loss_terms_dict[k].append(loss_term)\n",
    "            training_loss[k] += loss_term * bs\n",
    "\n",
    "        if verbose and step % print_steps == print_steps-1:\n",
    "            # print training loss\n",
    "            # training_loss /= sample_cnt\n",
    "            print('step:', step+1)\n",
    "            for k, v in training_loss.items():\n",
    "                print(k, ' training loss={:.5f}'.format(v/sample_cnt))\n",
    "            sample_cnt = 0\n",
    "            training_loss = {}\n",
    "            for term_name in diffusion_model.loss_terms:\n",
    "                training_loss[term_name] = 0\n",
    "\n",
    "    # evaluate_conditional(diffusion_model=diffusion_model, dataloader=eval_dataloader,)\n",
    "    device = next(diffusion_model.parameters()).device\n",
    "\n",
    "    if loss_terms_weights is None:\n",
    "        loss_terms_weights = {}\n",
    "        for term_name in diffusion_model.loss_terms:\n",
    "            loss_terms_weights[term_name] = 1\n",
    "\n",
    "    print(\"Evaluating...\")\n",
    "    diffusion_model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in eval_dataloader:\n",
    "            \n",
    "            if diffusion_model.model.encoder_type in ['frozen', 'fine-tune']:\n",
    "                # use input_ids and attention mask from bert tokenizer\n",
    "                # question1 as source, question2 as target\n",
    "                input_ids = data['question2_input_ids'].to(device)\n",
    "                attention_mask = data['question2_attention_mask'].to(device)\n",
    "                src_ids = data['question1_input_ids_bert'].to(device)\n",
    "                src_attention_mask = data['question1_attention_mask_bert'].to(device)\n",
    "                loss_terms = diffusion_model(input_ids=input_ids,\n",
    "                                             attention_mask=attention_mask,\n",
    "                                             src_ids=src_ids,\n",
    "                                             src_attention_mask=src_attention_mask)\n",
    "            elif diffusion_model.model.encoder_type in ['from-scratch']:\n",
    "                # use input_ids and attention mask from custom tokenizer\n",
    "                input_ids = data['question2_input_ids'].to(device)\n",
    "                attention_mask = data['question2_attention_mask'].to(device)\n",
    "                src_ids = data['question1_input_ids'].to(device)\n",
    "                src_attention_mask = data['question1_attention_mask'].to(device)\n",
    "                loss_terms = diffusion_model(input_ids=input_ids,\n",
    "                                             attention_mask=attention_mask,\n",
    "                                             src_ids=src_ids,\n",
    "                                             src_attention_mask=src_attention_mask)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "            loss = sum([v.mean()*loss_terms_weights[k] for k, v in loss_terms.items()])\n",
    "            bs = input_ids.shape[0]\n",
    "            test_loss += bs*loss\n",
    "\n",
    "        test_loss /= len(eval_dataloader.dataset)\n",
    "        if verbose:\n",
    "            print('eval loss={:.5f}'.format(test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG2CAYAAACDLKdOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABlGUlEQVR4nO3dd3xN9/8H8Ne92ZFJSIwQewsSIlRR0RhF0VK0RlW/fmirabWUWh1RRVWrtJSoDjqsWkWIEbElYsXKMrJEpsx7z++Py5Hr3oyb3HtPcvN6Ph734d5zPuec9z25ct/5TJkgCAKIiIiITIRc6gCIiIiI9InJDREREZkUJjdERERkUpjcEBERkUlhckNEREQmhckNERERmRQmN0RERGRSmNwQERGRSWFyQ0RERCaFyQ0RERGZlEqR3KxatQoeHh6wtraGj48PTp8+XWzZoKAgyGQytYe1tbURoyUiIqLKTPLkZsuWLQgICMD8+fNx/vx5eHp6wt/fH0lJScUe4+DggPv374uP2NhYI0ZMRERElZnkyc3y5csxefJkTJw4EW3atMGaNWtga2uL9evXF3uMTCaDm5ub+HB1dTVixERERFSZmUt58fz8fJw7dw6zZ88Wt8nlcvj5+SEsLKzY47KystCoUSMolUp07twZX375Jdq2bau1bF5eHvLy8sTXSqUSqampqFWrFmQymf7eDBERERmMIAjIzMxEvXr1IJeXXDcjaXKTkpIChUKhUfPi6uqKa9euaT2mZcuWWL9+PTp06ID09HQsXboU3bt3x+XLl9GgQQON8oGBgVi4cKFB4iciIiLjio+P1/p9X5SkyU15+Pr6wtfXV3zdvXt3tG7dGj/++CM+++wzjfKzZ89GQECA+Do9PR0NGzZEfHw8HBwc9Brbh3+GY9/lRMwe0BJju3kAgVpu/uw7er0mERFRdZCRkQF3d3fY29uXWlbS5MbFxQVmZmZITExU256YmAg3N7cyncPCwgKdOnXCzZs3te63srKClZWVxnYHBwe9JzeWtnaQW2XCuoa96txWWpq99HxNIiKi6qQsXUok7VBsaWkJLy8vBAcHi9uUSiWCg4PVamdKolAoEBkZibp16xoqzDJjHx4iIiLpSd4sFRAQgPHjx8Pb2xtdu3bFihUrkJ2djYkTJwIAxo0bh/r16yMwMBAAsGjRInTr1g3NmjVDWloavv76a8TGxuKtt96S8m0QERFRJSF5cjNq1CgkJydj3rx5SEhIQMeOHbFv3z6xk3FcXJxar+iHDx9i8uTJSEhIgLOzM7y8vHDixAm0adNGqregQRCkjoCIiKj6kglC9foqzsjIgKOjI9LT0/Xe5+bdPy5gZ8Q9zHupDd58rjGwwFGz0IJ0vV6TiKgyUygUKCgokDoMqiIsLS2LHeaty/e35DU3RERkegRBQEJCAtLS0qQOhaoQuVyOxo0bw9LSskLnYXJjANWqKoyISIsniU2dOnVga2vLARdUKqVSiXv37uH+/fto2LBhhT4zTG70iP93iYhUTVFPEptatWpJHQ5VIbVr18a9e/dQWFgICwuLcp9H8rWliIjItDzpY2NraytxJFTVPGmOUigUFToPkxsDqGZ9tImItGJTFOlKX58ZJjd6xP/GRERE0mNyQ0REVMl4eHhgxYoVUodRZTG50SNWwRIRVW0TJkyATCbDlClTNPZNmzYNMpkMEyZMELclJyfj//7v/9CwYUNYWVnBzc0N/v7+CA0NFct4eHhAJpNpPBYvXmyMt1QtcbQUERFREe7u7ti8eTO++eYb2NjYAAByc3Px+++/o2HDhmplR4wYgfz8fGzcuBFNmjRBYmIigoOD8eDBA7VyixYtwuTJk9W2lWV1ayof1twYAPsTExFVXZ07d4a7uzu2bt0qbtu6dSsaNmyITp06idvS0tJw7NgxfPXVV+jTpw8aNWqErl27Yvbs2RgyZIjaOe3t7eHm5qb2qFGjRpljiouLw9ChQ2FnZwcHBweMHDkSiYmJ4v6IiAj06dMH9vb2cHBwgJeXF86ePQsAiI2NxeDBg+Hs7IwaNWqgbdu22LNnT3lvT5XAmhs9YqMUEZF2giAgp6Biw3vLy8bCTOduA2+++SY2bNiAsWPHAgDWr1+PiRMnIiQkRCxjZ2cHOzs7bN++Hd26dYOVlZU+wxYplUoxsTly5AgKCwsxbdo0jBo1Soxn7Nix6NSpE1avXg0zMzOEh4eL88RMmzYN+fn5OHr0KGrUqIErV67Azs7OILFWFkxuiIjI4HIKFGgz7z9Jrn1lkT9sLXX7unv99dcxe/ZsxMbGAgBCQ0OxefNmteTG3NwcQUFBmDx5MtasWYPOnTujV69eeO2119ChQwe183388ceYO3eu2ra9e/eiZ8+epcYSHByMyMhIREdHw93dHQDwyy+/oG3btjhz5gy6dOmCuLg4zJw5E61atQIANG/eXDw+Li4OI0aMQPv27QEATZo00eleVEVsljIAgQswEBFVabVr18agQYMQFBSEDRs2YNCgQXBxcdEoN2LECNy7dw87d+5E//79ERISgs6dOyMoKEit3MyZMxEeHq728Pb2LlMsV69ehbu7u5jYAECbNm3g5OSEq1evAgACAgLw1ltvwc/PD4sXL8atW7fEsu+++y4+//xz9OjRA/Pnz8fFixfLcUeqFtbc6BPbpYiItLKxMMOVRf6SXbs83nzzTUyfPh0AsGrVqmLLWVtbo1+/fujXrx8+/fRTvPXWW5g/f77aqCoXFxc0a9asXHGUxYIFCzBmzBjs3r0be/fuxfz587F582YMGzYMb731Fvz9/bF7927s378fgYGBWLZsGd555x2DxSM11twQEZHByWQy2FqaS/Io7zQd/fv3R35+PgoKCuDvX/bErE2bNsjOzi7XNbVp3bo14uPjER8fL267cuUK0tLS0KZNG3FbixYt8P7772P//v0YPnw4NmzYIO5zd3fHlClTsHXrVnzwwQdYu3at3uKrjFhzYwAcLUVEVPWZmZmJzT5mZpq1Pw8ePMCrr76KN998Ex06dIC9vT3Onj2LJUuWYOjQoWplMzMzkZCQoLbN1tYWDg4Opcbh5+eH9u3bY+zYsVixYgUKCwsxdepU9OrVC97e3sjJycHMmTPxyiuvoHHjxrhz5w7OnDmDESNGAABmzJiBAQMGoEWLFnj48CEOHz6M1q1bl/e2VAlMbvRIxnYpIiKTUlLyYWdnBx8fH3zzzTe4desWCgoK4O7ujsmTJ+OTTz5RKztv3jzMmzdPbdv//vc/rFmzptQYZDIZduzYgXfeeQfPP/885HI5+vfvj++++w6AKvF68OABxo0bh8TERLi4uGD48OFYuHAhANUilNOmTcOdO3fg4OCA/v3745tvvtH1VlQpMqGarfKYkZEBR0dHpKenlylj1sUHf0bgn/N3MGtAK0zp1RRY4KhZaEG6Xq9JRFTZ5ObmIjo6Go0bN4a1tbXU4VAVUtJnR5fvb/a50SOuvkBERCQ9JjdERERkUpjcGIDY0GfJdUOIiIiMjcmNHmm0SjXpJUUYRERE1RqTGyIiIjIpTG4MgMsvEBERSYfJjR5xtBQREZH0mNwQERGRSWFyYwDVa1pEIiKiyoXJjR5pLL/ALIeIiCogJCQEMpkMaWlpAICgoCA4OTkZ/LoLFixAx44dDX4dQ2FyQ0REVEWMGjUK169flzqMSo8LZ+oROxQTEZmW/Px8WFpaSh2GyMbGBjY2NlKHUemx5oaIiOix3r17Y/r06ZgxYwZcXFzg7+8PADhy5Ai6du0KKysr1K1bF7NmzUJhYaF4nIeHB1asWKF2ro4dO2LBggXia5lMhnXr1mHYsGGwtbVF8+bNsXPnTrVj9uzZgxYtWsDGxgZ9+vRBTEyM2v5nm6WeNB9t2rQJHh4ecHR0xGuvvYbMzEyxTGZmJsaOHYsaNWqgbt26+Oabb9C7d2/MmDGjzPdFqVRi0aJFaNCgAaysrNCxY0fs27dP3J+fn4/p06ejbt26sLa2RqNGjRAYGAgAEAQBCxYsQMOGDWFlZYV69erh3XffLfO1y4PJjQFUs4XWiYhKJwhAfrY0Dx1/J2/cuBGWlpYIDQ3FmjVrcPfuXQwcOBBdunRBREQEVq9ejZ9//hmff/65zrdh4cKFGDlyJC5evIiBAwdi7NixSE1NBQDEx8dj+PDhGDx4MMLDw/HWW29h1qxZpZ7z1q1b2L59O3bt2oVdu3bhyJEjWLx4sbg/ICAAoaGh2LlzJw4cOIBjx47h/PnzOsX97bffYtmyZVi6dCkuXrwIf39/DBkyBDdu3AAArFy5Ejt37sSff/6JqKgo/Pbbb/Dw8AAA/PPPP/jmm2/w448/4saNG9i+fTvat2+v0/V1xWYpPWKzFBFRMQoeAV/Wk+ban9wDLGuUuXjz5s2xZMkS8fWcOXPg7u6O77//HjKZDK1atcK9e/fw8ccfY968eZDLy15PMGHCBIwePRoA8OWXX2LlypU4ffo0+vfvj9WrV6Np06ZYtmwZAKBly5aIjIzEV199VeI5lUolgoKCYG+vWs/wjTfeQHBwML744gtkZmZi48aN+P3339G3b18AwIYNG1Cvnm4/i6VLl+Ljjz/Ga6+9BgD46quvcPjwYaxYsQKrVq1CXFwcmjdvjueeew4ymQyNGjUSj42Li4Obmxv8/PxgYWGBhg0bomvXrjpdX1esuTEo1uAQEVU1Xl5eaq+vXr0KX19fyIr8BdujRw9kZWXhzp07Op27Q4cO4vMaNWrAwcEBSUlJ4nV8fHzUyvv6+pZ6Tg8PDzGxAYC6deuK57x9+zYKCgrUkglHR0e0bNmyzDFnZGTg3r176NGjh9r2Hj164OrVqwBUSVt4eDhatmyJd999F/v37xfLvfrqq8jJyUGTJk0wefJkbNu2Ta1JzxBYc2MAbJUiInqGha2qBkWqa+ugRo2y1/I8IZfLNbokFBQUaIZiYaH2WiaTQalU6nw9Q59TV507d0Z0dDT27t2LgwcPYuTIkfDz88Pff/8Nd3d3REVF4eDBgzhw4ACmTp2Kr7/+GkeOHNGIXV9Yc6NXbJciItJKJlM1DUnxqGCfgdatWyMsLEwteQkNDYW9vT0aNGgAAKhduzbu378v7s/IyEB0dLTO1zl9+rTatpMnT1YgcqBJkyawsLDAmTNnxG3p6ek6DSd3cHBAvXr1EBoaqrY9NDQUbdq0USs3atQorF27Flu2bME///wj9ieysbHB4MGDsXLlSoSEhCAsLAyRkZEVem8lYc0NERFRCaZOnYoVK1bgnXfewfTp0xEVFYX58+cjICBA7G/zwgsvICgoCIMHD4aTkxPmzZsHMzMzna4zZcoULFu2DDNnzsRbb72Fc+fOISgoqEKx29vbY/z48Zg5cyZq1qyJOnXqYP78+ZDL5WrNbKWZOXMm5s+fj6ZNm6Jjx47YsGEDwsPD8dtvvwEAli9fjrp166JTp06Qy+X466+/4ObmBicnJwQFBUGhUMDHxwe2trb49ddfYWNjo9YvR9+Y3BgAW6WIiExH/fr1sWfPHsycOROenp6oWbMmJk2ahLlz54plZs+ejejoaLz00ktwdHTEZ599pnPNTcOGDfHPP//g/fffx3fffYeuXbviyy+/xJtvvlmh+JcvX44pU6bgpZdegoODAz766CPEx8fD2tq6zOd49913kZ6ejg8++ABJSUlo06YNdu7ciebNmwNQJVFLlizBjRs3YGZmhi5dumDPnj2Qy+VwcnLC4sWLERAQAIVCgfbt2+Pff/9FrVq1KvS+SiITqtm45YyMDDg6OiI9PR0ODg56Pfcn2yLx+6k4BPRrgXf7Ngf+GA1E7Xmm0H3AUrf2XyKiqiQ3NxfR0dFo3LixTl+gZBzZ2dmoX78+li1bhkmTJkkdjpqSPju6fH+zz40exaRkq/2rtWdx2CojRkRERNXdhQsX8Mcff+DWrVs4f/48xo4dCwAYOnSoxJEZDpMbPTpx6wEAYOuFu8UXykowUjREREQqS5cuhaenJ/z8/JCdnY1jx47BxcVF6rAMhn1uiIiITFinTp1w7tw5qcMwKtbcEBERkUlhckNERAZRzcarkB7o6zPD5IaIiPTqyayzjx49kjgSqmry8/MBQOc5gp7FPjdERKRXZmZmcHJyEtc3srW11WnCOKqelEolkpOTYWtrC3PziqUnTG4MSkv1GqtpiagacHNzAwAxwSEqC7lcjoYNG1Y4GWZyQ0REeieTyVC3bl3UqVNH6wKSRNpYWlqKS1pUBJMbY3uUInUERERGY2ZmVuH+E0S6YodiQ9LWBHXnrPHjICIiqkaY3Bgb+9wQEREZFJMbQ3KoJ3UERERE1Q6TG0OyrCF1BERERNUOkxtj41wPREREBsXkhoiIiEwKkxsiIiIyKUxujI7NUkRERIbE5MbY2OeGiIjIoJjcEBERkUlhcmNINs5SR0BERFTtMLkxpIbdpI6AiIio2mFyY1DsX0NERGRsTG6IiIjIpFSK5GbVqlXw8PCAtbU1fHx8cPr06TIdt3nzZshkMrz88suGDbDctC2SydocIiIiQ5I8udmyZQsCAgIwf/58nD9/Hp6envD390dSUlKJx8XExODDDz9Ez549jRSpnqTHAbcOSx0FERGRyZI8uVm+fDkmT56MiRMnok2bNlizZg1sbW2xfv36Yo9RKBQYO3YsFi5ciCZNmhgxWj3Z9DKQECl1FERERCZJ0uQmPz8f586dg5+fn7hNLpfDz88PYWFhxR63aNEi1KlTB5MmTSr1Gnl5ecjIyFB7VAqJV6SOgIiIyCRJmtykpKRAoVDA1dVVbburqysSEhK0HnP8+HH8/PPPWLt2bZmuERgYCEdHR/Hh7u5e4biJiIio8pK8WUoXmZmZeOONN7B27Vq4uLiU6ZjZs2cjPT1dfMTHxxs4SiIiIpKSuZQXd3FxgZmZGRITE9W2JyYmws3NTaP8rVu3EBMTg8GDB4vblEolAMDc3BxRUVFo2rSp2jFWVlawsrIyQPQlEwSB46KIiIgkIGnNjaWlJby8vBAcHCxuUyqVCA4Ohq+vr0b5Vq1aITIyEuHh4eJjyJAh6NOnD8LDwytVk9PeS9qb1YiIiMiwJK25AYCAgACMHz8e3t7e6Nq1K1asWIHs7GxMnDgRADBu3DjUr18fgYGBsLa2Rrt27dSOd3JyAgCN7VLbeykBAzXzs6e4OjgREZFBSJ7cjBo1CsnJyZg3bx4SEhLQsWNH7Nu3T+xkHBcXB7m8SnUNIiIiIglJntwAwPTp0zF9+nSt+0JCQko8NigoSP8BERERUZXFKhEiIiIyKUxuDIQ9aoiIiKTB5IaIiIhMCpMbA0nJygNsnEsowbodIiIiQ2ByYyBKQQBc20odBhERUbXD5EYqnOeGiIjIIJjcEBERkUlhckNEREQmhcmNgcjYYZiIiEgSTG4MJDOvQOoQiIiIqiUmNwZy6W6G1CEQERFVS0xuiIiIyKQwuSEiIiKTwuRGj6wtdLidnOeGiIjIIJjc6JGcCQsREZHkmNzoEZMbIiIi6TG50SPmNkRERNJjcqNHuuU2zISIiIgMgcmNHsnlOiQsrOYhIiIyCCY3esR0hYiISHpMbvRIxtoYIiIiyTG50SNdWqWIiIjIMJjc6BFrboiIiKTH5EaPOFqKiIhIekxu9IgVN0RERNJjcqNHnKGYiIhIekxu9OjZ5CYjt0CiSIiIiKovJjd69GzFzZnoVGkCISIiqsaY3OiRvbWF1CEQERFVe0xu9GjSc43VXgtCCYXZP4eIiMggmNzokZ2VuQ6lmdwQEREZApMbPXq2MqakihsiIiIyDCY3eqRTXYwi31BhEBERVWtMbvTITNviUg26ai98cKFhgyEiIqqmmNzokUazlCAAnd/QXjg9zvABERERVUNMbvRI68KZMjPjB0JERFSNMbnRo2dnKGaHYiIiIuNjcqNHz9bbFCoEoJGvJLEQERFVV0xu9EjrvHw1mxg9DiIiouqMyY0eaTZLsWGKiIjI2Jjc6NGzNTdK5jZERERGx+RGj56tufnrbLxEkRAREVVfTG706NkuN8dupEgSBxERUXXG5EaPzM14O4mIiKTGb2M9qlnDUuoQiIiIqj0mN3pkpnUsOBERERkTkxs9quNgJXUIRERE1R6TGyIiIjIpTG4MLDkzT+oQiIiIqhUmNwY28+8IqUMgIiKqVpjcGNjlexlSh0BERFStMLkhIiIik8LkxsCEktaXurIDyMsyWixERETVAZMbKf05Dtj2P6mjICIiMilMbvSoxFqa4lzbpfc4iIiIqjMmNwZXnoyHiIiIyovJjR4JTGSIiIgkx+RGj8rVLEVERER6xeRGj7TlNkomPEREREbF5MbAlKzOISIiMiomN3okaElk8guVwORDEkRDRERUPTG50SNtdTSP8hWAjbPRYyEiIqqumNwQERGRSakUyc2qVavg4eEBa2tr+Pj44PTp08WW3bp1K7y9veHk5IQaNWqgY8eO2LRpkxGjLV4NS3OpQyAiIqr2JE9utmzZgoCAAMyfPx/nz5+Hp6cn/P39kZSUpLV8zZo1MWfOHISFheHixYuYOHEiJk6ciP/++8/IkWsyk8u072CnYiIiIqORPLlZvnw5Jk+ejIkTJ6JNmzZYs2YNbG1tsX79eq3le/fujWHDhqF169Zo2rQp3nvvPXTo0AHHjx83cuRERERUGUma3OTn5+PcuXPw8/MTt8nlcvj5+SEsLKzU4wVBQHBwMKKiovD8889rLZOXl4eMjAy1BxEREZkuSZOblJQUKBQKuLq6qm13dXVFQkJCscelp6fDzs4OlpaWGDRoEL777jv069dPa9nAwEA4OjqKD3d3d72+ByIiIqpcJG+WKg97e3uEh4fjzJkz+OKLLxAQEICQkBCtZWfPno309HTxER8fb9xgAUCpMP41iYiIqilJh/e4uLjAzMwMiYmJatsTExPh5uZW7HFyuRzNmjUDAHTs2BFXr15FYGAgevfurVHWysoKVlZWeo1bZ8oCaa9PRERUjUhac2NpaQkvLy8EBweL25RKJYKDg+Hr61vm8yiVSuTl5RkiRP1QMLkhIiIyFsknZgkICMD48ePh7e2Nrl27YsWKFcjOzsbEiRMBAOPGjUP9+vURGBgIQNWHxtvbG02bNkVeXh727NmDTZs2YfXq1VK+jZIpC6WOgIiIqNqQPLkZNWoUkpOTMW/ePCQkJKBjx47Yt2+f2Mk4Li4OcvnTCqbs7GxMnToVd+7cgY2NDVq1aoVff/0Vo0aNkuotlE5QSh0BERFRtSETtK32aMIyMjLg6OiI9PR0ODg46P38HrN2a2yL+bI/sKhm8QctSNd7HERERKZEl+/vKjlaqqrJzGfNDRERkbEwuTGCpf9FSR0CERFRtcHkxggu3+OsyERERMbC5MYIzsY+lDoEIiKiaoPJDREREZkUJjdERERkUpjcEBERkUlhckNEREQmhckNERERmRQmN0RERGRSmNwQERGRSWFyQ0RERCaFyQ0RERGZFCY3elbfyUbqEIiIiKo1JjdERERkUpjcEBERkUlhcqNngiBIHQIREVG1xuSGiIiITEq5kpv4+HjcuXNHfH369GnMmDEDP/30k94Cq6pkMpnUIRAREVVr5UpuxowZg8OHDwMAEhIS0K9fP5w+fRpz5szBokWL9BpgVcNmKSIiImmVK7m5dOkSunbtCgD4888/0a5dO5w4cQK//fYbgoKC9BlflcOaGyIiImmVK7kpKCiAlZUVAODgwYMYMmQIAKBVq1a4f/++/qKrgszkTG6IiIikVK7kpm3btlizZg2OHTuGAwcOoH///gCAe/fuoVatWnoNsKoZ391D6hCIiIiqtXIlN1999RV+/PFH9O7dG6NHj4anpycAYOfOnWJzVXU1kckNERGRpMzLc1Dv3r2RkpKCjIwMODs7i9vffvtt2Nra6i24qkjOZikiIiJJlavmJicnB3l5eWJiExsbixUrViAqKgp16tTRa4DVQtgqIPuB1FEQERGZhHIlN0OHDsUvv/wCAEhLS4OPjw+WLVuGl19+GatXr9ZrgNXCf58Af46TOgoiIiKTUK7k5vz58+jZsycA4O+//4arqytiY2Pxyy+/YOXKlXoNsNqIPS51BERERCahXMnNo0ePYG9vDwDYv38/hg8fDrlcjm7duiE2NlavARIRERHpolzJTbNmzbB9+3bEx8fjv//+w4svvggASEpKgoODg14DJCIiItJFuZKbefPm4cMPP4SHhwe6du0KX19fAKpanE6dOuk1wKqoZ3MXqUMgIiKqtso1FPyVV17Bc889h/v374tz3ABA3759MWzYML0FV1VZmnGxdSIiIqmUK7kBADc3N7i5uYmrgzdo0KDaT+BHRERE0itXFYNSqcSiRYvg6OiIRo0aoVGjRnBycsJnn30GpVKp7xirHK4LTkREJJ1y1dzMmTMHP//8MxYvXowePXoAAI4fP44FCxYgNzcXX3zxhV6DJCIiIiqrciU3GzduxLp168TVwAGgQ4cOqF+/PqZOnVrtk5tO7k44dC1J6jCIiIiqpXI1S6WmpqJVq1Ya21u1aoXU1NQKB1XVta3P4fBERERSKVdy4+npie+//15j+/fff48OHTpUOKiqTmCnGyIiIsmUq1lqyZIlGDRoEA4ePCjOcRMWFob4+Hjs2bNHrwFWRUxuiIiIpFOumptevXrh+vXrGDZsGNLS0pCWlobhw4fj8uXL2LRpk75jrHLa1XeUOgQiIqJqSyYI+qtniIiIQOfOnaFQKPR1Sr3LyMiAo6Mj0tPTDbpUhMes3WqvY6zHlH7QgnQDRUNERFS16fL9zal0jWS3ghMcEhERGQOTGyMJVzaTOgQiIqJqgcmNkSQLTlKHQEREVC3oNFpq+PDhJe5PS0urSCwmbaeyO1bgB6nDICIiMnk6JTeOjiWPAnJ0dMS4ceMqFJCpUpahkuzq/Qy0rssJAImIiCpCp+Rmw4YNhoqDAAz49hhiFg+SOgwiIqIqjX1uiIiIyKQwuanEFEpOdUxERKQrJjeVVOjNFLSetw9/nomXOhQiIqIqhclNJdJUdld8PvmXs8gvVOKjfy5KGBEREVHVw+TGQJrXsdP5mGCrmQaIhIiIqHphcmMgMpnUERAREVVPTG4MpKJ9gfW3nCkREVH1wuTGQOo52UgdAhERUbXE5MZAGtZkckNERCQFJjcGwmYlIiIiaTC5ISIiIpPC5MZAKlpxI1T4DERERNUTkxsDMavgWHA2axEREZUPkxsDeeeFZlKHQEREVC0xuTGQOg7WGtum5r8rQSRERETVC5MbI9qj7FbmskVbpQoUSv0HQ0REZKIqRXKzatUqeHh4wNraGj4+Pjh9+nSxZdeuXYuePXvC2dkZzs7O8PPzK7G8lHq3rK3zMTeTMgEA+YVPE5qXV4XqLSYiIiJTJ3lys2XLFgQEBGD+/Pk4f/48PD094e/vj6SkJK3lQ0JCMHr0aBw+fBhhYWFwd3fHiy++iLt372otL6Xy9LvxW35UY9vlexn6CIeIiKhakDy5Wb58OSZPnoyJEyeiTZs2WLNmDWxtbbF+/Xqt5X/77TdMnToVHTt2RKtWrbBu3ToolUoEBwcbOfLSlbc16e1fzuo3ECIiompE0uQmPz8f586dg5+fn7hNLpfDz88PYWFhZTrHo0ePUFBQgJo1a2rdn5eXh4yMDLWHsVhblO/27r+SqOdIiIiIqg9Jk5uUlBQoFAq4urqqbXd1dUVCQkKZzvHxxx+jXr16aglSUYGBgXB0dBQf7u7uFY67rNrXdzTatYiIiEhF8mapili8eDE2b96Mbdu2wdpac+g1AMyePRvp6eniIz4+3mjxySo4kR8RERHpzlzKi7u4uMDMzAyJierNMImJiXBzcyvx2KVLl2Lx4sU4ePAgOnToUGw5KysrWFlZ6SVeIiIiqvwkrbmxtLSEl5eXWmfgJ52DfX19iz1uyZIl+Oyzz7Bv3z54e3sbI1QiIiKqIiStuQGAgIAAjB8/Ht7e3ujatStWrFiB7OxsTJw4EQAwbtw41K9fH4GBgQCAr776CvPmzcPvv/8ODw8PsW+OnZ0d7OzsJHsf+iMAYHMWERFReUme3IwaNQrJycmYN28eEhIS0LFjR+zbt0/sZBwXFwe5/GkF0+rVq5Gfn49XXnlF7Tzz58/HggULjBm6QQyUn9JpJmMiIiJSJ3lyAwDTp0/H9OnTte4LCQlRex0TE2P4gCTUSKZ98kIiIiIqmyo9WoqIiIjoWUxuKhmh9CJERERUAiY3Juh6YiY2hEZzNXEiIqqWKkWfm+rkoWAHZ1mWQa/x4jeqxTcVSgFv9Wxi0GsRERFVNqy5MbL8UvLJWRab4S27ppdrRd5N18t5iIiIqhImN0aWIGhf4LOov60WaT82PRfrj0cjM7dA32ERERGZDCY3RvZOwTvlPvbVH09g0a4rmLPtUpnKC+ydTERE1RCTGwPzbuSs9jpOcC2mZOniU3MAACFRnAuHiIioOExuDCzoza56OU9ugUIv5yEiIjJ1TG4MzM5KPwPSAv4M1/kYtkoREVF1xOSmitgTmSA+z8gtBAAolQJO3X6A7LxCqcIiIiKqdJjcVFG5BQoEnYjBqJ9OYsy6U1rLCOxRTERE1RCTGyPYOb2H3s+ZkVOAP8/GAwAi4tP0fn4iIqKqismNEXRo4KT/k8qAawmZ+j8vERFRFcfkpoqKffCo1DJslCIiouqIyU0V9eqaMLXXsQ+ysfFEDIeMExFRtceFM41k5ehOePePCwCAKGUDtJTfKbG8OQpRqMOPp9fXIQCApMzcUsumZOUhPacATWvblfn8REREVQVrboxkiGc9ncpvtZxfruucjk59+qKYdinvzw+i77IjuJuWU65rEBERVWZMbiTwQ+GQUst0kEeX69xnYh6WuexlrhpOREQmiMmNEfVpWRsAECk00flYSxTAXZao75CIiIhMDpMbI3KuYVnuY3dYzsUxq/fRRXatzMcIHC9FRETVEJMbY6pArtFarpqw72WzUD0FA8hkMr2di4iIqLJgcmNEbo7WAAABxkkq9kQmoFChNMq1iIiIKgsmN0bUqq6DTuU7ym5W+JrfH356jofZ+bidnCW+Zr0NERGZIiY3RvRS+7o6ld9uNa/C1zx1++nQ8E6fHcALy45U+JxERESVGZMbI5LLZajvZIOHgvEmz2OnYiIiqm44Q7GRbZ/WAydupQDbjXO9mJTS16ACgMg76XCxt0RdRxsDR0RERGRYrLkxstr2VhjasX6Zyy+1WIOKDLNKyMhF6M0URN4pfsK+m0lZGPz9cfgGHir3dYiIiCoL1txUcq+YHcWPhS+Jr8uT5oxdd0rr9icjwSPi08pxViIiosqJNTdVgCUKpQ6BiIioymByQ2q1QYeucYkHIiKq2pjcVAmGGfGkbYLiN4POGuRaRERExsLkpgpwlmWVXoiIiIgAMLmpEn61DDTIeWWP5ygWBM6FQ0REpoOjpaqxR/kKzPrnIrLzFRr7bidnwc7KHHUcrCWIjIiIqPyY3EjlhbnAoc91Pkyfi27+EHITl+9laGxPyswVl2mIWTxIb9cjIiIyBjZLSaXdK1JHoDWxAYAbiezjQ0REVReTG6nUbCx1BMVae+y21CEQERGVG5Mb0hASlSw+f5CVh/jU4tenKlAooVSyQzIREVUeTG6oRF6fH0TPJYfx59l4jX25BQp4f34QQ1YdlyAyIiIi7ZjcUJl89PdFjW0X76QjPacAl+5q77tDREQkBSY3VG6cH4eIiCojJjdVjD6HgpfHrov38MXuK+xnQ0RElRbnuZHS6/8Av47Q6RCpU4rpv18AAHR0d8bNpKdDxn8Ji8GFuDQsfdUTZnJpEzAiIqremNxIyaGB1BHoZNDKY+LzmX9H4FGRmY3n7bgMAHixjSsGtK9r9NiIiIieYLOUlASl1BHopOikf4+0LNkAAJm5hQCAQj0MEf/24A18tutKhc5BRETVD5MbKQnaE4SqLCO3AAUKJXouOYxhP4SW+zyCIOCbg9fx8/FoxD0ofp4dIiKiZzG5kVIVq7kpi893X8WO8Hu4n56LiDvp2HQyFtN/P48CRfnf65azcXqMkIiITB2TGylZOUgdgUFsOhkrPv90+yXsungf/0bcK/GYo9eTMfqnk4h9kK2xb9XhW9h98T42n2aSQ0REpWNyI6VKvL5URWgbLPWkL44gCHjtpzBMCjqjtn/c+tMIu/0A724O13rOab+fx6ytkbiXlqPvcImIyMRwtFQVI/U8N2VRUoRxqY9w8nYqACCvUAErczO1/SmZeSWeOyO3APVgU9EQiYjIhLHmhvROJtNMb57MZlx0AJWsCiRqRERU9TC5qWLqyx5IHUKpCrV0Hl7w7xVExKepLdmgJQcqFVd8ICKi0jC5qWKcZZlSh1CqiDvpWrcPXRWKs7EPxdfacpuHj/Jx4mZKuZKYMzGpuHqfi3gSEVV3TG6k9sKnOhW3RIGBAjGOoquLa5vj71G+AmPWncK2C3d1Om9iRi5eXROGAd8eK70wERGZNCY3UmveT6fiHeTRBgrE+Ib9EIp1x25rnQPng78itB5TXI3OnYccRUVERCocLUWSuXwvA5fvZRS7lAMREVF5MLkhyS0/cL1Cx5+OTsWuiyVPEkhERNUHk5sqyAFZyICd1GFIQoBmu9TIH8MkiISIiCor9rmpgi5avw1P2U2pw5DE3+fuAADyC5XYFBaD28lZGmV2hOvWGZmIiEwLkxupubQo12GTzPfqOZCqYUNoDHILFFh3/DY+3XEZLyw7olHmvc3hWpMeIiKqHpjcSM2CSwnoqlApYMeFkvvY3E/PLXH//ssJWLz3GpTaxqMTEVGVxj43VZgFCtFZdgPnheYoqEY/yrsPcxCVWLHJDN/edA4A0L6+IwZ1qKuPsIiIqJKQvOZm1apV8PDwgLW1NXx8fHD69Oliy16+fBkjRoyAh4cHZDIZVqxYYbxAKxkzKLDQPAhbrD7Dl+brpA7HqM7EpOrtXIkZT2t4EtJzkZ7zdJLE9EcFWHfstloZIiKq/CRNbrZs2YKAgADMnz8f58+fh6enJ/z9/ZGUlKS1/KNHj9CkSRMsXrwYbm5uRo62cukjj8AY80MAgFfNj0ocjXEJelxg6smZHmTloVtgMDwX7sf2x7Mjz/w7Ap/vvooxa0/q7XpERGR4kiY3y5cvx+TJkzFx4kS0adMGa9asga2tLdavX6+1fJcuXfD111/jtddeg5WVlZGjrVwsUCh1CJJZ8O+VMpVLzc7Hp9svodWne7HqcMmjy64UWZNqxpZwAMCha6ok+1ZyttZjohIy8dPRW8gr5CSERESViWQdNfLz83Hu3DnMnj1b3CaXy+Hn54ewMP3NW5KXl4e8vDzxdUYGF1as6hRl7AT88T8XceBKIgDg6/+iMK1PM40yFakF8l+hqjErUAhaz01ERNKQrOYmJSUFCoUCrq6uattdXV2RkJCgt+sEBgbC0dFRfLi7u+vt3FKykLG2oCSZuQViYlMWsmfWKD98LQkybcuWaxFZzCroAPAwOx+5BfxZEREZk+Qdig1t9uzZSE9PFx/x8fFSh6TJc4zUEZicKb+eL3PZg1cS8frPp9S2TQw6U+EYUrPz0emzA/D+/GCFz0VERGUnWbOUi4sLzMzMkJio/td1YmKiXjsLW1lZVf7+OdaOUkdQrYTdeiA+/3z31TId8/muK5jQwwNf7L4KpSBgzetepR4THv8QAJCVV337RxERSUGy5MbS0hJeXl4IDg7Gyy+/DABQKpUIDg7G9OnTpQpLIhUf/bPxza5wc7AW+4GQppZz9yKvUFnm8qqmKtXPZt3xaGwPv4uUrHwAEP8FgH2X9deMSkREFSfpzG8BAQEYP348vL290bVrV6xYsQLZ2dmYOHEiAGDcuHGoX78+AgMDAag6IV+5ckV8fvfuXYSHh8POzg7NmlXvDp29WtQGALjYWap98dJTuiQ22hS9r0VHVxVVqFDi0r0MtKvnoNGPh4iIjEPS5GbUqFFITk7GvHnzkJCQgI4dO2Lfvn1iJ+O4uDjI5U+7Bd27dw+dOnUSXy9duhRLly5Fr169EBISYuzwK5eCHMDCBsc/fgFZeYXIzitEr69DxN0WKMQyi9U4rmyHPxV9pIuzCslXFJ8MjV+vfbLJz3ZdwcawWIz1aQi/Nq5ayxARkWFJPmf/9OnTi22GejZh8fDw0OsEbiZl8xjgjW2wtjCDtYUZsp/p5/GK2REMMQvDELMwJjcGtDEsFgDw26k49NNjchP34BG2nI3DxB6N4WKn3ocsIj4NjjYW8HCpobfrERFVZZInNwTArX3Fz3HrUIm7HaF9IjrSH0NO5vfyD6FIzc7HxTvp2DTJR9x+Ny0HQ1eFAgBiFg8y2PWJiKoSkx8KXiXUbCJ1BKQHPx25rfZapmWinJtJWXhr4xlcvJOm04rkqdmq/j7Prqt1MylLo+y6Y7fRc8khHL6mfRkTIiJTx5qbyoBNbSYh4pnJ/HLynzYN9l9xFF6NnHHkejLuPMzBwauqxOPyQn/UsDLHw8fJi3MNS52u+Wz6dOluuji8fWLQGdbmEFG1xJobE1XfyQZ17Cv5/D4mruhEgtcSMvHbqTjceZijVua/ywkoUCjR6bMD6PTZAeQXKqFQCvjvcoLW1cjlpUybnJyZV+J+bSLi07TWABERVVWsuakU9F9zY24mR+isF7Dtwl3ceZgDj6v2QGrpx1H5nIt9iINXy77cwxOFSgEZOQXi6/Qc1bIRn2yLBACcmeOH2kWS1KKpTVRCJi7eSVM/oY6jz5Myc9lnh4hMDmtuKgMDNUtZmMkx0tsdAf1a4OVO9Q1yDVIZsfpEuY776O+LuHj3aXOWQikgJOppX5lFu9RXQM/OVyAoNBqJGbnwX3EUS/dfV9tfUm6TV6jQ6OcTn5pTTGkioqqLyU01IS/yrXfziwG4tNBfumBIzcQNT9exWrLvGk5FP61i09Y0teDfK/D5Mlhju0IpFNu8lJOvQMeFB/DSd8fVtpdlcVBBEDBl0zks/Pey2nZDjg4jIqoIJjeVgnE7FJubyWFnpd4iGT6vn1FjIO22XriL9CLNVKejy96W2PSTPRprZf12SjXvzvm4h8gpUBQ7s3JJIu+mY9/lBGwIjRG37b+cgJZz92FDaLTO5yMiMjQmN5WBXJquT0Vrc5xsdRulQ8bz7ISMupiz7RKuJWhPaHZdvIcLcWmlnqNAoZl8v/PHBQDAwn+vaOwjIpIak5vKwN0HaPqCgS+i2f6w5X++aOxSA7+82dXA16aKaDv/vwodf+p2KsauO6W27VpCBqb/fgGfPdOn5+r9DLy/JRxxDx5V6JpERFJiclMZyM2AN7YZ/bJdPGri8Ie98fzjRTdf79bQ6DGQ4c3fqd5XZuG/l7Ej/J5GuYj4NAz49hi2XbiLyb+cRXh8Gpbsu4bcgqd9axRKAQqlUOwipOmPCjBi9QlsOhmr3zfx7HVyCnAzKdOg1yCiqotDwauzlBvAxT8B36mAjTNsLZ9+HA5/2BsZOQXiMGEyHUX7zhRV9GcdlZiJlx+/Ltp0tWDnZSifGd2XkpUnrne1KuQmzsU+xLnYh3ijWyPM2RaJszEPsWN6D1hbmOntPXT54iDyC5XYN6MnWrk56O28RGQaWHNTmRi79uaHbsDRJcCuAI1djV1qwNPdSWO7XAa0crM3QnBUWdwoUkOy6WQsfjsVp7Y/Ij4N1xMzkVugQNYz/YN+OxWHqMRM/Hc5QeO8uiyCKwgCfgmLwYlbKQCA/Mc1R8dvpJT5HERUfTC5qUyavgDYuZX/eKUC+G8OcG13Gcs//iK6c6bkckV41KqBfTOex3DOm1NtpGTll7h/0sazePGbo2gzbx8KFdqbq56t7Vl+4Dq6fHEQd9O0z7Nz6W46Zmy+gPhUVd+fsNsPMG/HZYxZe0qjbOjNFBy7kVyWt2JwgiBg8i9n8X+/npM6FKJqjclNZdO8AkOyf+oFhH0PbB6j23GPv3g8atUotohf6zrwbVILP77hBQD4YpgeVjInk6IUgLRHT4exv7XxrPhcEFRLQ+yJvI97aTlYGXwDKVn56LFYtZp9oUKJPZH38ejxelwvfXcc28PvYdrv53Hpbjr+PntHPFdG7tNr5BUqMXbdKbzx82lkPt6elJmLlKw8sXbHmJIy83DgSiL2XkoQ4yEi42Ofm8qm/2LgwqbyHZsQWc6LqpKbkd4NkJSZC98mtcQ9b3RrhINXE7FsZEc42liI283kOs7zT9VO0eUoBAEYuPKY1rWv4h48wtwdl3D0uqr2ZUJ3D3HfxTvpGhMP/lGkWSyvSGfnrLxCKJQCun6hmuDQxc4SZ+b4QSaTQRAE/HX2Dlq42aOjluZWfVHosNI7ERkOa24qGys7YNRvklza3EyOGX4t4FMkufns5XY4MesFtcQGACzN+dEhTfuvFL++VnGLep6KfiAmNgAQdCKmxGtk52ufGfl+ei6WH3i6HEVKVj6e5BrHb6bgo38u4uVVoUh7lI+CYprPnlAqBbVRYsVZvPcaBn57TKxxKprayMow/fP5uIeY+VcEUrJ0X/CUiIrHb6jKyNiT+mXcBb7tCERs0bq7uF/S3o2cDRgUmZInC4FqM/Pvizqd65ewGPH5ykM3xefDfziBX8LUh6A3/WQP5u+4hDd+Pi1u67joAF785igAYPn+KHjM2o0d4XfVjntlzQm0+nQfkjPzNNbjKmrNkVu4cj8D/5xXHV+0k/TCnZdL7TQ9/IcT+OvcHczddqnEckSkGyY3lZGVXcXPEX0MuPpv2RflfBgNbHtb9VypAG4GAzlpJR7yx9vdMHdQ64rFSdVCcfPilEfRfj1lsTFMc86d6JRsCIIgJkfvbQ5HVMLTUWHnHw9/7/LFQYxYo31R1KI1O+mPVJ2ui/53++vcHUTcSX/2MK1up2hfE6y8bidnocfiQ9hUJBEkqk6Y3FRKeujPsvElYMvrwOVyDC8/tQb4dTjw84slFrMwk6O+k43Wfe/2ba77dYmM6Mejt9Ve+684iqGrQvHR3xFq2y/EpeH1dacwb8clFCiUmLH5An49Gau2TtejYprKyrp0hg6j4ksVk5KNF5Ydwd20HHy643LpB+joxK0UjP7pZLGLtJJufjsVaxJrtOkytYMxMLmplPT4IYn4Q/djIv9S/ZsSVWrR2vZWWrcP8ayn+3WJjGjx3msa2yLi0/BnkZFZTxy/mYJfwmLRffEhbA+/h7nbL2H4D09rdA5eTYTPlwfRc8lhteM+3V625qYbSVm4fE+zlqdAoSz2S2PfpQR4zNqtcdyHf0VoLa8vY9aeQtjtBxzurgd5hQrM2XYJC/+9gh3hd7Fsf5QkndKP3Uiu0JIrW87EocsXwVo/w1JhcmPqFCXPUVJRXo2c8eGLLfD9mE541asBAODzl9uhae0aGPxMgnPg/ecx3reR2rZuTWpi73s98dMbXmhUy9agsRJVVHGdoq8nZiExQ3Pf7ZRsfLnnKtJzCvD+lnB4zNqNVp/uFefvKWrQSvVRYTn5CnT54iBG/XhS6zWnPE4uBq08rvaFmPqo7P/nFWXsOK1NUjH3oqjK9tf8E9cSMvD9oRvIKabGzViK/tze2xyO7w7dxLYLd0s4Qv/OxqTijZ9P4/mvD5deuBgf/xOJlKw8BGwxbGKtCyY3pu52iEFPL5PJMP2F5nipQz18/aonYhYPwuvdGkEmk+G70Z2wfVoPsWxzV3ssHNpO7fjNb/uidV0HvNjWDavGdDZorERS+OnobXgu3C9+aeUWKNFzyWGtfyl/vuuKmGycjH6AtEcFOB2Til0Xn64FdvhaEob/oL4syvTfzyM9R9UXqaRG7Ut303E2JlV8/fKqULT6dB9O3n6AAd8ew+GopDK/r9ISlw//ikC/b45qJE+CIGD21ov4+bh0TTH9VxzD0v3X8W3wjXIdLwgClh+4rnXm7Wc9zM7H3sj7yCssWyJ156FxF609F/tQb+cqVBp/bqniMLmpjCrpXzvloe0XbXHLN1iY8eNI1Ye2v5TXHY/Gm0FnkP6oAPsin35xTv/9gvh8YtAZscPzE3svJWDQymMAih/deDYmFS99dxyvrAkTk5jIu6pmhNd+Oomr9zMwccMZhN16AKVSwKx/LmLjiRicj3uI3l8fxtmYVKRmP60Vyi1U4nBUktiv6HZyFpbtj0La45qjv8/dwc2kLBy6pp4wnbydij9Ox+OzXVfw9X/XSm3KSH9UoNbZe8uZOPRYfAjXEzOhVAo4HZ2qsexHWa05ckscxq+LkKhkrAy+gf9tOoer9zPwICsP6TkFWqcYGL32JP7vt/NqP8PKpCytYHsi7+PfCM3Fdp9Vmb65OIkfGZSNpeZiiWvHeWPp/ihM7tlEbXsLVzsM8ayHnWX4T0Rkqk7cegDPRfs1th+9nqyRKBR152EOPGbtRrM66qMtvz90A7aW5li064q4beKGMwj5sLfW84xeexK9WtTGkevqS1q8siZM7XV+oRITN6iWbgmb/QL6f3sM+YVK3E7OxqqxT2thl+2PwsD2dQEAv56Mxdwi/ZBWHb6FVYdvIWbxoGLfV9F7MaxTfbEG7KO/L2J45/qYt+MyXB2scOoTv2LP8URUQiaenX80YEsE1jyeeb2s7qfnis8HfHtMfF7P0RonZvdVK3vtcWJ24Jk5oPZG3oetVfFfwWdiUpGUkYeaNSzh1chZnFssNTsfNhZmGr9bkzJyUcfBWqf3AagvjVKoUCLiTho6NHCChZkcl+6qT6LZq2VtOFhbICg0Gn+cjsefU3zV5kDLlbiZrygmN9VBoZY2+PslzS2iv9mHW7jaY0J3D7WOx+41bfHta500ryqTYeXoThjf3QNTfzuntQ8DUXU1bv3p0gsBGqOYlu6/rrVc76UhxZ7j2cSmNL6Bh8Tn5+PUmzluJWcDACLvpKslNkXN2RapdUmXZzvXFu2PcjctB/MejwZLzMhDRm4BHKwtsGDnZUQlZKJPq9poV88R3Zu54IeQm1gZfAO5BZo1K/ueaVraFBaDnRH3sG58FzjaWCD4aiK2nInH4hEdULOGJQDNtdKeuJeeiwKFElEJmXjpu+N4r5hRozeTsvB/v53Xuu+JV4skk2N8GuLLYe0RfDURkx4va7JqTGcM6qBKGpcfuI6VwTcwe0Ar/K9XU63nO3ErBSsO3sCMvs3RvoEjfj8Vh4Ht66o1L3626wo2hsWihqUZXOytEPtM02luvkJ1j/9VJcqeC/erJab3iiR9UmM7QHXweW3NbZf+NtrlFwxpi2l9mpW5vFcjZ42/whq71MDhYv7SJKLK4356LoZ+r945WqkUMPiZbUU9WWl+24U7WBl8Q1yAtaSZpJ/t3L3heAyO3UhG0IkYhN1+gC/3XMOYdaqFVpfsi9Ka2Dzx55l4AEBIVBI+3XEZZ2Ie4scjtxCf+giTNp7F/iuJWPjv02H1JY1oaj5nr1jbUVyfntvJug2j//1UHO48fCQmNgAw7ffzuJaQgYNXErHy8XUCi4wADL6aiJgUVWJ54lYKxqw9hdPRqRiz7hTm77yMwL3XMPj748gs0qT3ZE6o7HyFRmLzxLPv/dk+VU+aC6XGmpvKqF5H/Z/zYYz+z2lgu999Dsv2X4etpRk+8m+FhrVscTDgefgtPyp1aERUgmcnL2zyyZ5Sj7mWkIH3H4+2WX7gOt55oRkKFGX/kvzmoPYaqsSM0msTPvrnIkZ2cceEx81sALA78j5+CLklvt4Rfg87wu8hcHh77L9SekfikpT0vlYcvIEVBzWTooA/NUci9V9xTGPb0FWhiIhPE1/f/GIAFv17Ra1M8FVV82baowKcuPmgrGHjj9PxGve51af71F4/mf076vP+sDLX7JZgLDKhso7VM5CMjAw4OjoiPT0dDg4OUodTvPxsIOgl4F7JVZflMiMSOLMOCP1Wc9+CdOCnPk+vu6DyzFsAADeTMotNbiY911jSERhERCWxsTCDt4czjt1IkToUg1s7zhv92rjq9Zy6fH+zWaqysqwBvBVsmHOvaF++mYsrgaKpuK2lGYZ2VM2ls3J0J3z6UhtcXdRfosiIiEqWU6CoFokNIP0cR0xuKjO5AX88aXHF7yvDasZScbK1FJ+Hz3sRK0Z1xOk5fcUZkW0szbBhYheN41q42uHaZ/0xvFN9o8VKRFRd3UvLkfT67HNDVUpteyv89IYXbC3NxaGRdezVhz/2aVkH0YEDcfleBo7fTEENK3OM9G4AK3Mz+Ldzw9YSZgDd9c5zAKA2/JGIiHSz4N8rmNCjsWTXZ3JDVc6Lbd1KLSOTydCuviPa1XdUP7aNK9a83hl/n7uLg1dV807sfa8nHmbno0vjmrAwk0uytgsREekPkxuqVmQyGfq3q4v+7eoi9GYKzOUytK6r3jHN7NlZvh57368FaliZoXfLOvBbfsQY4RIRUTmwzw3pX8Y9IGKL9skDK5EezVzg06SW1n0b3+yKlzrUxQ+PZ1r96Q0vvOfXHG/1bKIxA+zqsZprYs0e0AoXPu2HxcM1JyYjIiLDYs1NZSczAwRjT2ldwQ7F33cF8jOB9Hjg+Q/1E5KR9WpRG71aqCY/LGlqeADo2UJ9ksQxPg3FWULNuV4WEZHR8TdvZffa71JHoLv8x4vc3TTQUPZKxs7KHMEf9MI3ozzxRrdGmDWgVYnlj33UB9GBA3EwoJeRIiQiql6Y3FR2LfsD714APjXm3Ah66lArM92P17uP14w5MesFAEDT2nYY1qkBPnu5HRysny4k18LVTuNY95q2kMlkaFbHDv/8X3csH+lZ5uvum9ETfVvVqWD0RESmzXS/fUxJzSaAmUXp5SqbSjxfTkUF9GuBmMWDUM/JpsRyHRo44cc3vDDpOdWQyLE+DdX2ezVyxvDODfDFsHYY1KEubnwxAN+MeprsHP6wN9aO8wYAvN6tIVq5OcDbo6ae3w0RkWlhn5uqxKUlkBIldRRlZ8LJjS7827rBv60bJvdsAlcHK61lxvo0wlifRgCAIZ71ER6Xhi6Na6KxSw00dqmh1u9n0nONYWdlhh7NXDDk+1A0qV0DFx+v5dPFwxlxqY/QrUktvOLVAAeuJOKXx4vhPWFnZY6sIovlERGZGiY3VcnUk8DJH4D9cwx8IX0lJUxuinJztC69EFRD0RcObVfsfktzOd7w9QAARC54EQDguXA/MnILMbFHYwxo5wbZ48SyZ/Pa+PSlNpDLZGpD3IOvJqqtMAwA/dq44sCVRF3eEhFRpcTkpiqRy4Hu042Q3BSRkwbYOD19fesQ4OgOuDQv/VgT7nNTWTxJYkJm9kFUQia6NakpbnvCQsuIrb6tXXF2rh8i76bDycYCnRo6Iz2nAJ4L9+scQ9DELmqrKRfVvWktnLhV9lWHiYj0gd8+pC79DvCoyJfR9v97+vxeOLBpGPC9d9nmsGFyYzQ1a1jCt2ktjcSmJC52VujTsg46NXQGADjaWCBi/ov4Y3I3bJigWp9rnG8jdGropHZc0ZV+owMH4vnmT4fCB3/wdATYkhEdsGpMZ3TxcIZvMfMJLX3VE9YW/JwQkX6x5obUfdNW/XXUHiDnIWDjDNyPeLr93AbA538ln4t9bqocRxsL+DZVJSIR81+Eg7U58gqViE7JxoBvjwGA2JcHUNUcyWSqJOfJ6/B5/XDlXga6NakFuVyGv6Z0h1Ip4NvgG/g2+Abq2FvB0cYCc19qg14tauMVrwYAAI9Zu9Vi2fXOc7iRlInzsWnYdPJpv6H1E7zxZpB6k5q+tKvvgEt3MwxybiIyHiY3VLqvPIAF6VAbIp5yowwHMrmpyhxtVCP0rC3M0LquAw4G9EJCei6ea+6CgH4t4Gz7dARf0RojJ1tLdG/monYuuVyG9/u1wPv9WhR7PUszOfIVSgDAz+O9xbXBhnVqgIk9PLDq8C1M7dMUTWvb4bvRnXA+7iE2hMaIx+99rycUSgHvbb4AT3cnnLqdirs6rkw8uEM9JjdEJkAmCEK1WiUwIyMDjo6OSE9Ph4ODQ+kHVEZHvwYOfW7ca9q5ApZ2QOqtp9vmp2mvnVnweLHK5v7A2D9Vz498reoz1PMDg4dKVdPR68l4a+NZfD6sHUZ6u5fpmNPRqVhx8DoWDmmL5q72avsUSgERd9Iw/IcTaF7HDjeSsgAAres6YPPkbrh4Nw1v/Hxa7ZjjH/fBvB2XcehaUrHXHN6pPraF30Vxvzk3vtkVN5OycPxGMm4mZyE+VbcEqyLe6NZIrZaLSEqlze6uK12+v5ncVFWZCYBtLSDuJLDxJWlimJcKyM00tz9JbloMAMZsBrIfAF83UW2bfQewstc8hgiqhKS4hUsrQqkU8EtYDEJvPcC8l9rAvaYtACAnX4Gw2ynwalgTkD2trUrJyoOFXI6T0Q/Qp2Ud/BtxD8v2R6Fn89qY+1Jr3HmYIzbTPevZX+iHo5IwsZgO19q417TRSIh6NnfB2nHeSM8pwPwdl7HvcgI83Z0QEZ8mljGXy3BhXj/YW1tAoRTw8qpQNKpli/f7tUDfZdoXev2of0ss2VeFppegKkXK5IY9+aoqezfVxH5mltLFcDuk5P1PanUURTofKwoMFg5VfYZIbABVs9iEHo2xdpy3mNgAgI2lGV5o5QpHWwsxsQFUna0dbS3g39YNluZyjPBqgBOz++KrVzrA3toCres6IGbxII15i4Z41tO4dp+WdXDry4HYOb0HvBs5Y+vU7jj/aT+M822ErVO748D7z+PighdhY6H6Q2FSD9WEj64OVlj2qif6tqqDNa97wdrCDK4O1lj9emdcWeSP39/ywcIhbXFi1gu4/eVAXFroD/vHs2ObyWX4953n8P2Yzmha2w4xiwdhdFdVbdgMv+bo1aI2pvVpiqm9m2HXO8/B2dYCu999DgsGt4GnuxM+6t9S7T3873nVHyfWFnJc+LQfnB43Sc4a0AobJnSBuVyGju5OOP5xH7XFYns0q4V/pz+HmMWDcDDgeXRo4KjTz83eqvSeE7vffQ5/TfHF/3o10encpQn5sDc6F+lMP71PsxLLLxratsT9z5rQ3QM7pvUoc/luTWpiWp+mOl3jrceThwLQ+Jk+a9UYzQWAS/Je3+YY0M6t2P0flNAEbQysuanq4k4C6/2lu/6CdC3bHv8Ca/US8NpvqlqmZY//Y828DdTQPnKmWA9jgYJHQJ3WFYuVSM9mbL6A7eH3AADrxnnjueYusLbQUptZBrkFCggCYGUux9EbyejQwAk1a+j3jxdBEMo8om7QymO4fC8Dxz/ugwbOthr7H+UXwtZSe/Jx4lYKjkQl44MXW8LS/Onf0PGpj9BzyWEAwMf9W+GrfdfEfStGdYRSEBDwp2rgwuiu7pjWpxn8vzmK7HzV4sGONhZ4sY0rvBo547WuDTXez6fbL2HTyVgM61QfCwa3xR9n4rDuWDSWvtoB6TkFiE99hKX7r2vEG/JhbzSqZatxb349GYu52y+heR07HAjohaGrQhERn4Y/JnfDmZhURKdko3fL2rC1NEe/Nq748cgtBO59+p5Ozu6LmAfZ8GmsmlW88ew94r4ntRpDvz+OiDvpWDKiA4Z3ro9T0akYu+6URowXF7woLu1yNy0H6Y8KkJyVh/HrT2uUXTKiA+ytzTGgfV217XfTcjB3WyQmPdcEr//89BrLXvXECK8G+OfcHaw9dhub3+6GPktD8PCR6o/R9RO8cTr6IdYcedot4WDA82hWxx4KpYDs/EK8sDQEKVn5aF/fEX1b18EMP/0nN2yWKgGTGz17eQ2QFge0fwXY+Q7QcSywY6pqX+vBwKhfgcxEYNnjD/rMW0ANl+LPp82TZKk8iRGRAWXkFmBTWCwGd6iHhrU0E4CqTBAE5BUqy52sFedWchacbCxQy84Km07G4tPtlzCtT1PM9G8FQRAQevMBWrrZo7a9qlZs1j8XsflMPIDyNXM8mwBF3klH0IkY/HP+DgDAo5YtQmb20XqsUingbOxDtKnnADsrcyiVAgqUSliZF39Pridm4sVvjmqN9+r9DLy18Sze79dCHCWYW6BA7INHaOFqB5lMBqVSwNubzqKBsy3mD26Dn49Ho4aVOUZ3bahxLQBY+O9lbAiNwcsd64mJ9tVF/WFjWfLP7Y2fT+HYjRRM6O6BBUM0a506LdovJje3vxwIuVyGtEf52BF+DylZefjgxZJrggyByU0JTC65iQ0DNvSXOgrtWg8BRm0CspKBpY+rdD+8CRxapBpa3m9R2c7zJLl56xDQwMswsRKRJJIyc1HbzqrYGqWDVxLx1i9n4WBtjosL9PeH3JOpBwa2d8MPY/X7eyWvUAFzudxgzaxFKZQCrtzLQJt6Dvjn/B2Yy2UY3rlBqcdl5xXidHQqujerpTVZ+2rfNawOuQWfxjWx5X++hghdZ7p8f3MoeFVX2/jZc5k9+WVV9JfWg5vA+V9Uz8ua3BCRyapjX/KyJH1b18FfU3zRtLadXq/buq4Drt7PwPBOpScCuiqpZkffzOQytH/cl6msowwBoIaVOfq0qlPs/oB+LdCtSS14NXKucIxSYHJT1dnWBMysAEWe1JFoEmcoLpLcFFZkWGwxlYwpN4HsZKBR5fjrgoj0RyaToYtHTb2fd9vU7ohLfYQWrhy9qY2FmRy9WtQuvWAlxdFSpuC9cKkj0O7h4/k2ctOebhOUxZd/lAoUlJD8FNeC+r2XqmnuwS3t+4mInmFtYcbExoQxuTEFDvWAOQlSR6Hp3nngxPfAtilPtxVdwqGoR6nAksbA0go0syVXYL4OZQlJFxERVSlMbkyFhQ3w+lagzxzA2knqaJ7aPwe4U2SoYnAx/WzuPJ7kLE/L0PIyK2ff+Iz7qkkG/zPiautERGQwTG5MSbO+QK+PgPeKqR2pbJKvAwW5j18U6ZdzdgOweSyQfhc4/GWRA0pJXso78O/EStXioGHfl+94IiKqVNih2BTZOAGv/QFsHi11JCVb1UX176tBqnWrntg1Q/VvwSPg1qGn23MzgLvngHqdVTMdy81V61WJqtWsBkREVAwmN6aq1UBg2E9A0mUg9FupoynZXxMABy3DMYsmNgDw2wjNMmZFpr+vXlM2ERFRMdgsZco8R6nmkukxQ+pISpdxp3zHPTsE/n6EqhNzYR5w+4hqmHhJlArg1mH1bWnxwKkfgfzs8sVU1LXdqjiIiMhoWHNTHfRbCISukDoKw7u+Dwj/TfV8/zOdg986BLg0U/XzaeD9dGLBMz8DyVeflntwC1jnB+SkqkZfDVyqagpzaw9YlDzZmIaM+8DmMarn2tbgIiIig2ByU13U9wbunlU97zgWcG4MRP4FpFRg+HRl8ySx0WbdC+qvB38LeE0Azv6svv27Iivjnv0ZuHkQSIsFmvUDvN8E9n0MjPgZcO/6tFzGfSArEajXUf1cmffL8y6IiKiCuLZUdZKbrlqLqukLgPnj1YafrNtEZWftCHwc+7T2p+g9fGM74NoOSL4GxIUBh794XKaMNTeF+aqmNqvHk4sV5gF3z6tqm8ws9PYWiIiqGl2+vytFn5tVq1bBw8MD1tbW8PHxwenTmku4F/XXX3+hVatWsLa2Rvv27bFnz54Sy9Nj1o5Ay/5PExtAtUo36SY3HVjopOoIfTtEfd+ml1WLhG586WliAwAHF6iXezJpoFIB3DgI7PtEtar6qq5AYAPgYYyqv87ndVSzL+//1FDvhojI5Ehec7NlyxaMGzcOa9asgY+PD1asWIG//voLUVFRqFNHc1GvEydO4Pnnn0dgYCBeeukl/P777/jqq69w/vx5tGvXrtTrVeuam+LcDAZ+HQ7Y1gIePVBte3Uj8Nd4aeMidc1fVNW61W4JWNiqhsrHngCOLQdc2wKp0cD4Hap+RF3fBhwbABl3AbcO6ouXAoCiULXPuZHm9ivbAWUh0GGU5nFERBLR5ftb8uTGx8cHXbp0wfffqyZQUyqVcHd3xzvvvINZs2ZplB81ahSys7Oxa9cucVu3bt3QsWNHrFmzptTrMbkpRmG+qkanMA8ws1R9qaXFAw9uAI16qGoQiPRh5C+qz9vWt0ouV6sZ0HceEHMcOP0TYF8XaNIbSL8D2NUBLm8HWg1STV6ZmQDUaQ0kXgHkZqrEzvxxB3AxQZM9ff4wVrVsiUyuSvIc6gP5WaraTW2/EnPTVfNHPTmPSHhaXiZTTUqpLHjarAiUPEXBs8ljcWXFRWifuZ7OnhwjQO19CMpizlfcNSpzbwYm5JWCjTPQuKdeT6nL97ekHYrz8/Nx7tw5zJ49W9wml8vh5+eHsLAwrceEhYUhICBAbZu/vz+2b9+utXxeXh7y8p4OF05PV/V9yMjIqGD0pujJbMGP75fcEajtDTzKA967DSReVg217jBSNapoQ3/JIqUqbNMbZSt374Z62bx7QMrv6mXCd6geRFS51PNS1STr0ZPv7bLUyUia3KSkpEChUMDV1VVtu6urK65du6b1mISEBK3lExK0LxwZGBiIhQsXamx3d3cvZ9QEvCt1AEREVKmFAO8aZsBKZmYmHB1LPrfJDwWfPXu2Wk2PUqlEamoqatWqBZme+xNkZGTA3d0d8fHxbPLSEe9dxfD+lR/vXcXw/pUf751uBEFAZmYm6tWrV2pZSZMbFxcXmJmZITExUW17YmIi3NzctB7j5uamU3krKytYWVmpbXNycip/0GXg4ODAD2o58d5VDO9f+fHeVQzvX/nx3pVdaTU2T0g6FNzS0hJeXl4IDg4WtymVSgQHB8PX11frMb6+vmrlAeDAgQPFliciIqLqRfJmqYCAAIwfPx7e3t7o2rUrVqxYgezsbEycOBEAMG7cONSvXx+BgYEAgPfeew+9evXCsmXLMGjQIGzevBlnz57FTz/9JOXbICIiokpC8uRm1KhRSE5Oxrx585CQkICOHTti3759YqfhuLg4yOVPK5i6d++O33//HXPnzsUnn3yC5s2bY/v27WWa48bQrKysMH/+fI1mMCod713F8P6VH+9dxfD+lR/vneFIPs8NERERkT5ViuUXiIiIiPSFyQ0RERGZFCY3REREZFKY3BAREZFJYXKjJ6tWrYKHhwesra3h4+OD06dPSx2SwR09ehSDBw9GvXr1IJPJNNb3EgQB8+bNQ926dWFjYwM/Pz/cuHFDrUxqairGjh0LBwcHODk5YdKkScjKylIrc/HiRfTs2RPW1tZwd3fHkiVLNGL566+/0KpVK1hbW6N9+/bYs2eP3t+vPgUGBqJLly6wt7dHnTp18PLLLyMqKkqtTG5uLqZNm4ZatWrBzs4OI0aM0JjAMi4uDoMGDYKtrS3q1KmDmTNnorCwUK1MSEgIOnfuDCsrKzRr1gxBQUEa8VS1z+/q1avRoUMHcfIzX19f7N27V9zPe1d2ixcvhkwmw4wZM8RtvH/FW7BgAWQymdqjVatW4n7eu0pCoArbvHmzYGlpKaxfv164fPmyMHnyZMHJyUlITEyUOjSD2rNnjzBnzhxh69atAgBh27ZtavsXL14sODo6Ctu3bxciIiKEIUOGCI0bNxZycnLEMv379xc8PT2FkydPCseOHROaNWsmjB49Wtyfnp4uuLq6CmPHjhUuXbok/PHHH4KNjY3w448/imVCQ0MFMzMzYcmSJcKVK1eEuXPnChYWFkJkZKTB70F5+fv7Cxs2bBAuXbokhIeHCwMHDhQaNmwoZGVliWWmTJkiuLu7C8HBwcLZs2eFbt26Cd27dxf3FxYWCu3atRP8/PyECxcuCHv27BFcXFyE2bNni2Vu374t2NraCgEBAcKVK1eE7777TjAzMxP27dsnlqmKn9+dO3cKu3fvFq5fvy5ERUUJn3zyiWBhYSFcunRJEATeu7I6ffq04OHhIXTo0EF47733xO28f8WbP3++0LZtW+H+/fviIzk5WdzPe1c5MLnRg65duwrTpk0TXysUCqFevXpCYGCghFEZ17PJjVKpFNzc3ISvv/5a3JaWliZYWVkJf/zxhyAIgnDlyhUBgHDmzBmxzN69ewWZTCbcvXtXEARB+OGHHwRnZ2chLy9PLPPxxx8LLVu2FF+PHDlSGDRokFo8Pj4+wv/+9z+9vkdDSkpKEgAIR44cEQRBda8sLCyEv/76Syxz9epVAYAQFhYmCIIquZTL5UJCQoJYZvXq1YKDg4N4vz766COhbdu2atcaNWqU4O/vL742lc+vs7OzsG7dOt67MsrMzBSaN28uHDhwQOjVq5eY3PD+lWz+/PmCp6en1n28d5UHm6UqKD8/H+fOnYOfn5+4TS6Xw8/PD2FhYRJGJq3o6GgkJCSo3RdHR0f4+PiI9yUsLAxOTk7w9vYWy/j5+UEul+PUqVNimeeffx6WlpZiGX9/f0RFReHhw4dimaLXeVKmKt3/9PR0AEDNmjUBAOfOnUNBQYHa+2rVqhUaNmyodv/at28vTngJqN53RkYGLl++LJYp6d6YwudXoVBg8+bNyM7Ohq+vL+9dGU2bNg2DBg3SeI+8f6W7ceMG6tWrhyZNmmDs2LGIi4sDwHtXmTC5qaCUlBQoFAq1DyoAuLq6IiEhQaKopPfkvZd0XxISElCnTh21/ebm5qhZs6ZaGW3nKHqN4spUlfuvVCoxY8YM9OjRQ5xpOyEhAZaWlhqLvD57/8p7bzIyMpCTk1OlP7+RkZGws7ODlZUVpkyZgm3btqFNmza8d2WwefNmnD9/XlzWpijev5L5+PggKCgI+/btw+rVqxEdHY2ePXsiMzOT964SkXz5BaLqbtq0abh06RKOHz8udShVSsuWLREeHo709HT8/fffGD9+PI4cOSJ1WJVefHw83nvvPRw4cADW1tZSh1PlDBgwQHzeoUMH+Pj4oFGjRvjzzz9hY2MjYWRUFGtuKsjFxQVmZmYaveETExPh5uYmUVTSe/LeS7ovbm5uSEpKUttfWFiI1NRUtTLazlH0GsWVqQr3f/r06di1axcOHz6MBg0aiNvd3NyQn5+PtLQ0tfLP3r/y3hsHBwfY2NhU6c+vpaUlmjVrBi8vLwQGBsLT0xPffvst710pzp07h6SkJHTu3Bnm5uYwNzfHkSNHsHLlSpibm8PV1ZX3TwdOTk5o0aIFbt68yc9eJcLkpoIsLS3h5eWF4OBgcZtSqURwcDB8fX0ljExajRs3hpubm9p9ycjIwKlTp8T74uvri7S0NJw7d04sc+jQISiVSvj4+Ihljh49ioKCArHMgQMH0LJlSzg7O4tlil7nSZnKfP8FQcD06dOxbds2HDp0CI0bN1bb7+XlBQsLC7X3FRUVhbi4OLX7FxkZqZYgHjhwAA4ODmjTpo1YpqR7Y0qfX6VSiby8PN67UvTt2xeRkZEIDw8XH97e3hg7dqz4nPev7LKysnDr1i3UrVuXn73KROoezaZg8+bNgpWVlRAUFCRcuXJFePvttwUnJye13vCmKDMzU7hw4YJw4cIFAYCwfPly4cKFC0JsbKwgCKqh4E5OTsKOHTuEixcvCkOHDtU6FLxTp07CqVOnhOPHjwvNmzdXGwqelpYmuLq6Cm+88YZw6dIlYfPmzYKtra3GUHBzc3Nh6dKlwtWrV4X58+dX+qHg//d//yc4OjoKISEhakNKHz16JJaZMmWK0LBhQ+HQoUPC2bNnBV9fX8HX11fc/2RI6YsvviiEh4cL+/btE2rXrq11SOnMmTOFq1evCqtWrdI6pLSqfX5nzZolHDlyRIiOjhYuXrwozJo1S5DJZML+/fsFQeC901XR0VKCwPtXkg8++EAICQkRoqOjhdDQUMHPz09wcXERkpKSBEHgvassmNzoyXfffSc0bNhQsLS0FLp27SqcPHlS6pAM7vDhwwIAjcf48eMFQVANB//0008FV1dXwcrKSujbt68QFRWldo4HDx4Io0ePFuzs7AQHBwdh4sSJQmZmplqZiIgI4bnnnhOsrKyE+vXrC4sXL9aI5c8//xRatGghWFpaCm3bthV2795tsPetD9ruGwBhw4YNYpmcnBxh6tSpgrOzs2BraysMGzZMuH//vtp5YmJihAEDBgg2NjaCi4uL8MEHHwgFBQVqZQ4fPix07NhRsLS0FJo0aaJ2jSeq2uf3zTffFBo1aiRYWloKtWvXFvr27SsmNoLAe6erZ5Mb3r/ijRo1Sqhbt65gaWkp1K9fXxg1apRw8+ZNcT/vXeUgEwRBkKbOiIiIiEj/2OeGiIiITAqTGyIiIjIpTG6IiIjIpDC5ISIiIpPC5IaIiIhMCpMbIiIiMilMboiIiMikMLkhIoPz8PDAihUrylw+JCQEMplMY40eIqKyYHJDRCKZTFbiY8GCBeU675kzZ/D222+XuXz37t1x//59ODo6lut6uli7di08PT1hZ2cHJycndOrUCYGBgeL+CRMm4OWXXzZ4HESkP+ZSB0BElcf9+/fF51u2bMG8efMQFRUlbrOzsxOfC4IAhUIBc/PSf43Url1bpzgsLS2Nsrrx+vXrMWPGDKxcuRK9evVCXl4eLl68iEuXLhn82kRkOKy5ISKRm5ub+HB0dIRMJhNfX7t2Dfb29ti7dy+8vLxgZWWF48eP49atWxg6dChcXV1hZ2eHLl264ODBg2rnfbZZSiaTYd26dRg2bBhsbW3RvHlz7Ny5U9z/bLNUUFAQnJyc8N9//6F169aws7ND//791ZKxwsJCvPvuu3ByckKtWrXw8ccfY/z48SXWuuzcuRMjR47EpEmT0KxZM7Rt2xajR4/GF198AQBYsGABNm7ciB07doi1VyEhIQCA+Ph4jBw5Ek5OTqhZsyaGDh2KmJgY8dxPanwWLlyI2rVrw8HBAVOmTEF+fr5Y5u+//0b79u1hY2ODWrVqwc/PD9nZ2Tr+1IjoWUxuiEgns2bNwuLFi3H16lV06NABWVlZGDhwIIKDg3HhwgX0798fgwcPRlxcXInnWbhwIUaOHImLFy9i4MCBGDt2LFJTU4st/+jRIyxduhSbNm3C0aNHERcXhw8//FDc/9VXX+G3337Dhg0bEBoaioyMDGzfvr3EGNzc3HDy5EnExsZq3f/hhx9i5MiRYiJ1//59dO/eHQUFBfD394e9vT2OHTuG0NBQMeEqmrwEBwfj6tWrCAkJwR9//IGtW7di4cKFAFS1ZKNHj8abb74plhk+fDi43B+RHki7bicRVVYbNmwQHB0dxddPVoHfvn17qce2bdtW+O6778TXjRo1Er755hvxNQBh7ty54uusrCwBgLB37161az18+FCMBYDa6surVq0SXF1dxdeurq7C119/Lb4uLCwUGjZsKAwdOrTYOO/duyd069ZNACC0aNFCGD9+vLBlyxZBoVCIZcaPH69xjk2bNgktW7YUlEqluC0vL0+wsbER/vvvP/G4mjVrCtnZ2WKZ1atXC3Z2doJCoRDOnTsnABBiYmKKjY+Iyoc1N0SkE29vb7XXWVlZ+PDDD9G6dWs4OTnBzs4OV69eLbXmpkOHDuLzGjVqwMHBAUlJScWWt7W1RdOmTcXXdevWFcunp6cjMTERXbt2FfebmZnBy8urxBjq1q2LsLAwREZG4r333kNhYSHGjx+P/v37Q6lUFntcREQEbt68CXt7e9jZ2cHOzg41a9ZEbm4ubt26JZbz9PSEra2t+NrX1xdZWVmIj4+Hp6cn+vbti/bt2+PVV1/F2rVr8fDhwxLjJaKyYYdiItJJjRo11F5/+OGHOHDgAJYuXYpmzZrBxsYGr7zyilrzjDYWFhZqr2UyWYkJhbbygp6acNq1a4d27dph6tSpmDJlCnr27IkjR46gT58+WstnZWXBy8sLv/32m8a+snaeNjMzw4EDB3DixAns378f3333HebMmYNTp06hcePGFXo/RNUda26IqEJCQ0MxYcIEDBs2DO3bt4ebm5tax1pjcHR0hKurK86cOSNuUygUOH/+vM7natOmDQCIHXstLS2hUCjUynTu3Bk3btxAnTp10KxZM7VH0eHrERERyMnJEV+fPHkSdnZ2cHd3B6BK0Hr06IGFCxfiwoULsLS0xLZt23SOmYjUMbkhogpp3rw5tm7divDwcERERGDMmDEl1sAYyjvvvIPAwEDs2LEDUVFReO+99/Dw4UPIZLJij/m///s/fPbZZwgNDUVsbCxOnjyJcePGoXbt2vD19QWgGul18eJFREVFISUlBQUFBRg7dixcXFwwdOhQHDt2DNHR0QgJCcG7776LO3fuiOfPz8/HpEmTcOXKFezZswfz58/H9OnTIZfLcerUKXz55Zc4e/Ys4uLisHXrViQnJ6N169YGv1dEpo7JDRFVyPLly+Hs7Izu3btj8ODB8Pf3R+fOnY0ex8cff4zRo0dj3Lhx8PX1hZ2dHfz9/WFtbV3sMX5+fjh58iReffVVtGjRAiNGjIC1tTWCg4NRq1YtAMDkyZPRsmVLeHt7o3bt2ggNDYWtrS2OHj2Khg0bYvjw4WjdujUmTZqE3NxcODg4iOfv27cvmjdvjueffx6jRo3CkCFDxIkQHRwccPToUQwcOBAtWrTA3LlzsWzZMgwYMMCg94moOpAJ+mq0JiKqRJRKJVq3bo2RI0fis88+M/r1J0yYgLS0tFKHoxOR/rFDMRGZhNjYWOzfv1+cafj7779HdHQ0xowZI3VoRGRkbJYiIpMgl8sRFBSELl26oEePHoiMjMTBgwfZh4WoGmKzFBEREZkU1twQERGRSWFyQ0RERCaFyQ0RERGZFCY3REREZFKY3BAREZFJYXJDREREJoXJDREREZkUJjdERERkUpjcEBERkUn5fwPwiGjOE8TmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_terms_dict['mse'], label='MSE loss')\n",
    "plt.plot(loss_terms_dict['rounding'], label='rounding loss')\n",
    "plt.ylim((0, 0.5))\n",
    "# plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdd3e62ab10>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAklElEQVR4nO3de3RU1f338c9MQoZEknBNQiRILCiVm8oljXipi/ykFK30569FF21Z2FVv8ULxUaEVqI+1QfTnQ0WK1q4KfX4KXiro44WWRi5VAQFBQWwARUjFBBHIhNtAMvv5I8khwz0wc3Zgv19rzTqTczZzvrNX2nzcZ5+zA8YYIwAAAJ8EbRcAAADcQvgAAAC+InwAAABfET4AAICvCB8AAMBXhA8AAOArwgcAAPAV4QMAAPgq2XYBh4tGo9q6davS09MVCARslwMAAE6CMUbV1dXKzc1VMHj8sY1mFz62bt2qvLw822UAAIBTUF5erk6dOh23TbMLH+np6ZLqis/IyLBcDQAAOBnhcFh5eXne3/HjaXbho+FSS0ZGBuEDAIAzzMlMmWDCKQAA8BXhAwAA+IrwAQAAfEX4AAAAviJ8AAAAXxE+AACArwgfAADAV00OH4sXL9Z1112n3NxcBQIBzZ07N+a4MUYTJkxQx44dlZqaqqKiIm3YsCFe9QIAgDNck8PHnj171KdPH02bNu2oxydPnqwnn3xSTz/9tJYtW6ZzzjlHgwcP1v79+0+7WAAAcOZr8hNOhwwZoiFDhhz1mDFGU6ZM0YMPPqjrr79ekvSXv/xF2dnZmjt3rm688cbTqxYAAJzx4jrnY9OmTaqoqFBRUZG3LzMzUwUFBVqyZMlR/00kElE4HI55AQCAs1dcw0dFRYUkKTs7O2Z/dna2d+xwJSUlyszM9F6saAsAwNnN+t0u48aNU1VVlfcqLy9PyHkqw/v1yJvrVPL2pwn5fAAAcHLiGj5ycnIkSZWVlTH7KysrvWOHC4VC3gq2iVzJdnekRs/+c5NeWLYlIZ8PAABOTlzDR35+vnJyclRaWurtC4fDWrZsmQoLC+N5qiZLD9XNrd0dqVE0aqzWAgCAy5p8t8vu3bu1ceNG7+dNmzZp9erVatu2rTp37qzRo0frt7/9rbp166b8/HyNHz9eubm5GjZsWDzrbrK0+vBhjBSpiSo1JclqPQAAuKrJ4WPFihW6+uqrvZ/HjBkjSRo5cqRmzJih+++/X3v27NEtt9yiXbt26fLLL9e8efPUsmXL+FV9CpICAe991DDyAQCALQFjmtdf4nA4rMzMTFVVVcV1/sf+g7XqPn6eJGnNb65RessWcftsAABc15S/39bvdvFLMGbkw2IhAAA4zqHwceh9MxvsAQDAKQ6FD0Y+AABoDpwJH42yBxNOAQCwyKHwEfACCOEDAAB7nAkf0qFLL2QPAADscSx81G0Z+QAAwB6nwkegfuSDCacAANjjVPjwRj5IHwAAWONY+GDOBwAAtjkZPpjzAQCAPU6FD261BQDAPqfCR5AJpwAAWOdY+KjbsrYLAAD2OBY+GPkAAMA2p8JHgAmnAABY51T44AmnAADY51j44DkfAADY5lj4qNsy8gEAgD1OhQ/WdgEAwD6nwkew/tsy8gEAgD1uhQ9vzgfhAwAAW5wMH1x2AQDAHqfCh7e2C+kDAABrnAofSYx8AABgnVPhgzkfAADY51T48C67kD0AALDGqfARZG0XAACscyt88JwPAACscyt8sLYLAADWORU+Alx2AQDAOqfCR5AJpwAAWOdY+GDkAwAA2xwLH3VbnvMBAIA9ToWPAE84BQDAOqfCx6E5H6QPAABscSx8MPIBAIBtToYP5nwAAGCPU+EjwGUXAACscyp8eJddopYLAQDAYY6Fj7otIx8AANjjWPhgbRcAAGxzKnywtgsAAPY5FT5Y2wUAAPscCx+MfAAAYJtb4aP+2/KcDwAA7HEqfLC2CwAA9jkVPrjsAgCAfY6Fj7otIx8AANjjWPhoeMIp6QMAAFucCh+s7QIAgH1OhY8gE04BALDOsfBRt2XkAwAAexwLHw1ruxA+AACwxanwwXM+AACwz6nwwWUXAADscyx8MPIBAIBtcQ8ftbW1Gj9+vPLz85Wamqpvfetbevjhh5vFPIuGkY/mUAsAAK5KjvcHPvroo5o+fbpmzpypHj16aMWKFRo1apQyMzN19913x/t0TRLg8eoAAFgX9/Dx/vvv6/rrr9fQoUMlSV26dNGsWbP0wQcfxPtUTcZlFwAA7Iv7ZZfLLrtMpaWlWr9+vSTpo48+0rvvvqshQ4YctX0kElE4HI55JQoTTgEAsC/uIx9jx45VOBxW9+7dlZSUpNraWj3yyCMaMWLEUduXlJTooYceincZRxUMNjznw5fTAQCAo4j7yMdLL72k559/Xi+88II+/PBDzZw5U48//rhmzpx51Pbjxo1TVVWV9yovL493SR5vbReuuwAAYE3cRz7uu+8+jR07VjfeeKMkqVevXtq8ebNKSko0cuTII9qHQiGFQqF4l3FUzPkAAMC+uI987N27V8Fg7McmJSUpGo3G+1RNlsTdLgAAWBf3kY/rrrtOjzzyiDp37qwePXpo1apVeuKJJ3TzzTfH+1RNxnM+AACwL+7hY+rUqRo/frzuuOMObdu2Tbm5ubr11ls1YcKEeJ+qyVjbBQAA++IePtLT0zVlyhRNmTIl3h992oJcdgEAwDrH1nap2zLyAQCAPW6FD+85H6QPAABscSp8BHjCKQAA1jkVPhrmfNTav+sXAABnORU+6gc+ZMTIBwAAtrgVPg6lDwAAYIlb4aN+7IPsAQCAPW6FD55wCgCAdU6FjwZEDwAA7HEqfDQ8Xp2BDwAA7HErfNRvyR4AANjjVvhgzgcAANa5FT7qt0QPAADscSt8eEMfdusAAMBljoWPui1POAUAwB63wkf9likfAADY41T4ELfaAgBgnVPhg4XlAACwz63w4d1qa7cOAABc5lb4YGE5AACscyt8MPIBAIB1boUP7x3pAwAAW9wKH4x8AABgnVvhgzkfAABY51T4EAvLAQBgnVPhg4XlAACwz63wwRNOAQCwzq3wUb+Nkj4AALDGrfAROHEbAACQWE6GDwY+AACwx63w4d1qS/oAAMAWt8IHIx8AAFjnVPhoQPgAAMAep8KHd6stl10AALDGrfBRv2XkAwAAe9wKHw1zPuyWAQCA09wKHyJ9AABgm1vhw8sepA8AAGxxK3zUb5nzAQCAPW6FD666AABgnVPho2HswzD0AQCANU6FjyAjHwAAWOdU+PAeMkb6AADAGrfCR/2W7AEAgD1uhQ9udwEAwDonwwfRAwAAe9wKH2LOBwAAtjkVPsQTTgEAsM6p8MGUDwAA7HMrfHCrLQAA1rkVPuq3ZA8AAOxxK3w0zPlg6AMAAGvcCh/e2AcAALDFrfBRnz2ijHwAAGCNW+Gjfkv2AADAHqfCh3jCKQAA1iUkfHz55Zf6yU9+onbt2ik1NVW9evXSihUrEnGqJjn0hFPiBwAAtiTH+wN37typgQMH6uqrr9bbb7+tDh06aMOGDWrTpk28T9VkrO0CAIB9cQ8fjz76qPLy8vTcc895+/Lz8+N9mlPi3etC+gAAwJq4X3Z5/fXX1a9fP/3oRz9SVlaWLrnkEj377LPHbB+JRBQOh2NeieI94TRhZwAAACcS9/Dx+eefa/r06erWrZv+9re/6fbbb9fdd9+tmTNnHrV9SUmJMjMzvVdeXl68S/LwkDEAAOwLmDj/JU5JSVG/fv30/vvve/vuvvtuLV++XEuWLDmifSQSUSQS8X4Oh8PKy8tTVVWVMjIy4lmaVnyxQ//19BKd1y5Ni+67Oq6fDQCAy8LhsDIzM0/q73fcRz46duyoiy66KGbft7/9bW3ZsuWo7UOhkDIyMmJeiXJo5CNhpwAAACcQ9/AxcOBAlZWVxexbv369zjvvvHif6hQ0zPkgfQAAYEvcw8cvf/lLLV26VL/73e+0ceNGvfDCC/rjH/+o4uLieJ+qyRj5AADAvriHj/79+2vOnDmaNWuWevbsqYcfflhTpkzRiBEj4n2qJuPx6gAA2Bf353xI0rXXXqtrr702ER99WhputQUAAPY4tbbLoZEPhj4AALDFrfDB49UBALDOrfBRP/ZxoCZquRIAANzlVPj4evd+SdI3ew5YrgQAAHc5FT4Y8QAAwD6nwkfntufYLgEAAOc5FT7Kd+61XQIAAM5zKnx0zWpluwQAAJznVPhoeM5Heighz1YDAAAnwa3wEWhYWA4AANjiVvio3/KEUwAA7HErfPCEUwAArHMqfAQbLruQPgAAsMap8NEgSvoAAMAap8IHl10AALDPsfBB+gAAwDanwkfQyx6kDwAAbHEqfATqb7aNkj0AALDGrfDRMPLBhFMAAKxxK3zUb4keAADY41T4kDfyYbcMAABc5lT4aHjImMSlFwAAbHEqfAQavSd7AABgh1vho/HIh8U6AABwmVvho9F7LrsAAGCHW+GjUfogegAAYIdj4aPxhFOLhQAA4DDHwseh96xsCwCAHW6FD9sFAAAAx8IHl10AALDOqfARjJlwSvoAAMAGp8JHoNGFF1a2BQDADrfCR+ORD667AABghVPhozGiBwAAdjgVPmJHPuzVAQCAy5wKH0EecQoAgHVOhY/Gz/ngIWMAANjhVvhgVVsAAKxzK3w0es/dLgAA2OFW+GDKBwAA1jkWPni8OgAAtjkVPqRDox9cdgEAwA73wkf9lugBAIAd7oWP+qEPBj4AALDDufDRsLItq9oCAGCHc+GjYWVbVrUFAMAO58KHmHAKAIBVzoUPb8Ip2QMAACvcCx+BE7cBAACJ41z4CHK3CwAAVjkXPhoGPljVFgAAO9wLHw0jH5brAADAVe6Fj/otd7sAAGCHc+HDu9XWbhUAADjLufDBhFMAAOxyLnywqi0AAHa5Fz7qt0QPAADsSHj4mDRpkgKBgEaPHp3oU50UVrUFAMCuhIaP5cuX65lnnlHv3r0TeZomYVVbAADsSlj42L17t0aMGKFnn31Wbdq0SdRpTkH9qrZRy2UAAOCohIWP4uJiDR06VEVFRcdtF4lEFA6HY16JFGDkAwAAq5IT8aGzZ8/Whx9+qOXLl5+wbUlJiR566KFElHFUrGoLAIBdcR/5KC8v1z333KPnn39eLVu2PGH7cePGqaqqynuVl5fHu6QYrGoLAIBdcR/5WLlypbZt26ZLL73U21dbW6vFixfrqaeeUiQSUVJSkncsFAopFArFu4xj4iFjAADYFffwMWjQIK1ZsyZm36hRo9S9e3c98MADMcHDBla1BQDArriHj/T0dPXs2TNm3znnnKN27dodsd8GVrUFAMAu555w2oDHqwMAYEdC7nY53MKFC/04zUkJsKotAABWOTfywYRTAADsci58sKotAAB2uRc+6rdEDwAA7HAvfHDZBQAAqxwMH3VbLrsAAGCHe+GjfhslewAAYIV74cN7yBjpAwAAG9wLHw1vyB4AAFjhXvjgIWMAAFjlXPjgIWMAANjlXPhowKq2AADY4Vz4YFVbAADsci981G95zgcAAHa4Fz6YcAoAgFXOhY8g6QMAAKucCx8N2YMJpwAA2OFe+Kjfkj0AALDDufAh7nYBAMAq58JHkFVtAQCwyrnwwaq2AADY5Vz42HugVhITTgEAsMW58PGvimpJ0sz3v7BbCAAAjnIufDRYtmmH7RIAAHCSs+EDAADYQfgAAAC+InwAAABfET4AAICvCB8AAMBXhA8AAOArwgcAAPAV4QMAAPiK8AEAAHzlbPi46oIOtksAAMBJzoWPa3t3lET4AADAFufCRzAQkCSxpi0AAHY4Fz4aGEP8AADABufCR/3ABwAAsMS98GG7AAAAHOde+GiY88FVFwAArHAufGzavkeS9O+dey1XAgCAm5wLH6vLd0mSZi7ZbLcQAAAc5Vz4AAAAdhE+AACArwgfAADAV4QPAADgK8IHAADwFeEDAAD4ivABAAB8RfgAAAC+InwAAABfET4AAICvCB8AAMBXhA8AAOArwgcAAPAV4QMAAPiK8AEAAHxF+AAAAL6Ke/goKSlR//79lZ6erqysLA0bNkxlZWXxPg0AADhDxT18LFq0SMXFxVq6dKnmz5+vgwcP6pprrtGePXvifSoAAHAGSo73B86bNy/m5xkzZigrK0srV67UlVdeGe/TAQCAM0zcw8fhqqqqJElt27Y96vFIJKJIJOL9HA6HE10SAACwKKETTqPRqEaPHq2BAweqZ8+eR21TUlKizMxM75WXl5fIkgAAgGUJDR/FxcVau3atZs+efcw248aNU1VVlfcqLy9PZEn6+eX5Cf18AABwfAm77HLnnXfqjTfe0OLFi9WpU6djtguFQgqFQokq4wi9O2VKkrq0S/PtnAAA4JC4hw9jjO666y7NmTNHCxcuVH5+8xppWF9ZLUn64pu9lisBAMBNcQ8fxcXFeuGFF/Taa68pPT1dFRUVkqTMzEylpqbG+3RNtuZLJrQCAGBT3Od8TJ8+XVVVVfrud7+rjh07eq8XX3wx3qc6JcnBgO0SAABwWkIuuzRnwQDhAwAAmxxc26V5hyMAAM52zoWP8L4a731zH6UBAOBs5Fz42LXvgPd+M3e8AADgO+fCR0CH5nww/QMAAP85Fz6yMg490IzJpwAA+M+58HFxXmvbJQAA4DTnwkeLpENf+bOvd1usBAAANzkXPkLJjcPHHouVAADgJufCx9Xds7z33GoLAID/nAsfKY0uu9RGCR8AAPjNufDR+AaXGsIHAAC+cy58NL699qPyXfYKAQDAUc6Fj8Z3u/x9XaXFSgAAcJNz4SMns6XtEgAAcJpz4QMAANhF+AAAAL4ifAAAAF8RPgAAgK8IHwAAwFeEDwAA4CvCBwAA8BXhAwAA+IrwAQAAfEX4AAAAviJ8AAAAXzkfPvYeqLFdAgAATnE+fFSGI7ZLAADAKc6Hj4DtAgAAcIzz4SO8/6DtEgAAcIrz4WPcq2tslwAAgFOcDx+fbA3bLgEAAKc4GT7+46Js2yUAAOAsJ8PHdX1ybZcAAICznAwf3bJa2S4BAABnORk+clunxvx8oCZqqRIAANzjZPjITG0R8/P/LN1sqRIAANzjZPg43P9+Y53tEgAAcAbhAwAA+IrwUa+aJ50CAOALwke9/8u8DwAAfOFs+Hjkhz1jfp48r8xSJQAAuMXZ8HFF1w5H7IvU1FqoBAAAtzgbPg6/3VaS/rDgMwuVAADgFnfDR9qR4eP3pRssVAIAgFucDR/Hsv8gl14AAEgkp8PHX28vPGLfs4s/V9U+brsFACBRnA4fh6/xIkn/PX+9+jz0d32xfY+FigAAOPs5HT7SWx4576PBa6u3+lgJAADucDp8tAolH/PY//nHeq3cvIM5IAAAxJnT4UOSPnlo8DGP3TB9ia5/6j0fqwEA4OznfPg4J5Ss/7z03GMeL6us1je7IzLG+FgVAABnL+fDhyQ98eOLj3u872//ofGvrfWnGAAAznKEj5P0P0u36MrJC2yXAQDAGY/wUW/Nb645YZstO/aqy9g39eziz3WwNnrE8WiUSzMAAJxIwDSzyQzhcFiZmZmqqqpSRkaGr+fevjuifr/9R5P/Xem9V2ne2gpNX/iZXr3jMl2QnZ6A6gAAaL6a8veb8HGYaNTo/F+9dcr/PiUpqP931+W6ILuVAoGADtRElZLMABMA4OzWLMLHtGnT9Nhjj6miokJ9+vTR1KlTNWDAgBP+O9vho8HKzTt1w/T34/Z5L99WqP5d2h7zuDFGf1j4mb7V4Rx9r2dHb380ahQMBuJWBwAAiWA9fLz44ov62c9+pqeffloFBQWaMmWKXn75ZZWVlSkrK+u4/7a5hI8Gr3+0VXfPWpXw8zzyw5769Zy6O2pK771KndumadRzy/Xuxu2aMvxizVtbof/q20lFF2Vr74EaPfzGOn2/V0dd0a1DwmsDAOBErIePgoIC9e/fX0899ZQkKRqNKi8vT3fddZfGjh173H/b3MKHVDcqkT/u1C/F2DT5ht5q1ypF57ZJ1bqtYa39MqxgQPrrh//W1Jsu1XfOb6ukYEAL13+taNToqgs6aOfeg4oao+yMljGfdaAmqqRgQEmHjcRUVO3X9t0R9Tw386g11EaN9hyoUcZxHmd/IowAAUDzZjV8HDhwQGlpaXrllVc0bNgwb//IkSO1a9cuvfbaazHtI5GIIpFITPF5eXnNKnw0ZozRvoO1+t6Uf2rLjr22y8EJDLs4V3MPW6en33lttGLzzph9A7u2U0ABBYMB5bdLUyDQ9KDT1P8pHag1mvXBFknSqIFdmny+49dSt23K1zjd/yc4hS4DYEn7ViEVX901rp/ZlPBx7MVNTtH27dtVW1ur7OzsmP3Z2dn617/+dUT7kpISPfTQQ/EuI2ECgYDSUpK1+P6rvX3V+w8qLaWuK0s/rdTfPqnUXz/8t60S0cjhwUPSEcFDkt7b+I33fnFCKzq65977wsJZAbjq/A7nxD18NEXcw0dTjRs3TmPGjPF+bhj5OJM0Xh33mh45uqZHjv77x32O+2+MMaqJGtXUGgUC0r937tOKL3YoGAwor02aqvcf1IKyr9WnU6bGvrom0V/hrFV4fjst+fybmH3/ecm5enXVlzH7ir6dpe27D+ibPRFd36fucftGRgEd/z/nT+a/9o/VJGqkpxZsVGqLJN18eZcTf5APTvR9j8WoWd00B+AE2qSlWD1/3MNH+/btlZSUpMrKypj9lZWVysnJOaJ9KBRSKBSKdxnNXiAQUIukgFok1f3cNauVuma1imlzTY+6/rpxQGe/yzvrPTH8YtslSJL+1+ALbZcAAL6L+wMoUlJS1LdvX5WWlnr7otGoSktLVVhYGO/TAQCAM0xCLruMGTNGI0eOVL9+/TRgwABNmTJFe/bs0ahRoxJxOgAAcAZJSPgYPny4vv76a02YMEEVFRW6+OKLNW/evCMmoQIAAPfweHUAAHDamvL3m0VHAACArwgfAADAV4QPAADgK8IHAADwFeEDAAD4ivABAAB8RfgAAAC+InwAAABfET4AAICvEvJ49dPR8MDVcDhsuRIAAHCyGv5un8yD05td+KiurpYk5eXlWa4EAAA0VXV1tTIzM4/bptmt7RKNRrV161alp6crEAjE9bPD4bDy8vJUXl7OujFNRN+dHvrv1NF3p4f+Oz3038kzxqi6ulq5ubkKBo8/q6PZjXwEg0F16tQpoefIyMjgl+gU0Xenh/47dfTd6aH/Tg/9d3JONOLRgAmnAADAV4QPAADgK6fCRygU0sSJExUKhWyXcsah704P/Xfq6LvTQ/+dHvovMZrdhFMAAHB2c2rkAwAA2Ef4AAAAviJ8AAAAXxE+AACAr5wJH9OmTVOXLl3UsmVLFRQU6IMPPrBdUsItXrxY1113nXJzcxUIBDR37tyY48YYTZgwQR07dlRqaqqKioq0YcOGmDY7duzQiBEjlJGRodatW+vnP/+5du/eHdPm448/1hVXXKGWLVsqLy9PkydPPqKWl19+Wd27d1fLli3Vq1cvvfXWW3H/vvFUUlKi/v37Kz09XVlZWRo2bJjKyspi2uzfv1/FxcVq166dWrVqpRtuuEGVlZUxbbZs2aKhQ4cqLS1NWVlZuu+++1RTUxPTZuHChbr00ksVCoXUtWtXzZgx44h6zrTf3+nTp6t3797eg5kKCwv19ttve8fpu5M3adIkBQIBjR492ttH/x3bb37zGwUCgZhX9+7dveP0XTNhHDB79myTkpJi/vznP5tPPvnE/OIXvzCtW7c2lZWVtktLqLfeesv8+te/Nq+++qqRZObMmRNzfNKkSSYzM9PMnTvXfPTRR+YHP/iByc/PN/v27fPafO973zN9+vQxS5cuNf/85z9N165dzU033eQdr6qqMtnZ2WbEiBFm7dq1ZtasWSY1NdU888wzXpv33nvPJCUlmcmTJ5t169aZBx980LRo0cKsWbMm4X1wqgYPHmyee+45s3btWrN69Wrz/e9/33Tu3Nns3r3ba3PbbbeZvLw8U1paalasWGG+853vmMsuu8w7XlNTY3r27GmKiorMqlWrzFtvvWXat29vxo0b57X5/PPPTVpamhkzZoxZt26dmTp1qklKSjLz5s3z2pyJv7+vv/66efPNN8369etNWVmZ+dWvfmVatGhh1q5da4yh707WBx98YLp06WJ69+5t7rnnHm8//XdsEydOND169DBfffWV9/r666+94/Rd8+BE+BgwYIApLi72fq6trTW5ubmmpKTEYlX+Ojx8RKNRk5OTYx577DFv365du0woFDKzZs0yxhizbt06I8ksX77ca/P222+bQCBgvvzyS2OMMX/4wx9MmzZtTCQS8do88MAD5sILL/R+/vGPf2yGDh0aU09BQYG59dZb4/odE2nbtm1Gklm0aJExpq6vWrRoYV5++WWvzaeffmokmSVLlhhj6sJfMBg0FRUVXpvp06ebjIwMr7/uv/9+06NHj5hzDR8+3AwePNj7+Wz5/W3Tpo3505/+RN+dpOrqatOtWzczf/58c9VVV3nhg/47vokTJ5o+ffoc9Rh913yc9ZddDhw4oJUrV6qoqMjbFwwGVVRUpCVLlliszK5NmzapoqIipl8yMzNVUFDg9cuSJUvUunVr9evXz2tTVFSkYDCoZcuWeW2uvPJKpaSkeG0GDx6ssrIy7dy502vT+DwNbc6k/q+qqpIktW3bVpK0cuVKHTx4MOZ7de/eXZ07d47pv169eik7O9trM3jwYIXDYX3yySdem+P1zdnw+1tbW6vZs2drz549KiwspO9OUnFxsYYOHXrEd6T/TmzDhg3Kzc3V+eefrxEjRmjLli2S6Lvm5KwPH9u3b1dtbW3ML5IkZWdnq6KiwlJV9jV89+P1S0VFhbKysmKOJycnq23btjFtjvYZjc9xrDZnSv9Ho1GNHj1aAwcOVM+ePSXVfaeUlBS1bt06pu3h/XeqfRMOh7Vv374z+vd3zZo1atWqlUKhkG677TbNmTNHF110EX13EmbPnq0PP/xQJSUlRxyj/46voKBAM2bM0Lx58zR9+nRt2rRJV1xxhaqrq+m7ZqTZrWoLNDfFxcVau3at3n33XdulnFEuvPBCrV69WlVVVXrllVc0cuRILVq0yHZZzV55ebnuuecezZ8/Xy1btrRdzhlnyJAh3vvevXuroKBA5513nl566SWlpqZarAyNnfUjH+3bt1dSUtIRs5krKyuVk5NjqSr7Gr778folJydH27ZtizleU1OjHTt2xLQ52mc0Psex2pwJ/X/nnXfqjTfe0IIFC9SpUydvf05Ojg4cOKBdu3bFtD+8/061bzIyMpSamnpG//6mpKSoa9eu6tu3r0pKStSnTx/9/ve/p+9OYOXKldq2bZsuvfRSJScnKzk5WYsWLdKTTz6p5ORkZWdn039N0Lp1a11wwQXauHEjv3vNyFkfPlJSUtS3b1+VlpZ6+6LRqEpLS1VYWGixMrvy8/OVk5MT0y/hcFjLli3z+qWwsFC7du3SypUrvTbvvPOOotGoCgoKvDaLFy/WwYMHvTbz58/XhRdeqDZt2nhtGp+noU1z7n9jjO68807NmTNH77zzjvLz82OO9+3bVy1atIj5XmVlZdqyZUtM/61ZsyYmwM2fP18ZGRm66KKLvDbH65uz6fc3Go0qEonQdycwaNAgrVmzRqtXr/Ze/fr104gRI7z39N/J2717tz777DN17NiR373mxPaMVz/Mnj3bhEIhM2PGDLNu3Tpzyy23mNatW8fMZj4bVVdXm1WrVplVq1YZSeaJJ54wq1atMps3bzbG1N1q27p1a/Paa6+Zjz/+2Fx//fVHvdX2kksuMcuWLTPvvvuu6datW8yttrt27TLZ2dnmpz/9qVm7dq2ZPXu2SUtLO+JW2+TkZPP444+bTz/91EycOLHZ32p7++23m8zMTLNw4cKYW/b27t3rtbnttttM586dzTvvvGNWrFhhCgsLTWFhoXe84Za9a665xqxevdrMmzfPdOjQ4ai37N13333m008/NdOmTTvqLXtn2u/v2LFjzaJFi8ymTZvMxx9/bMaOHWsCgYD5+9//boyh75qq8d0uxtB/x3PvvfeahQsXmk2bNpn33nvPFBUVmfbt25tt27YZY+i75sKJ8GGMMVOnTjWdO3c2KSkpZsCAAWbp0qW2S0q4BQsWGElHvEaOHGmMqbvddvz48SY7O9uEQiEzaNAgU1ZWFvMZ33zzjbnppptMq1atTEZGhhk1apSprq6OafPRRx+Zyy+/3IRCIXPuueeaSZMmHVHLSy+9ZC644AKTkpJievToYd58882Efe94OFq/STLPPfec12bfvn3mjjvuMG3atDFpaWnmhz/8ofnqq69iPueLL74wQ4YMMampqaZ9+/bm3nvvNQcPHoxps2DBAnPxxReblJQUc/7558eco8GZ9vt78803m/POO8+kpKSYDh06mEGDBnnBwxj6rqkODx/037ENHz7cdOzY0aSkpJhzzz3XDB8+3GzcuNE7Tt81DwFjjLEz5gIAAFx01s/5AAAAzQvhAwAA+IrwAQAAfEX4AAAAviJ8AAAAXxE+AACArwgfAADAV4QPAADgK8IHAADwFeEDAAD4ivABAAB8RfgAAAC++v8R1snsAy9ElwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_terms_dict['rounding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ts = diffusion_model.word_embeddings.weight.data.cpu()\n",
    "init_ts = torch.nn.Embedding(len(tokenizer), diffusion_model.config.word_embedding_dim).weight.data\n",
    "\n",
    "trained_ts_normed = trained_ts / trained_ts.norm(dim=1, keepdim=True)\n",
    "init_ts_normed = init_ts / init_ts.norm(dim=1, keepdim=True)\n",
    "\n",
    "trained_cosine = torch.matmul(trained_ts_normed, trained_ts_normed.T)\n",
    "init_cosine = torch.matmul(init_ts_normed, init_ts_normed.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21.8831,  8.6172,  7.3387, 12.2852, 10.4657,  7.9724,  9.0047, 15.2567,\n",
       "         9.5580, 20.4276, 14.9555,  6.4496, 10.2263,  8.5789, 13.5854, 13.6579,\n",
       "        15.6314,  6.8749,  5.3842,  9.2093, 13.7879, 13.1452, 14.2123,  9.4225,\n",
       "        11.6611, 13.5092, 12.5825, 13.5993, 10.4602, 14.2846, 11.3724, 13.2142,\n",
       "        11.8243, 11.0697, 14.4086, 13.6377, 12.2509, 15.3699, 15.6723, 11.4584,\n",
       "        12.9936, 14.6573, 15.7526, 13.5041, 13.3888,  6.9546, 14.8483,  8.8226,\n",
       "        16.3888, 19.2825, 11.0580, 14.4109,  8.9228, 18.8372, 13.4110, 14.6643,\n",
       "         7.4504, 16.8032, 14.2178, 18.4082, 13.6273, 13.5975, 14.5907, 13.9242,\n",
       "        11.4729,  9.8927, 14.1217, 13.4206, 13.6141, 11.9385, 15.9566, 12.3583,\n",
       "        15.4035, 13.1177, 19.6243, 12.5618, 15.1814, 12.5672,  9.8864, 22.4683,\n",
       "        12.5661, 12.3967, 14.8720, 18.3632, 14.4745, 15.0497, 15.1815, 15.6543,\n",
       "        13.5556, 13.7822,  7.7458, 15.7502, 12.6514, 14.3874,  6.4917, 17.2969,\n",
       "        12.1216, 14.3382, 14.8450, 10.9829])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_ts.norm(dim=1)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnter = Counter()\n",
    "for d in train_dataset:\n",
    "    cnter.update(d['question1_input_ids'].tolist())\n",
    "    cnter.update(d['question2_input_ids'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1000.0)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sorted(cnter.values(), reverse=True))\n",
    "plt.ylim(0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAG1CAYAAAARLUsBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAClU0lEQVR4nOzdd3xTVf8H8E9G23SmdDdtactoWW1BRilVQAEB/SEIiqKPgiKiFEUZrkdERMXxoKgsJ+CjKKgM1wPKhrKXtIwuCoXumTbdSe7vjzS39yY3adImnd/369UXPTf33pwE2nw553u+R8QwDANCCCGEkC5E3NYdIIQQQghpbRQAEUIIIaTLoQCIEEIIIV0OBUCEEEII6XIoACKEEEJIl0MBECGEEEK6HAqACCGEENLlUABECCGEkC5H2tYdaI+0Wi1ycnLg7u4OkUjU1t0hhBBCiAUYhkFFRQUUCgXEYvNjPBQACcjJyUFISEhbd4MQQgghzXDz5k0EBwebPYcCIAHu7u4AdG+gh4dHG/eGEEIIIZYoLy9HSEgI+zluDgVAAvTTXh4eHhQAEUIIIR2MJekrlARNCCGEkC6HAiBCCCGEdDltGgCtXLkSQ4cOhbu7O/z8/DBlyhSkpKTwzhk9ejREIhHv65lnnjF7X4Zh8MYbbyAwMBDOzs4YO3Ys0tLS7PlSCCGEENKBtGkAdOjQISQkJODEiRP4+++/UV9fj7vvvhuVlZW88+bMmYPc3Fz264MPPjB73w8++ACffvopNmzYgJMnT8LV1RXjx49HTU2NPV8OIYQQQjqINk2C3r17N6+9adMm+Pn54ezZsxg5ciR73MXFBQEBARbdk2EYrF69Gq+//jomT54MAPj222/h7++PnTt34uGHH7bdCyCEEEJIh9SucoCUSiUAwMvLi3f8+++/h4+PDwYMGIBXX30VVVVVJu+RmZmJvLw8jB07lj0ml8sRGxuL48ePC15TW1uL8vJy3hchhBBCOq92swxeq9XihRdeQHx8PAYMGMAef+SRRxAaGgqFQoGLFy/i5ZdfRkpKCrZv3y54n7y8PACAv78/77i/vz/7mKGVK1di+fLlNnolhBBCCGnv2k0AlJCQgOTkZBw9epR3/Omnn2a/j4qKQmBgIMaMGYOMjAz07NnTJs/96quvYuHChWxbX0iJEEIIIZ1Tu5gCmz9/Pn7//XccOHCgydLVsbGxAID09HTBx/W5Qvn5+bzj+fn5JvOInJyc2KKHVPyQEEII6fzaNABiGAbz58/Hjh07sH//foSHhzd5zYULFwAAgYGBgo+Hh4cjICAA+/btY4+Vl5fj5MmTiIuLs0m/CSGEENKxtWkAlJCQgO+++w5btmyBu7s78vLykJeXh+rqagBARkYGVqxYgbNnz+L69ev49ddf8fjjj2PkyJGIjo5m79OnTx/s2LEDgK789QsvvIC3334bv/76K5KSkvD4449DoVBgypQpbfEyCSGEENLOtGkO0Pr16wHoih1ybdy4EbNmzYKjoyP27t2L1atXo7KyEiEhIZg2bRpef/113vkpKSnsCjIAeOmll1BZWYmnn34aZWVluP3227F7927IZDK7vyaio9ZokVVShe5eLpBK2sVMKyGEEMISMQzDtHUn2pvy8nLI5XIolUrKB2oGtUaLqeuO4WK2EtFBcmyfN6LVgyAKwAghpOux5vObPhmIzWWVVOFitm5E7mK2Elklpus2NYdao8W1QhXUGq3Jx6euO4a7Vh3C1HXHTJ5HCCGk66IAiNhcdy8XDFDoIu8BCg9093IRPK+mTo1DKQWoqVNbfG9LghuhAKypoIkQQkjX0m7qAJHOQ63RIqNQBQDIaAg6DKehaurUGLRiL6rrNXB2kOD80rGQOTb9z1EouOnh68ab8uru5YLoILluCi5YDoVc1uZTcoQQQtoX+hQgNnf8WjGq63UjLdX1Why/VmziHE3DORrBc4RGbfTBDQBEB8vR3cvFaFQIALbPG4H9i0Zh+7MjkKOsseuUHCGEkI6HRoCIzfm5y8y2ASBQ7my2bSqRWioRY/u8EbwE52uFKsFRoR6+bgBgNCJkakqOEEJI10EBELE5R6nYbBsAgj1lZtumprqENBXgCAVNhBBCujYKgIjNhfu4IipIjqRsJaKC5Aj3cTU650RmiVF7bL/GrUq6e7kgSuGBpJxyRAU1JlKbGhlqKsCRSsQmAyhCCCFdDwVApEnW1tSRSsT4ae5wnMwsQWy4l+A1Gi1jtg0A2oYSVVrOY9aMDBFCCCGmUABEzFJrtJiy5iiScyswINAdO+ff3mQQpNZoMf3zE2ZXXQUZTHkZttMLVLiUWwEAuJRbgfQCFfoE6kaCuKNL+iTo+9cdY4/tmDcCAGjKixBCiEn0ydBJ2KvOTXqBCskNgUhyQyDSFEsKITo5SM22b5VWmWxrtVren5lFlUhqeL6kbCXS8iuoECIhhBCzKADqBOxZ+ThXWW22LcTLRWq2DQCBHk5m275ujoLttPwK3shQWn6FQJ+Nl71TIURCCCFcFAB1AvbceiKuhzdkUhEAQCYVIa6Hd5PX7LlUYLYNAMcySsy2s8tqBNvZZdUGx6sR7uOKAYHuAIABCncMC+sGZwcJAMDZQQI/N0caESKEEMJDAVAn4OfmCFHD96KGtk2JRPw/mzC+v5/ZNgDcKK402xYKdAAguBt/ibu+LRKLG7ooRm55La/I4tmsMpMBIo0MEUJI10QBUCdwNqsM+nVSTEPbVo5fK0ZNQ1XnGhNVnQ0VqurNtgGgSFVrtl2qqhNsB3jwg7sAD0dklVTxcoAA8KpFx4Z7GVWPBmw3dUhBFCGEdDy0CqwTiA33grODhN1XKzbcy2b3tqSqs6GyylqBtjvvmKfMwWw7IsBdsL3zfC7v+M7zufhXXCj6B7jhUp4K/QPdEO7jalQXiNsGgGuFKmi0TIuX1JuqS0QIIaR9owCoE5A5SnF+6Vi27o4lm4paSiIWmW0L2fVPjlF7aA8f3rHS6nqzbUepSLBdo+afV6OuR02dGpfzdKvTLueqUFOnNvkecJfoRwXJMSDQHcm5Fbxii/rzDJfRCx2jukSEENIxUQDUScgcpRgVaZxr01K19WqzbSExwd3w3cmbvLYxw8KHhoURIdhWVvGfX1mlxh9JebwpwF//ycWPp2+yozLb5g7HAxuOIzmnHL39XJFWoMs3SspWIsJfH6w0BlxCozoABEd6aJ8xQgjpmGisvpOwVx7KmetlZttCig3yeQzbAODl7Gi2bSpHqL/Ck3e8v8IT90YF8JLAo4PlvFGZo+lFSM4pBwCkFVSit68uSIn0d0Nqvm7kKImTHC00qmNqpZ1UIsaWp4bh/alR2DJ7GE1/EUJIB0EjQJ2APfNQtIzWbFvItSKV2TYAODlJzLY9DHKC9O1wX/6+YuG+rpBKxHCUilCrZuAoFcHHnf/PurKGP2324rhIuDpJERPsgbj3DrK5Uwq5Lr/J1D5kQiM9NXVqDH13P6rrNXjzt8s4v3SsTacgCSGE2Af9pu4E7JmH0rCa3GRbSJi3i9k2AIQZTBUZtq/kKgXaISiq4C+PL6qoRkFFDWrVukmwWjWD9QcyDa7lF0v88M9LyCyrQ28fF95y+Zul1ZCIRbpASMQdUzK9o/zJzBLePU5mlthlKpIQQoht0Xh9J2BY98eWdYBuFKvMtoWItObbAPDFkWtm2+mFFYLtz/an845/tj8dLgbbaPT24wd/Gg0/vyizTLekPq2oip0OiwrywItbL+CuVYdw35pE3rJ67nRXD1833uiafgUeAJuvwCOEEGI/NALUCZy6XmrUvquvv03uHe7tarYtJNOgErVhGwDySlVm29klwm1Pg201PF2k+PWfW7xjRzOKeG2xxPTKtcV390HvAHfU1msw8dOjAIDUAhUiGvKDhBKbuavB7LkCjxBCiP3Qb+tOIFAuM9tuCV+DwoOGbSGeLg5m2wAQ28sXmWdyeG2u60V1gu203DLe8bTcMgztzl9i7+PKf75wgSk4vVAfV/TwdcPV3HLe8Y+nD4Szo8RoN3mhfCt7rcBrKaFl+4QQQnTot2In0NvfHQMUHgCAAQoP9PZ3b+IKy2UWVZttC/F1lZltA4BULDbbNoWByKjtZZD0nFfOX0F2/hZ/hEyfbu0kEc5PAgCGMVymr2PPfddsyZ4b5BJCSGdAAVAnIJWI8eOcWLw/NQo/zom16f/2B4V6mG0L2Xo202wbAM5nFZttG+Za69tCdYCOX+NvpFpVx1/1JWH474f+XrUa4GapLqAzDHheaMgHmrI2EWn5FVBrtFBrtNBoGUQ1bKsRFeQBjZZpl8FFRwnUCCGkrVAA1Anol2K/vD0JQ9/dj5q6posVWmrXuVyzbSF+ro5m2wBQUlFjtm1KN4McoG4uUuSX869NzeGvIDtzvdDk/Wrr1bhWqILIYKPX9EJdscTknHKM+/gwpqxNxJS1iRj38WEwDIPdC+4AIMK4jw8LjrDU1KlxKKXApn8X1tAXaARABRoJIUQA5QB1AsevFfOWYh+/Vow7+9gmCTq+lw9+TcrjtZuSZ7CRqWEbAPIrGbNtwzEVfdvFUQKgMahwcZSgv8IDiRmN01yeLo4oqml8Tkcpv8YQ1/NbzuJaSS36B7qz22Jwq0Xr6Qsp6r/PVVazK8W4pQfUGi3SC1S4f10iquu1cHaQtEltIFPL9gkhhOhQANQJeBpUUTZst0SZQUVmw7YQVXWd2TYAOIuBSi2/bYnM4lqjtkMmf/qs2CDgcjLzdlwr0d3vUm4F/njudjg7SuDlIsWgFfuMNuvg8nZ14m1Aq5DLeAnSem1ZG0i/bJ8QQogx+m9hJ3DhZqnZdktcLVCZbQsRqtZsqFJrvm2KWmvcFqv500yGA05Xcy3Lf8kpq0YPXzecuVFmFPw4GPykFFTU8EbdcpQ1vLwbrphgD7ttVUIIIaR5KADqBAzzVwzbLZFbXmW2LeR6ocpsuyWEtlDNLudHPIYJ1FoL03D8PWS4VqhCdZ1xuet6g7glUO7My7FRyGWorddAJjV+78/fVNKKLEIIaWdoCqwT+L9of7z522Ve21bEBsvODdtCDBcc2XIBkocUKFHz26oqg/3KDK5xcgQEZuGMvLj1PDKKqhDi2fQUoqO0McdGIZdh+ucnBEd/nB0kCJQ7222rEkIIIc1DI0CdwKUcldl2S2QVlZttC3ESm2+3hMEqeFSpAZmT+WvUFo4AZRTpIrWbZcLRkp+r7v8L/QN1dZb0IznXi4WnvlbePwDnl45FmLcLb7sMhQ0LVRJCCGkeGgFqC+pK04+JJIBEZtm5EANSZwzu7gkRAJmoBiIAgxUOAtfpzm28bxWMJ5TYTgBS3bJpRtR4XwBwEosN7t14ru6+1RAzNXDmDBSJGc7rkDbmAzmJaiHm9oFzX2dRDaoZGefcOkBdCZGoBpxXAQCQS4GSWv65Ys44kJYBrz/VjBP0m5w6iuohMZo0M3GuuB7OolrkFNXivtV/wdlB3LDSSwxnkRY1jCMcJRLUahgMVDhjaIgTpEw1MgpVgLpS1wc1kFtSjHB/X0DUEBlq6gCm3mQfIJYBYon152rrAa2ZoS+xEyCWNuNcNaA1kwwvdgTEDs04VwNozZRDEDkAEkfrz2W0gMZMAU+rzpUCkoaIm2EAjZnhTavOteLnvhm/I5p3rmW/I6w/txrG47QcnN8RVp2rqQEYM7s1W3OuxKVxQ2RNLcCY+V+UVec6W/5zb825Hfl3RBtq0wBo5cqV2L59O65evQpnZ2eMGDEC77//PiIjIwEAJSUlWLZsGf766y9kZWXB19cXU6ZMwYoVKyCXy03ed9asWdi8eTPv2Pjx47F79267vh6LbTMz/aG4Bxj9R2P7Fz/Tvzj9RgFjD6JAVQcGwNG+T8JbWg78JnCu1xBgwunG9h/9gMobwveV9wPuvQQAcJHJsDHgGUTIsjj955zrGgpMvt7Y3jsSF6POGN9zGwAnH2BaY02ezeHLMNwtWfC+Z/s7oV/yL2x7fei7wLapuBIl3OWwi7+z338Usgr3eiYKnwigb9LPbHD1btAaPOC1z+S5t136HiUa3b+1p9034PHwP0yee/uVryHz7IFXJvaB8tiL6HXwRwBAJMDv934A9yRD7d4XWSVVCMv5EOJLb5m8L8afAryH6r5P+QS48JLpc8ccAPxH675P/wI4M9/0uaN+B4Lu1X1//XvgxBOmz719G9D9Qd33t3YAR6ebPnf4RqDHLN33uXuAQ/9n+twha4CIBN33hUeAfXeaPnfgB0C/JbrvS88Be4aZPnfAMiD6Td33yivAnwNMn9t3MTDoQ933lVnAr+Gmz+09Dxi6Vvd9bRGw3czqvvCZQNwm3feaKvM/9yEPAHf81Ni28e8I1q4wXb+FNPN3BABgz1BAeVn4XIHfESgR+B0BGP2OwMGJQMEh4XMlLsBDnIDuyDQg50/hcwHgEU6Aduwx4ObPps+drmoMmE7NBTI3mz53agEga9jK59xCIG2d6XPvywTcwnTfX/w3cOU/ps+9Jxnw7K/7/tK7QPJy0+d25N8RbahNp8AOHTqEhIQEnDhxAn///Tfq6+tx9913o7JS9486JycHOTk5+M9//oPk5GRs2rQJu3fvxuzZs5u894QJE5Cbm8t+/fDDD/Z+OW2mu5cLohRNV2hujrsi2t8eV20h3Muyaav0wko89e1ZFFWaTzpSaxu3qth6+qYtukgIIcQKIsbUpkdtoLCwEH5+fjh06BBGjhwpeM5PP/2Ef/3rX6isrIRUKjyANWvWLJSVlWHnzp3N6kd5eTnkcjmUSiU8POwQWNh4eFut0eL+dceQnpOP/goP/Pj0cIHCd80b3p7/3UnsvXSLnQKb2N8bHz08VPBc3X2rMeTNP1HJGV12lQBn3pygazT8ryrslT+MpsCurJjAft936W6jKbCUFXej71LhUTzDc8Vmhs2bMwXmJAEifB2Rnm86B6qGcQTT8H8KB1E9pCbu21/hgZUPDsO41UfZc/9aEIdwHxP/6+/Iw9s0BWbhuTQFxqIpMOvP7ci/I2zMms/vdpUDpFTqEkm9vLzMnuPh4WEy+NE7ePAg/Pz80K1bN9x11114++234e3tLXhubW0tamsb/7LKy5tO9G0R7g+iDc7NKqlqqEosw5nsOmSVi9BDoPYO/76WbY2QfEuJGk5wce5Wnfk+SZ1RopbxfmXVqiF4TS1jkL3MOYcb0OjOdQSkrkbHAcAwB7qW4a/iEsP0r9A6xgFA0z+ItRogKa8OgPmRIBF0HwP1jAPqG+4b5u2C68WNH35nsutws7QGUUFyJGUr0TfIByG+voAl1ZoljgAsLHQpdrD8l4xV50obf9HZ9FwJILbwZ8Oac0Viy3/mrDpXZJ9zgXZyrhXbp1h1rmEWn43OlVg2Smv9uU4w/i1ji3Ot+Fm217nt4XdEG2o3q8C0Wi1eeOEFxMfHY8AA4fn6oqIirFixAk8//bTZe02YMAHffvst9u3bh/fffx+HDh3CxIkTodEIR/wrV66EXC5nv0JCQlr8eloTdwosKsjDpvs++bg7mW0LMfzRs11damFN/SNurao7DmLj/wOHeTlj57w43hSls4MET24+AzAM/n5xJLY/O4K2qiCEkFbWbkK0hIQEJCcn4+jRo4KPl5eX495770W/fv3w5ptvmr3Xww8/zH4fFRWF6Oho9OzZEwcPHsSYMWOMzn/11VexcOFC3nN1tCBI/8Fr6wnNa4WVZttCpFJwt+tCE4N1LWZmsLdV1WsBJ6kYtWotu0Lsekk1Hvv6NH6YE4vTN0qh0TJ46tuzAICkhv3FaL8uQghpfe3iN+78+fPx+++/48CBAwgODjZ6vKKiAhMmTIC7uzt27NgBBwfr5g579OgBHx8fpKenCz7u5OQEDw8P3ldHkllUyW7WmZxTjsyipoMUS02MCjDbFqLVmG/bWmvsty5Q4FlQrVqLxeMiUM0pHZ2UU45JaxLxxKYz+GRfOgY0jAYNUHjgxa0XcNeqQ7h/bSJViCaEkFbUpgEQwzCYP38+duzYgf379yM83Hj5aXl5Oe6++244Ojri119/hUxmfRG5W7duobi4GIGBgbbodrtj+MFpyw/Sq7mVZtuCDIMF2+3MIag1/hGrzYysGe41/5+/U+Ek4b/ozIYcoKRsJWrrdSFbTV09G7gmNQSutGcYIYS0jjYNgBISEvDdd99hy5YtcHd3R15eHvLy8lBdrVuFoQ9+Kisr8fXXX6O8vJw9h5vP06dPH+zYsQMAoFKpsGTJEpw4cQLXr1/Hvn37MHnyZPTq1Qvjx49vk9dpb/bcC0zh5Wy2LcTws9ven+WGAUhrExrgqtUIR0yhXs5IK9QFQ+lF/NVGGi3D2zOspk6NtPwKpOVXUEBECCE21qY5QOvXrwcAjB49mnd848aNmDVrFs6dO4eTJ08CAHr16sU7JzMzE2FhYQCAlJQUdgWZRCLBxYsXsXnzZpSVlUGhUODuu+/GihUr4ORkYXY+YbkZ5KUYtoWEejkgtaSe17an9pIDZIqjRIS6hoDIweD96+3nirSCSkQFySERi3h7ht23JhGpBbptTaIUHtiREE95QoQQYiNtGgA1VYJo9OjRTZ5jeB9nZ2fs2bOnxX3rSDRaxmy7JY5fLzLbFnKztN5su6sJ7uaMaw37jKUXVqK3nxvSClSICpLjp7nDkaOsYVfuRQfJcTFbiUh/d6TkV7D3SMopp01UCSHEhtrNKjDSfAUVNUbt/jC9VYg1gru54XppKa/dFEcpUF3Pb3dl+uBHz0kqxu/zR6CgQldUjBvUcHeYf/DzEw31nXQJ07Ysb0AIIV0djad3AnE9vHm7jcf1EC742BwODhKzbSFOUvPtri45pxzTNpzAk5vPYNCKv1FT17iOTSoRo4evG6QSMd6bGoXQhpwrO+eRE0JIl0MfTZ2AzFGK06/dhT+S8nBvVABkNhxycXMUmW0Lqaw23+7qHCQi1Kp1Sc3V9VpsO52F6UO742ap7o0K6eaMBzccZ+sEATQFRgghtkYBUCeg1mjxyFencDFbie9PZmH7PNtVFnaUSsy2hTAGe08wNM7IU2+wQuyN367gnf+lsEFRhJ8rUgv45QYi/d1oCowQQmyIPpo6gaySKt7qoawSM5suWsnXzdlsW0igXGq23dXJpCKjwor64AcAUgsqEeHXuGdThL8bdtEKMEIIsSn6ZOoEFHIZu/WCs4MYCrn1xSJNie/liw1HMnntpiir1WbbXV2NmsHckWH49XwOciuMd1eO8HPD9mfjkFteC7VGywY+1wpVVm2ZodZo2arg4T6uFEARQggHBUCdwM3Sanbrhep6LW6WVqO3v7tN7v17crZR+45I80FQpEKOomtKXpvwfX74OgBAKgY4gz9wkACpBSrM+OoUfpo7HNM/P4GL2Uo4O0hQXa9BdJDcoilOtUaL+9cdY1eRUR0hQgjho9+GxCyZRGK2LcRd5mi2TRqpDQo81zeUlU7KVmL7uWx2arO64YGL2UocSStssjp0VkkVG/wAjUnUhBBCdGgEqBMI6ebMmwIL6dZ0no6l8iqqzbaFZBaWm20Ty7y2M5kd+eHuMv/EpjMAgKggOXaYGA3q7uWCqCB54whQENURIoQQLgqAOgF7ToHd0z8Iey4V8tpN8Ze7IqWwltc2JALAGLQJ4CAC6jlvTHW9BuHeLsgsrkKwpzNulTUGoEkNCe9CS+OlEjF2zBtBOUCEEGICBUDErNiecrNtId1cHcy2AX7wI9TuqnYkjIBUIsHzP5xDakElwr1dkVmsC2JulVXDQQw0xLqICpKbHdWRSsQ2C4QJIaSzof8SdgIh3Zwhk+r+KmVS206BbTudY7YtRKQ13yampedXYv4WXfDjIAYyiyvhJG38MdUHP6FeLnhvalQb9ZIQQjo+CoA6gRxlDWoasmlr1FrkKGuauMJycT28zLaF1BuM5xi2iWkv/PQP0gt1Iz76YKdWrUWYQVB7o6QK9352FFPWJuJqbnmTSdGEEEL4KADqBLp7uSA6SDc1FR1sflrEWqo6jdm2kOfH9jbbBgDDSkW2q1zUObnIpPjyscFGx5NzyjHhkyMY9/Fh3L/uGGrq1LhWqKJgiBBCmkA5QJ2AVCJmdxG3plCeJQaFyM22hfxxPs+oHTnBk3fMMOnZsC0FoDZod2WXcysQ5uOKAYHuSM6tEDwnKVuJyWsTkZKvQnSQHNvmDmf3F6MkaEII4evqnyudhn4XcVs7f1Np1L6zj/nxGrmro9k2ANQ20TYcv9C3DbYZM2p3Vn38dKN6Pz49HKeul8LP3RFSiQSLt11gA6IIPzek5KsA6OoFTfr0CNKKdLV/zC2ZJ4SQrogCIGJWoNzZbFvIwBAPs20ACHQDslX8NpepAEjouAOA+iZ71bGlFFRh3MeH2XpA+orQO+ffzi51D/RwwrT1x5FSoEKEnxtSCxrfYHNL5gkhpCui/w4Ss3r5uWFAoG4p9QCFO3r5Nf0BWqSqN9sGAG9XJ7PtAH7TqM3l5950deqOTp9Grt809WK2EplFlexS93AfVzzy1SmkFKgQ6e+Gj6bH8K6PoN3kCSGEh0aAiFlSiRg7599uVX6RRCwy2waAPJXafNtgTsywzaWqbToxu6MzLBwJAAu3XmD398oqqWK3zUjJV0EiFiHC3w2p+brRoF9pHzBCCOGh34ikSfr8Iks/QPsEupptA0Cwl7PZtszgqQzbXC7GdRY7NG+DwpGBHk44sOQOo/O4+3txVwJGBcnx0s8XkZqvQqSfG36dHw+ZI/1fhxBCuCgAIjb3+cFMs20A6G+wQ7xhO6Sbo2DbxeBfrIsYqDYzOtQRFVfypwxzy2sx4/NTRudFBXlAo2Wg1mghlYixbe5wbJw1BAvG9EJSjm7/tZQClcm6UGqNlpbME0K6LPpvIbG57t1czbYBwNnBwWw7V1kn2DbcPV2tBRy6QBifW86P8v49sQ82HsvEuI8Ps0veH9xwnA18nKQi1KoZk3Wh1Botpq47hovZSjahmjvCp9Zo7VJWgRBC2gv6zUZsbnCYp9k2AEQHe5pt9wpwE2xH+vE/zCP9XFDFTx/q9KQi4J3/XUWOUhcUXcxWYteFHDb4AYBaNYNgT2dsmT1MMIDh5gxdbFghpqcPju5adQhT1x2jESJCSKdEARCxuZKqerNtAFB4OpttR4d4CbYr1fxop1Ktxui+3Zrd145IbZANLQHw8vYkOBr8NN8qq8a09ccFAxhz1cPNBUeEENJZ0BQYsbngbi5m2wBwOa/cqH1bWGPQY7jqXd+ur+cHQPX1akhEUqNzuRNGnb1OkH4NXJ3AQE1KgQqZRZWQiEW86Sxz1cP1wdHFbKXNt1YhhJD2ggIgYnO9/NwwQOGB5JxyDFB4CNYOCvOSmW2LpWLBto+HDDcrGkckfDxk8HHjX+soAbgr47viBI6TRIRaDYOoIA8s3PYPkgRyfUxVD7fn1iqEENJe0G+2TqI9reiRSsT4+Zk4bH5iKH5+Jk7wA/Svy4Vm25H+HoLt1Hz+dExqfhWqDabFDAvm+DZdvLpDc5QY11ny95Dhm5lD8OEDMUhqxnSWtaUPCCGko6Hfbp1Ae0taVWu0ePDzE5i58TQe/PyEYH8mRPmZbZca5A3p2z19+NFMTx9neLvwl8wbzIihqpPXSazTGJZIBLJKq/Hk5jN47odz6N+QQB4V5EHTWYQQ0oACoE6gvSWtZhZVsqMOSQ1bNhiqqTPf1jJawXb/IH5ydP8gLwwI4idBj+7nw2tH+HbdD/20gkqkN7z/jHGcRAghXRYFQJ2AuRU9bUGjZcy2AWBYWDezbRFEgu2ccn5Rv5zyGgTI+TWEGDX/2uJKg+iqi6ltWDaWnFMuGIwSQkhXREnQnUB7S1q1ZC+wW2U1Ru0+zo1TWUEGQZy+vXxKP4z+8Ah7fPmUfth5Npd3bnoBfwSstIsVCurh7QyxWIz0Qgp2CCHEFBoB6iTaU9JquI8rohS6pOWoIA+E+xhXgs5VVpttG16jb6uq+Qk9qmoNRkbwp7ziehvUEArlb7PR2WWVVAsGPxF+rgjp1skzwgkhxEJt+mm5cuVKDB06FO7u7vDz88OUKVOQkpLCO6empgYJCQnw9vaGm5sbpk2bhvz8fLP3ZRgGb7zxBgIDA+Hs7IyxY8ciLS3Nni+FcEglYuxIiMf+RaOwY57wLuRxPbzh3LCHhbODGHE9vHmPh3m7QCbVjRzJpCKEeetGgC7e4tcPunirHFKJhHfswvVSXruovGuNABkWSgSAILkMqQWVeHCDrjBie1o1SAghbaFNA6BDhw4hISEBJ06cwN9//436+nrcfffdqKxs/N/riy++iN9++w0//fQTDh06hJycHEydOtXsfT/44AN8+umn2LBhA06ePAlXV1eMHz8eNTXCm0IS22tqREoqEaNnQw2angLn5ShrUNPwSV6jZtgNPe+LCeSdd19MIM5n8QMeL3d+GcVhPbpWpWhDDmIgu+H9S8opR3qBql2tGiSEkLbQpjlAu3fv5rU3bdoEPz8/nD17FiNHjoRSqcTXX3+NLVu24K677gIAbNy4EX379sWJEycwfPhwo3syDIPVq1fj9ddfx+TJkwEA3377Lfz9/bFz5048/PDD9n9hpElZJVVIbti7KjmnHFklVbyifH5ujhBBV9JH1NAGAJmjFP0D3HApT4X+AW6QOUrh584vhDihfxD2Xi1m25NigrDp+C17v6R2RSoGPpgahcp6LfoFumHahpPsY2dulBitGhQqiEgIIZ1Z2yeMcCiVul/KXl66HI6zZ8+ivr4eY8eOZc/p06cPunfvjuPHjwveIzMzE3l5ebxr5HI5YmNjTV5TW1uL8vJy3hexr6ZWrp3NKmPrGTINbUAXOF3KUwEALuWpkFVSBYUnPwByMBhNkjk4oH+gOwDA16Vd/ZO3G7UWWPhzEpbuuoQZX55ij8scxHh95yW2TbWBCCFdVbtZBabVavHCCy8gPj4eAwYMAADk5eXB0dERnp6evHP9/f2Rl5cneB/9cX9/f4uvWblyJZYvX97CV0Cs0dTKtcHdPXkjQIO7ewIQ3qfqSBq/inRGUQWvnVVShYxCXdBUWt31pnu4hRJr6vmv/6PpA9tF4jwhhLS2dvObLyEhAcnJyfjxxx9b/blfffVVKJVK9uvmzZut3oeuyFyeUIGqjjcCVKCqY6/ZPm8E9i8ahe3P6va1MkyoHtOHH/zmKqvZfCI1o5seAnS5MV2NlFORwNQKPUII6QraxUfA/Pnz8fvvv+PAgQMIDg5mjwcEBKCurg5lZWW88/Pz8xEQECB4L/1xw5Vi5q5xcnKCh4cH74u0LWuKO0olYvRs+CDv6eOKnr6ukDVENzIHMbxd+IUS1Q2DIPVdbzCIXSEW4e+Gn+Y27tNGq8IIIV1NmwZADMNg/vz52LFjB/bv34/w8HDe44MHD4aDgwP27dvHHktJSUFWVhbi4uIE7xkeHo6AgADeNeXl5Th58qTJa0jbMPehKzTSo7/GcAVTVkkVknN1017JuRU4faOUneqpqdeipJK/r1iwpxPvz64oNV/FrqwTek8pICKEdHZtmgOUkJCALVu2YNeuXXB3d2dzdORyOZydnSGXyzF79mwsXLgQXl5e8PDwwHPPPYe4uDjeCrA+ffpg5cqVuP/++yESifDCCy/g7bffRu/evREeHo6lS5dCoVBgypQpbfRKiSH9h+7FbCWig+TYPm+E0VSYfoqMS2jfM4VcBmcHCarrNXB2kMDXjR/Y+Hnwk6TzlbW6P8trbf2y2j0HCVCv4Y+qGb6nmUWVWLTtH7N/N4QQ0tG16W+19evXQ6lUYvTo0QgMDGS/tm7dyp7z8ccf4//+7/8wbdo0jBw5EgEBAdi+fTvvPikpKewKMgB46aWX8Nxzz+Hpp5/G0KFDoVKpsHv3bshk/A9C0naau4Gr0NRYjrIG1fW6CtHV9Ro4OUh4lah7+PLzXOobpoG64hRYvQaI9HfDtqeHQyoRo6ZOjetFlRjQ8H5FB+ve2/a0uS4hhNiDiGFoj2hD5eXlkMvlUCqVlA9kJ7wRoGA5b5rLkmu5q8eE7gWAPQcApqxNRHJOOfoGuOFKwzL6ruzvF0cipJszBq34G9X1WsikIuyYF4/e/rpyAc39uyGEkLZkzed3u1kGT7qWlmzgajg1Zupe+nPUGi27t3xVLX9bjJBuMtwsrUHfADdcL65igwEA7MoxAAjtJsON0s5TSfypTafw8sS+qNbnSqkZ5JXXoK9CNwIk9H4KBZ7tZQNeQgixltUBUE1NDT777DMcOHAABQUF0Gr58wjnzp2zWedI5yaU42OPe2WVVCGpoeq0YRDj1PDBLRWLcfyVO7HnUgEGBMlx72dH2XPenxqF8f39MHzlAdSoO8e82Y3SGjz3w3neMW5FbcP30zBna9vc4Zj++QleO0dZQ8EQIaTDsDoAmj17Nv766y888MADGDZsGEQiUdMXEdKGunu5IErhgaSccgxQuINhgEu5Fejt54q0At2+c0k55Xjoi5NIyVdhQKA7m1QtAvDy9iR8f1KOE6/eiYU//YP9V4va9gXZiMZg8lut0eBQSgFiw70gc+T/ajDM2TqZyd9OY/LaRKTkqyhpmhDSYVgdAP3+++/4888/ER8fb4/+EGIfDYG6SCTGz8/oRisUchk7ihHp74aUfF1ukH5JPQC2GOPFbCUe3HAcaYWdNyF46vrj0DCATCrGjnkj0NvfnQ1kDCtwx4Z7sW3ue0d7ixFCOgqrA6CgoCC4u7vboy+E2EVWSRWSGkYrkrKVyFHWsB/Q+lwXbjAUFeQBQISkbCU7EsQdLdKTAkgY0wuf7Etv5VdkH/oRoRq1FhM/PWo0tWWYFyT03jVVtJIQQtoLq1eB/e9//8Onn36KDRs2IDQ01F79alO0CqxzsXTFGTepFwD74Z6jrMG1QhWe+vYs73yZg9hob63OJsLPFakFlUZTW5QQTQhpj+y6CmzIkCGoqalBjx494OLiAgcH/jYDJSUl1t6SEEG2+lC1dMUZN/HXsALy8HAvODuI2VVTgPHGop1RasOo18VsJdILVHCUivkjPpzAiKa9CCEdidUB0IwZM5CdnY13330X/v7+lARN7MKSStHWsOYDmvvc+imwqCA5eni74JJADaHONhLUy9cF6QK5TvevS0R1vdYo5yezqJKtH0QIIR2F1QHQsWPHcPz4ccTExNijP4QAEK4U3VojDNzn1leY1ucQcTlJgFoN4O/uhBsl1bzHpOLGTVc7C/3oV0q+ChF+bkgt0AVBC7dewI6EeJr6IoR0KFb/xurTpw+qq6ubPpGQFrBmN3h7Prd+fNPZQYIBge4N3+t+bGp1sRFulFRDajAQ2pGDH6HRH6DxdUcHy/HpjEHs8aScctougxDS4Vg9AvTee+9h0aJFeOeddxAVFWWUA0RJw8QWWlIp2hbPvW3ucOy6kIOXtycB0I0EffzwIOSUVWPmxtNG1+iLRvfxc8HVgs4ZDOyYFw9HqZgNRrnL4mnlFyGko7E6AJowYQIAYMyYMbzjDMNAJBJBo9HYpmeky2urxFq1Rssm+epzgKKD5Qj3cUW4jyv7wR8VJMe4Pn74aF8ae21FrfG/f6lYBLW2Y2+5Fx0sR5i3buNZoG0DVEIIsQWrA6ADBw7Yox+EtBuGOUCbnxiK+F4+7Ic894O/pk6Nj/elgYFuuixbWcu7l4NEhHrDkssdzOJxEZg1IpRWfhFCOhWr6gDV19djwoQJ2LBhA3r37m3PfrUpqgPUtVlbN8jLRYrfLubB28UB6w5mIDm3AgMU7lh0dyT83GW8fcU6qnBvF2QWN07t7V80ioIfQki7Y7c6QA4ODrh48WKLOkdIe2dqesewUKI+SBoQ6I70wkrUqLVwkojw1eODcXvDiFFmUSUGBLojObcC/QPd8NDQ7njj18tt+fKahRv8ODtIoJDLzJxNCCHtn9VTYP/617/w9ddf47333rNHfwhpF5raDX3V9Bh2moy7d1ithsFT355FVJAcYBgk5ZQjKkiOv18ciXAfV6QXGNcR6miq6zW87UQIIaQjsjoAUqvV+Oabb7B3714MHjwYrq6uvMc/+ugjm3WOkPbCsC4R0LgKSqhwILduUFK2EhKxbp38rdKOv0Isws+NVn0RQjo8qwOg5ORk3HbbbQCA1NRU3mNUFZp0Voa7oYf7uLLTZHVqLSZ8coR3vrODBD19XJCcW4HoYDkUchk7gmQJMYD2WkpoyfjItu4CIYS0mNWboXYFlARNhJjam0yt0eL+tYlIyinnnb9x1hAEd3NBuI8rskqqcNeqQ63d5RbxdZHAUSpCdrna6DHDneKlEjFq6tQ4mVmC2HAvyByt/r8VIYS0mDWf3y0KgG7dugUACA4Obu4t2iUKgIi11BotMosqsXDrBSTllDfWD2pYMq7WaDFoxV5U12vgJBWj1qBUdIS/GySMFlc6UBHFSD83pBSoEB0kx7dPDkHsygOoVWvh7CDBjnkj0MvPjeoDEUJalTWf31b/dtJqtXjrrbcgl8sRGhqK0NBQeHp6YsWKFdBq2+ugPSH2JZWI0dvfHTsS4rH5iaHsHmL6fcxullazx2rVug1FAbAJ0tuficP1Ul0NoY4wkRzq7YKUgsYNUf/vs0Q2qKuu12DCJ0cwdd0xqDX0O4EQ0j5ZPU7973//m10FFh8fDwA4evQo3nzzTdTU1OCdd96xeScJ6SikEjHie/nw8oUUchkeWH+MPcfZQYKtT8fin1vliA33glQixi9nb7EBEgPghbG9sHpvehu9iqbd4CyLD/VyNtoMFmj9TWwJIcQaVk+BKRQKbNiwAffddx/v+K5duzBv3jxkZ2fbtINtgabASEtx84WE8n/000fc5fJcZ/59J2ZtPIvknHIoPGVwkwKpRTWt+RKapXs3GQoqalGjZuDsIMH5pWMpH4gQ0mrsOgVWUlKCPn36GB3v06cPSkpKrL0dIZ2Svo6QVKLbPDRK0fiDGOHvxk4fJWUrjYIfALiUo8LOhHjsXzQKXz42pEMEPwDw7OheqGnYGVZfL4gQQtojqwOgmJgYrFmzxuj4mjVrEBMTY5NOEdKZSCVi7EiIx98vjsTfL47ErwnxiA6SA9DlAHGDIwCQScXs1FgPXzcUVHSMIMJJIsKrO5Ihk+p+rdAu8YSQ9szqsekPPvgA9957L/bu3Yu4uDgAwPHjx3Hz5k38+eefNu8gIZ2BPklaj7vVBgBkFlXiha0XcCmnHCFezrxrh4Z2gwi63CAuuUwKZY3xEvW2EOrtwuYF1ai1eHtyfzwwOJhWgRFC2i2rfzuNGjUKqampuP/++1FWVoaysjJMnToVKSkpuOOOO+zRR0I6He4UmT5IuNQwFZZWUIlJa45i7+U8XM0tR255rVHwA6DdBD8APykaAF7fdQkPfn6CVoERQtotKoQogJKgSWtSa7S4f90x3vYZXP0C3SECcImz5xhXgIcT8spr7djDpjlKRKjTGP8q2fzEUMT38gEAwSKShBBiS3bZDT4rK8ui87p3727pLQkh0AUGpoIfALicW4HP/3Ub5n53TvDxYlXbBj9SEQSDHyepGDM3nsYAhQdEIhGSGjaS3T5vBAVBhJA2Z3EAFBYWJrjXF8Mw7HGRSAS1uv0MyxPSEXD3GYsK8sDK+6Mwbf0x1HKCCpGZ8oj1bTzL1N3bBdeKdFNgThIRajUMQrvJcKNUl7ydzFnlRrWBCCHthcUB0Pnz5wWPMwyDH3/8EZ9++inc3OiXGiHWkkrEvKRoqUSMX54dgf9bk8ieE9TNGb39XJFWUNmGPRWmD34AYNvc4XB3dkR1nQb3fnbU6NyoIA9aGUYIaRcsHoeOiYkx+iosLMRTTz2FdevW4aWXXkJGRoY9+0pIp8VNigaAPoEeuiKJAPoHuuPFbReQVlCJ3n5u+OyhgW3YU/Oe33IeCrkMErHwiNVH0wfS9BchpF1o1m+ic+fOYdy4cfi///s/DB8+HOnp6XjzzTfh7u7e9MWEkCZJJWLsmDcCf784EnVqLVLzdYUT0wpUeG7rhbbtnBk3ymowac1RwdVfUUEeCPdxbYNeEUKIMasCoIyMDDz00EMYNmwYfH19cfnyZaxZswZ+fn7NevLDhw9j0qRJUCgUEIlE2LlzJ+9xkUgk+PXhhx+avOebb75pdL5Q5WpC2jv9SElaoelpr/6BbpBJ29f2qWkFlXjhR+Mpc62WFpwSQtoPiwOgefPmoV+/flAqlThz5gy2bNmCHj16tOjJKysrERMTg7Vr1wo+npuby/v65ptvIBKJMG3aNLP37d+/P++6o0eNcxEI6Yh6++lGUJwdJACAeg3YrSfak/SiKqNjl3IrcCStkGoDEULaBYuToDds2ACZTIaCggI8+eSTJs87d054qa6QiRMnYuLEiSYfDwgI4LV37dqFO++8s8nASyqVGl1LSEcU7uOKqCA5krKViAqS46e5w3EyswQzN54GAKQWqBDh54pUTnK0GEB7CTGcpGLUqht788SmM4gKkmNHw1J47qaxlBtECGlNFgdAy5Yts2c/mpSfn48//vgDmzdvbvLctLQ0KBQKyGQyxMXFYeXKlWbrE9XW1qK2trGWSnm58eaUhLQFfS4QN0iI7+XDLpuPDpbjm5m3Ycg7B9hr2kvw8/aU/ohSeGDRtn94I0JJ2UpkFlUi3McVU9cd070Oqg9ECGllHSYA2rx5M9zd3TF16lSz58XGxmLTpk2IjIxEbm4uli9fjjvuuAPJyckmk7RXrlyJ5cuX26PbhLSYfoUYt7193ghkFulGff66VNhWXTNJBOD1nZcAAE4COUp1at3Iz8WGApD6+kDdvVxoRIgQ0irazVYYIpEIO3bswJQpUwQf79OnD8aNG4fPPvvMqvuWlZUhNDQUH330EWbPni14jtAIUEhICG2FQdottUbLjp70V3iw+4h1FM4OYpx+bQwe+eoUO5K17enhmP75CRoRIoQ0m122wmhLR44cQUpKCrZu3Wr1tZ6enoiIiEB6errJc5ycnODk5NSSLhJid9x8Ge7oyaWccvw+fwQu3irHdydv4HJuBQYodD/4+irM/QLdUVpZh9w23jNMr7peixOZJXhhbG8EymXo7e8uOCJEFaMJIfbSIQKgr7/+GoMHD0ZMTIzV16pUKmRkZOCxxx6zQ88IaR3cEZ/oIDm2zR3OywPqEyjHgOBumD40hA2SMosqMe7jwwB0+4m1J05SMeZ9fxZ1Gt2KtvNLx/K2BIkOlltcMZoSqQkhzdGmAZBKpeKNzGRmZuLChQvw8vJik5bLy8vx008/YdWqVYL3GDNmDO6//37Mnz8fALB48WJMmjQJoaGhyMnJwbJlyyCRSDBjxgz7vyBC7MRwdCRHWWO0fQbAzxcK6eYMZwcJqus1Rqux2kqwpxM0Wi1yy+vZY9X1GpzMLMGoSD/B12SOYWDY2tNmNXVqnMwsQWy4F2SOHeL/k4SQBm36E3vmzBnceeedbHvhwoUAgJkzZ2LTpk0AgB9//BEMw5gMYDIyMlBUVMS2b926hRkzZqC4uBi+vr64/fbbceLECfj6+trvhRBiZ0KjI4bJ0YZylDWortcAAGrVWna5fP9Ad9SqtUg3U2DRXm6VGU/BiQAM7u4JwDjhuyltOW1WU6fGoBV7UV2vYUexKAgipOOwOgn6008/Fb6RSASZTIZevXph5MiRkEgkNulgW7AmiYqQ1mLtVA9vdKQhyThHWQOFXIb71hzl1Q5qa29P7o8HBgdbHUAYvsbtz7beCNChlAK2HhMAbH5iKEZFNq8qPiHENqz5/LY6AAoPD0dhYSGqqqrQrVs3AEBpaSlcXFzg5uaGgoIC9OjRAwcOHEBISEjzX0UbogCIdBZCQVNafgWbGwQAUhEAEdCaM2QhnjLcLKvhHZNJxTjz7zEoUNWx/dX3XyGXIUdZIxj8tVUOEI0AEdL+2DUA+uGHH/DFF1/gq6++Qs+ePQEA6enpmDt3Lp5++mnEx8fj4YcfRkBAAH7++efmv4o2RAEQ6Wy4gcS09cdwqY2Toh0lAEQi1Bls4xHu7YLM4io20Vu/LF6fy9TelsdTDhAh7YtdA6CePXvil19+wcCBA3nHz58/j2nTpuHatWs4duwYpk2bhtzcXKs73x5QAEQ6E+40UaS/G1IadpZvbxwlItRpGn8dbX5iKG+KSW//olEdbnk8rVQjpHVY8/lt9U9ibm4u1Gq10XG1Wo28vDwAgEKhQEVF+1p2S0hXxU0UTslXobeP8fLy1v5IFgPoG9AYxHTvJsPWp+MQ4ac7FhUkh7+HDFFBcgC6ZfMArFoe317oA9C7Vh3C1HXHaDNYQtoJq8ds77zzTsydOxdfffUVBg0aBEA3+vPss8/irrvuAgAkJSUhPDzctj0lhDSL4QqybU8Px/XiKtwsqYLC0xmOUjF83Rww9j8HUVStaZU+aQFczWscicoqrcH9648B0O14z2i1mPDJEQwIdEeEnxtSC1SI9HPDtqeHd7gRFCrwSEj7ZHUA9PXXX+Oxxx7D4MGD4eDgAEA3+jNmzBh8/fXXAAA3NzeTdXsIIa1Lv3cYN5m4l58b+gTqhof1IxStFfzomZp7T+OsTkvm5CqlFKiQo6zpcMFDcws8EkLsq9l7gV29ehWpqakAgMjISERGRtq0Y22JcoBIZ2SqaKDhqrDW5iQVI0juiGvFjavCenk7I724GlFBHgBESLLBMndb5uFw7wWgyftSDhAhraNV9gLr06cP+vTp09zLCSGtSK3RIjG9SHD39Re3XmjTvgXLHfHRQ7dh8rpj7DGRRIJvZg7BiJ7ekErEzQ4euKvfrNlo1VzAwg0ko4LkAMMgKafc7H2tLfBICLE/qwMgjUaDTZs2Yd++fSgoKIBWy0/o279/v806RwhpOe4HNrucvGEqJrOokt0wVU8E3fSUzEEMjUaLejvn7GYU12DRtgu8Y2kFKjy5+Qwi/dywa358k8GDUMDCW/3m54aUAl3OUVN5OIar5nYlxPOWuHNzepIa/rTkvoSQ9sXqAGjBggXYtGkT7r33XgwYMAAikcge/SKE2Aj3A7u6XoPNTwxFfC8fwZGKrx4fjEC5MwoqahAod8aET47YvX+OEhHSi6oEH0spUOG+tYn4NSGerWLNLYio1miRWVSJhVsvGI3C8Fa/FajYEgBCeTjcAMpw1dzkNYn4Y8Ed7PvFzenhjQBRfg8hHYrVAdCPP/6Ibdu24Z577rFHfwghNmaYhMsNfsJ9XBEVJEdSthIR/m5Y/XcqknMrEB0kx5anhrXKJqrc2j8A4OMqhbJGjYZtzJCarwuCUvNVvIKI3EKJetxRGKHVb0LVpA1zo7bNHc6rl5RSoOKN7HCTyi3NASKEtD9WB0COjo7o1auXPfpCCLEDww9s7oe0VCLGT3OHY/KaRF6BxIvZSpzNKmuVHeQdJCKAYdiptqJK4zpjqQ1902/uejFbiZOZJbzgB+DXCRJ63ULTU4bL1HOUNdiVEK97TwqER4y4uPelZGdCOg6rf0IXLVqETz75BM1cPEYIaQP6D2mhD+UcZQ2bH6MXFeQBP3cnDFDYfxVkvYbBfx6INnuOk1Q31e7soNtkOTpYjthwL0Q3FEqM8HPD7gV3GK0S475utUaLa4Uqo0KECrmMva+zgwQKuQwyRyn+WHAH9i8axd5Tf31NnVqwsCEVPCSkY7F6BOjo0aM4cOAA/ve//6F///5sLSC97du326xzhBD7M8xp+fCBaCz5+SImfnoUAxQeeHtyf7y+65Jd+/De7hSzj9eqGXz1+GAEd3OBRCxCuI8rpBIxtjw1DJPWJCK1QIWXfr6I7fNG8K7Tj8j4uTli2vrjuhEdg9VaOcoadmSpul7D1hoyHNlpKqHa3gUPaXSJENuyOgDy9PTE/fffb4++EELagOFUUVZJFbu6KTmnHK/vusTm3thLbnltk+es+O0ybpRWswGMWqPFtPXHkVmsS6A2DDq4QQs3l8nwPH4A6IHaeg3S8ivYIAuARQnV9ix4aKqGEyGk+awOgDZu3GiPfhBC2hB3tEM/JcQNeKrrNVhxX38s/dW+I0EA4CQRoVbDIMzbBdeLG1eH3SitBqALYBLTi6DwdOZN3UX4u/GCDm7Qws1lijQ4TyoRY9vc4TiWUYxVf6di4qdHAQBRCg/sSIiHVCK2KKHaXK5VS9F2GoTYXrMLIRJCOh+1RouTmSVGoz3RwXI8OCQYP5y6gct59t1NvlbDINTLBTvnxeHBz08izSA/SQRg5sbTiAqSY0CgO7tdhqNBwNHdywVRCg8kceocRfjp6voYrgIzXE0GAEk55bxAY9X0GABgR4ZMJT5bGphYM6VF22kQYnsWbYVx2223Yd++fejWrRsGDRpktvbPuXPnbNrBtkBbYZCuSKhgYlSQHB9Nj0FIN2fkKGtQVVuP/1tzrOmb2UAPb2dcK642e87GWUPwxKYzbPvvF0dCIhaxAcKRtEKjx3v7u/Puca1QhbtWHTK6d1SQB3bMiwcAk9NPzZ2aas51lANESNNsvhXG5MmT4eTkBACYMmVKiztICGl/TBVMBID71x1DUrYSvf1cW60/TQU/UUFyxPXwZkd5Big82IKI3AKF+vyf6GA5wn2M+9/dy4WthQQAvX1dsfrhQXCUGuf/cKefTG0vYskIUHOmtGg7DUJsy6IAaNmyZYLfE0I6D1MFE9PyK9jgIK2gEr19XZFWWAknCVDbMFPmKBWhTt26pTG0moYnbxiRVtWq2Zwh7hYVtWotwr1dsO3p4Sb36fpoegy7IWxaYSUWbrugS3JuKIxoOP1kbnsRQ0IjNzSlZTka+SL2QjlAhBAAlifxvjyxDwLlznhh63mkFVQiyFOGhWN6Y9EvSa3a30t5KpzMLGGDnevFVXCUiFCnYRAVJEdtvRqpBZUAgMziKpzMLDG5BUi4jysbkHCrQOsLIxq+L9cKVRZtL2JqqsueCdOdCa1+I/ZkUQDUrVs3i/f8KikpaVGHCCFtR2iaJdzHlZ1mcnYQ46lvz7KBBgBkl9W0evADAKHdnBEb7oUIP1c20KnTMPhm5hCMjPCFWqPF5LW6CtfODhLM3Hja5IcoNyDh7RzfMDpj+L6Y216Ey9xUF1WQbhqtfiP2ZFEAtHr1avb74uJivP322xg/fjzi4uIAAMePH8eePXuwdOlSu3SSENJ2pBIxdiTEIzG9CDM3ngZgvH+XyWtFgFgssvh8S4kBbH1mGGSOUnzy8CB26ToAhDQEEVKJGH88fwev3+Y+RLkBSVOjM4YBk6lzLZnqolEO02iqkNiTRavAuKZNm4Y777wT8+fP5x1fs2YN9u7di507d9qyf22CVoERYoz7Qd1eJC8bB6lEjEEr9qK6XgMnqRhn/z0Gbs6O7KiK4YgOd7uMmjo1TmaWIDbcCzJH6zMCLAlemhrdMVyFtn/RqHY1ytHWo1Nt/fykY7H5KjCuPXv24P333zc6PmHCBLzyyivW3o4Q0kHoRz0yiyrx4tYLSObU1wEAB7EI9drWTYT+JvE6JkYFsnWLatW66tC75sc3Bj0NicyGhQtr6tRs4OTsIMH5pWOtDoIsmaJpavVWW41yWBJYtIfRKVr9RuzF6n/J3t7e2LVrl9HxXbt2wdvb2yadIoS0T1KJGOE+rvj4oYH43/O3I6phs9RgT1mrBz8A8NHeNLy49QIcJY05iikFKt5O8fpEZu5msGqNFrsu5PD2ADuZaX3+oj54AXTL8jVaBmqN1uTGq0L0gSV341V7s3TjVqEAj5DOwuoRoOXLl+Opp57CwYMHERsbCwA4efIkdu/ejS+//NLmHSSEtB+GIwI/zIllNxltK4YjUWFezhjc3ZO3v5dGy6CmTo0cZQ1vSkwEgIFuF/jYcC+Ln5M7eqIfFVu49QLGfXxYFxSKREiyYtSktUc5LE0uphwc0plZHQDNmjULffv2xaeffsru/N63b18cPXqUDYgIIZ2T4Qfn2awyo+BHH1QYcpQAdXbYT9VJKkItpwbR9ZJqTNtwHFufjsW5LCU++jsV4z4+zNbr4a4aYwC8PzUKkwcq2OkvbnADgM0j0k+hAcaVoSViEbvlBnfrjfa6csnSwIaW65POrFl1gGJjY/H999/bui+EkHZOIZfxdkIf3N0TkX5uSClQsQGGqYkwewQ/AHjBj15KvgpD392Pes7qM/10lz74AYABCg/cFtpNcGsL7kgOW+wwSI5V02OMRk+4AcUAhTsyCqvYpGw/N0fBfBtbJ/dacz9rAhvKwSGdlUUBUHl5edMnNaBVU4R0TvpNQ1PyVYj0c8OW2cPwyFenkFKgQri3CzKLWzc/pF+Am9mNWesNlt4b7nAPALX1aoz7+DA7ksMd4eKO5Oiv0z+mr4sUFeTBBhD6qbBbpVXs/mO1ai2mbjgOJ4kYSTnliPRzw675us1YW5JcbBjsNCdZmQIb0tVZFAB5enpaXAhRo7HTf/MIIW2KGxykFKhwNquMbWcWV6G3nyvSOKMr9nRwyR3wlDni7tVHUFBRZ/bcCD83rH30NoR0c8bN0mreCra0Ql3QJjSSI5OKUNMwuqQv/BgdLEdIN2d2+w3dhF+jRdv+wcVsJbv/GACk5jcGaSkFKkxem4g1j9zGG0XKLKpEb3933tJ9w1VrekLBDhUMJMR6FgVABw4cYL+/fv06XnnlFcyaNYtXCHHz5s1YuXKlfXpJCGlzCrmMHUVxdpBgcHdP3iaisK6kWIs8tekcskqqmiywGCR3wocPRCHcxxVSiRi9/d3xnwdjMOGTI7zzooLkvJGcw6mFeHJz4y7ydRoGYV7O2DJ7GHKUNexrTuIEG9wgpFatRbCnM26VVRtty5GSr1sd5uwgRnW9Lkh6cesF/PxMHJucrX+fI/3dsCshnrc8XyjYoWRlQqxnUQA0atQo9vu33noLH330EWbMmMEeu++++xAVFYUvvvgCM2fOtH0vCSFtLkdZw1s2XqCqM9hEtIqXYGxP6YX85/Bzd0R5dT07YqOXrazF5HXHMUDhgZ0J8QCAJT9fZB/XJ2Yz2sZl4FKJGCECAcT1kmpMXXcMvz53O2/fMIVcBoCfWOzsIMGtsmpE+rnhh6eG4VZZDZ7/8TxSG3KnpJLG4AfQrWTjLt3Xv88p+SpMXpOIPxbcYXYjVcOcHkBXYJESlwkxzeqfjOPHj2PIkCFGx4cMGYJTp05Zda/Dhw9j0qRJUCgUEIlERlWkZ82aBZFIxPuaMGFCk/ddu3YtwsLCIJPJEBsba3W/CCHGuDVv9B+8+k1EASAqyAOfzrgNu+bFwcHMb5ZXJ/SB1LIZdYsVVNRB4eEIiYn7JueUI6ukClklVbyd4vWJ2cm5Fcgsagyqwn1cMUBhnM+YWliJm6XV+OCBaEQ0JINP//wE1BotG4RsfmJoYwBToMKkzxIx4ZMjcJKI8feLI7H92REI6eaMCP/GKaqoIA/Ehnux76WTtPENTClQ8ervmKobxM3psaTGDyFdndUBUEhIiGC9n6+++gohISFW3auyshIxMTFYu3atyXMmTJiA3Nxc9uuHH34we8+tW7di4cKFWLZsGc6dO4eYmBiMHz8eBQUFVvWNEMIn9MGrP/b3iyMBiDDhkyN46ZckcAY3jIKhlbuvQmDhVotdK6mFuRkxLxcp/NwceUUTubjFC6USMf7zYIzROb19XfHij+cx4ZMjbG4Pt0CgVCJGbLgXIv10gYiTVIzMhseScsohEeuee/rnJ5Car0KEnxv+eO52fDR9IO/9PfvvMew9hKa09MGOpRuwEkKMWb0M/uOPP8a0adPwv//9j637c+rUKaSlpeGXX36x6l4TJ07ExIkTzZ7j5OSEgIAAi+/50UcfYc6cOXjiiScAABs2bMAff/yBb775hrbqIKSFhFYOSSViXR0cfYJ0voqdCovwc8W2ucN1H/itlCBtyn2fJULmKBHMG+qv8MBLP19EUk45u3XG4p/+YR/v5ecKEcMgrdD4NTg7iFGn1rIVoCevTURKgQphXs64XlLNnhfp74buXi68ACW1QIWF2y7oygo0PC8AyByl+GPBHc1aJk/5QIRYxuoRoHvuuQepqamYNGkSSkpKUFJSgkmTJiE1NRX33HOPzTt48OBB+Pn5ITIyEs8++yyKi4tNnltXV4ezZ89i7Nix7DGxWIyxY8fi+PHjJq+rra1FeXk574sQYjnDLSEcpRIAgJODFG4yR/y5YCT+9/ztcJK0XR+zympMBmHPjurJLnu/mK3EjvPZvArTr0zow64YM1Rdr8WET47g/rWJuG9NIlIaRoa4wU+Eny6ZWSoRs8nkgG6EKIUzkjR5TSI7dQVAcJSnpk6NQykFqKlTG/VFv4ps29zhrbq1BiEdUbMKIYaEhODdd9+1dV+MTJgwAVOnTkV4eDgyMjLw2muvYeLEiTh+/DgkEuPfpEVFRdBoNPD39+cd9/f3x9WrV00+z8qVK7F8+XKb95+QroKbhKvRMmxiNHeVlEbLoJZTJSOkmww3S2tatZ9OEhFqNQwkALgFO+b/cJ79XiYV49Udybzr/NwbC0BG+LtBq9Ui3SAgSsox/R+ntY/exq7k4iaT16q17H0j/d2Rkl8BgL+6izsKZG4DV1O1gGg3dUKENeun4ciRI/jXv/6FESNGIDs7GwDw3//+F0ePHrVp5x5++GF2hdmUKVPw+++/4/Tp0zh48KBNn+fVV1+FUqlkv27evGnT+xPSFeinx7iJ0fopGLVGi4Qt53jnM1qNzZOhm1KrYbD0nj4wV62sRm2cNLz453+Qkq+Ck1SM1HwVL/jp7esKQJfIHNXwuiP8GpOoo4PlCPdxZc/3c3NEeMO0VHSwHLsS4rF/0SjsShjBe9/83Bxx76dHeMnMJzNLTG7gKpT709Smp9Zs2kpIZ2P1CNAvv/yCxx57DI8++ijOnTuH2tpaAIBSqcS7776LP//80+ad1OvRowd8fHyQnp6OMWPGGD3u4+MDiUSC/Px83vH8/HyzeUROTk5wcnKyeX8J6YqEtlm4VqjCDc6UEADcUtbb/LmD5E7IVtaaPWflbtOjwfqChwDYQogRfq5swnOtQHDk5CDB3y+OZIMcw33EuCMvNXVqDH13P7tNxpbZwyBzlLJ5Vfr3TSGXYfKaRHafNX1AExvuxavFxN3AtbuXi1GFalMFEtUarW4D123/WLVpKyGdidX/2t9++21s2LABX375JRwcHNjj8fHxOHfunJkrW+7WrVsoLi5GYGCg4OOOjo4YPHgw9u3bxx7TarXYt28fW7SREGJ/hquUunu5IMLP/pWJmwp+AMAwhtGvCgtwd+AlSP/8TBz2LxqFX+ffzo7MyKTGvzKTOau7uAGP0Eot7ghOrVqL0zdKca1QhZo6Na4V6oKdHr5uyFHW8DaZjfR3R3cvF8gcpTi/dCw2PzGUN/3FMqhQLVS6QD8qNO7jw2ziOq0WI12R1SNAKSkpGDlypNFxuVyOsrIyq+6lUqmQnp7OtjMzM3HhwgV4eXnBy8sLy5cvx7Rp0xAQEICMjAy89NJL6NWrF8aPH89eM2bMGNx///2YP38+AGDhwoWYOXMmhgwZgmHDhmH16tWorKxkV4URQlqfVCLGr/PjMeGTI7jeynuG6fm5OaBAxR910u8k7yQVI6/C4DEHKRRyGU5mluDbJ4fgn1vl8HSWYvI6/oKK6GA5FHKZyfwbfX2hcB/XhhEcXRFEJ6kY/9mTgku5FbzNVrfPG8FbyRXh54rVDzUuyZc5SjEq0o9t63N8NFpGsEK10GjcRU4tJEC3KSytFiNdjdUBUEBAANLT0xEWFsY7fvToUfTo0cOqe505cwZ33nkn2164cCEAYObMmVi/fj0uXryIzZs3o6ysDAqFAnfffTdWrFjBm67KyMhAUVER237ooYdQWFiIN954A3l5eRg4cCB2795tlBhNCGldMkcpfp8fj0lrEpFZXAURYHLneEt5OktQVm2c0SMVgVdrSAQYBT/c6TLDqa3Qbs7wdXNAzFt/8x7jFih0dhBjx7x49PJzE5xqUshluG/NUXblWVSQHD/NHY4ePq64lFuBWrUWl3J1Sc/czVa5gYt+mmrip0cFp6m4ic8DAt0R4e/GVpvWBzSGpQu6e7kgwtcVqZwl/XWUA0S6IKsDoDlz5mDBggX45ptvIBKJkJOTg+PHj2Px4sVYunSpVfcaPXo0GDP7B+3Zs6fJe1y/ft3o2Pz589kRIUJI+6DWaPHIV6eQWVxls93jhYIfAEaFFoV+y2QraxHm7YLrxVWQOYhRw6ne6CaTYsqaY0aBEbddXa+FY0NApNEy7L5okf7u8HNzxOQ1ibxl90nZSpzMLGGDHi79qBB3aw3D+kpCm5xyA6/khvtG+rlh29PDzebzODrwV9Gm5qtoA1XS5VidA/TKK6/gkUcewZgxY6BSqTBy5Eg89dRTmDt3Lp577jl79JEQ0glwP6wzi6taJSfIHAeJiJ2OC/dyRqBH48jypdwKXC+tNnUpAGCAwp2d+hr38WFotVqEeTkjJb8C09Yf5+XwALoRoNhwL3alGFeYl7PR1hqAcA4PF/dxvZQCFU5mlrCFGQ1XeWWVVPFqHJm6t6VoJRnpqESMuSEYM+rq6pCeng6VSoV+/frBza3z/M+hvLwccrkcSqUSHh7G+wERQqzHq1MTLMe2p4cjs6gSc/97BlmtXA9IKjZOhubq7ecKmVRitrZPVJAcH0yLwsRPhct/6Kth9/Z1waczbkO4jytylDVQyGU4ml6Ep749a/Le+xeNYkdjDPOIhAojHkkrwgd7riKtoJLNJ4pSeAAikdEqr5o6Ne777ChSCysxQOGOjx8aJHhfS5iqPURIW7Hm87tZhRAB3Yord3d3uLu7d6rghxBiH0LL43v7u+ONSf3NBgN6TeUM9fRxQb2WQVaJ+ZEbiUgX/Ji7n6NEjB/mxGLahuNspWZDSdlKPPudcL/DvJzh0FANW+bogHAfV0z//IQuV0fhgVq18dSdPn8n0t+dnQZjl6tvvcBu08ENMmrq1Lw8oyBPZ2SX6V4/N3jjFlZ8cMNxTv6PqNnBDyBce4im0UhHYfW/erVajaVLl0IulyMsLAxhYWGQy+V4/fXXUV9v+7oehJDOg7s0XK3R4v61iXjq27Ps8nKnhsqIQhuWNjVUnVFUhf8bEGB2J3oA7Iap5u53KbcCh9MKTQY/etdNBFvXS6pxqSEA0ef+sLk6OeVIM9iSIypIju3PxCHSzw0p+RWY/vkJ1NSpcb9+uTpnm470AhXS8itwNbcc963l5xlll1Wzidrcwoz6Ka6skipeYJScU96i5e9NTdER0p5ZPQL03HPPYfv27fjggw/Y2jrHjx/Hm2++ieLiYqxfv97mnSSEdD6ZRZXsh7G++nJvP3d8/NBAhHRzxrGMYjy5+YxV91x3OBMiAGtmDIIYDOb9cKHZ/Zu3pfnXckUHyzG4u6cuuDHIC+rt54p1jw5GuI8rskqqeIUPj18rZhOgue5fl4jqetPzd7VqLTY/MRTxvXwA8GsTcYslArrAy9KgRWhLDaFRPUI6CqsDoC1btuDHH3/k7eIeHR2NkJAQzJgxgwIgQkiz6YsKyhylGNHTm82jsWbJPAPgrd8vwd2xdT6MzVWf3jhrCOJ6eOPBz08gpUCF3n5ucBAxuJyvG7XJKqmGr5sDMosqodZo2eAkOliOQLmz4D2Fgp/efm4Ao0VaYRWig+WI7+XDBiPcKSmpRIwdCfHs81kSsDQ1DWe4zJ6QjsLqAMjJycmoBhAAhIeHw9HR0RZ9IoR0AeE+ruzScf0ycP2IhFqjxfTPTyC1oBKRfm7YOjcWey4V4OXtSRbdu6CiDgV27n8Pb2dIJBKkFQhPkw1QeCC4m4tupKthJCetQIUXxvbC5XxdAdhatRZD39kHfUzTX+GBb2YOwYie3pBKxGxA1MvHBbeUNaip1/KCQf3mriKGwfZ58ShQ1bEjOtcKVYKjMlKJGOE+rhYlL3OTnPUo14d0Flb/F2n+/PlYsWIFuwcYANTW1uKdd96h2juEEItJJWLsmDcCf784Ej31m4U2LErlJtemFKhQqKrHbaHd0C/Q3eb96Onr2vRJAq4VV5sMfnr5uqCmTo1xHx/G8z/wtwhavTcd3Awn7oDOpZxyPLn5DCavTYRao8VPDXlB6UVVbJ0iBsBbk/pixX39UduQ0JRaWIlJaxKhkMug1miNNlE1lFlUaZS8LIT796BHuT6ks7BoBGjq1Km89t69exEcHIyYGF159n/++Qd1dXWCG5QSQogp+mJ/+iJ+SQ1JuYZbQby49QKSc8p5lZibEu4tQ009g9xy8/uDZRRWmn28Obi7xacVVqG3nysv8Zk7nSeTio12oE/JV2HymkR8MmOQUd4QALzx2xUA/M1bM4urcN+aRAAMmxgtNFqj1mixcNs/bFu/caoQ7t9DVJAcH02PYTd9NTXCREhHYVEAJJfzC21NmzaN1w4JCbFdjwghXQr3Q1Y/uiCViLHlqWGYZFBNWWg3dlMyiy2rLdQ/0F2wOnNzCAUzAPD+1Cg4O0px/7pjRo//8uwIvPjjeaQWVvICmpQCldHokaE6DYNgT2fcalj6nmoQLOk3UeXKKqniJVd/NH2g2SDmgweikausRlwPb8gcpVT7h3QaFgVAGzdutHc/CCFdlNBKIrVGi2nrjxttl6HPFTL0+sQ+2H7+Fi7nmV+2LqSu3rgmj4MY8Pdwwq2yxtGjCH83MBot0op0fQr1csENztTR5/+6DZ/tS0NybgWbm6P30BcnsGPeCKPgJzpYDkepmK3LU6dhEO7lgsySKkT6uyMl3zgw444mRQV54IenYtnK01FBcoBhkJRTjkh/N+xKMA5ODANO/YiOIX2ZAu6KsR0Nf09U+4d0Bs0uhEgIIbZiuJKIuyScS6tl8Nakfnjjt8u842G+rqhvYiuGUC9n3Cip5o2yAGADGgDo6eMMtYbBjdIaeLo4wcVRqkvE9nfDroR4AMCxjGJ4uzrg4q1yLP31Enutg0TMTuVxgx9Al+dz8Ra/qvQ3M4dgZIQvAPACki2zh+HU9VJ4uzpgyc8Xkcqt7hwkB6PVlwxwxYcPxEDmKMUfC+5gA0j9+2dqesrSpeuGNYOSspXILKpEuI+r0YgdIR2R1QFQcXEx3njjDRw4cAAFBQXQavm/dEpKSmzWOUJI19Tdy4VdIRbkKUN2mW46q1bDYP3BdN65DiKgTq1bAm7OjZJqOIh1oyy9fF3BaDTIKOFPk2UUNRY2TM4px8ZZQxAod4ZErEtb1ldzNjRA4Y4RPb3ZwMCQk0SE+2ICseXkDSTnVmCAwp0NfrJKqrBt7nB2m4wHNxznBR4Rvq7Y9sxwnMtSQsswbNXstIJKTPjkCDsNxQ0gmxqRsWTpumHNIABYuPUCdiTEU+0f0ilYHQA99thjSE9Px+zZs+Hv7w+RyLhiKyGEtFjDirCiCn6QkltRx2vXM8C8LectuqV+9izdgsRnEYAnNp1hR18iGzYrNdVV/cgKt2aOk1SMWrUWvf3dIZWIIRLrggWRSLcnl37qSh/EGI66ALoVXvqSAIDxNKC9pqH0NYMOpxayBSn1Seo9fN1o2ot0eFYHQEeOHMHRo0fZFWCEEGJr3ECg1jhFxyx90NFS+kms6oYcIXPbYlzKrUB6gQp9Aj3Q298dOxLicSStEE9s0gUOyTnlOJlZwiYfJ2Urce+aRNxoyHHi7tVlOOqiLwapV12vxcZZQ/DRX6ls0USFXNbsVVlCFZ71pBIxRvT0ZqtY05QX6UysDoD69OmD6mrzmw0SQkhLcBN19SMwTemv8EBtXT3Si6rR01tXRTmjuPF3lQSAlbEUAMsDqlxlNfoEerCVk1f9lco+FhUkR2y4F/uaDJfF9/J1YQMQw0rNId2cedNiAxQeuKO3L+J6eONkZgkGd/dkp+aig+TsdJolwVBTK7r0BSlTClSI9HfDtqeH05QX6TSs/pe8bt06/Pvf/8ahQ4dQXFyM8vJy3hchhLSUfjpp/6JROL90LDbOGmL2fEeJCG9PHoD0hhyejOJq1Gv5icga6BKhd82LM1tQkbuZaoSfG355Jq7J/jpKRYjr4c0GFOM+PoxkzijOhw9EQ+YoZV/TS+P78K7nxndSiRi9/d3RVyFHb393yByl+OmZOET46VZridAYmMzceBrT1h/nrcqavDaRLYJYU6fGtUKVUTFEtUaLa4UqswUR1RotjqQVNhakzFfhWEaxYGFFQjoiq0eAPD09UV5ejrvuuot3nGEYiEQiaDTN+T8WIYTwcRN17+jtyyZFD1B44N37ozBtfSKb01OnYXAwlb/5RVapcR2gGyXVSNhyAesevQ33rU00etxBIsKRl0bick4lAuUyhPu4IqPQeC+yvv6uyCypZqsz9/LWjbYIVU4GgMXbLuDjhwch3McV3b1cUFWrhlQEqBl9v6qQll8BJwcJb+RGPz2l0TYWN0xqmE7jVsrW5ydx85QuZisxeU0iL8dIX2JAP+oTpfBg31fu9JZao8X9644Zbcb65OYziFJ44Kdn4iweZSKkvbI6AHr00Ufh4OCALVu2UBI0IaRV6LfN0OeqZBZVwrAc0OgIP3y6L73JTVNvlVXjwc+PoaePCzKK+CvH6jUMRn14BLVqLQYoPCASiYyCgLen9EdsuDfGfXyYPXY5v9KognWYlwuuN4yoJOdWYNzHhxGl8AAD8EaH9J7/8TzSCirZYAWAyUCFO50WFeSBD6ZFs9Nl+ukwbh0hbqI0N0hLyinH3y+OhEQs4gUzhsUSuZJyyjF5bSJS8lVUCJF0aFYHQMnJyTh//jwiIyPt0R9CCBHEHRHSGExv9fJxhptMajb48Xd3Qn6FrrBhrZoBN62HWxtIn+8jFKQAwBeH0jGhvx8i/N2Q2jDaMkDhzgYQ2+YOZwMEw/wlwxVeXGkG21fov9df9/eLI9nXfrO0GtvmDsfN0mos3PYPJn56lA1G9KvJFHJZY24QZ3RHqBCifmRIn0jNLUNgKMLPlTfKZOsVaOaSsgmxJasDoCFDhuDmzZsUABFCWg33QxEAlvx8kX2st68rfnvudl3ujEFysUQE6GsSers6oKy6DrVqBk5SMa+Kc7CnDLUahq03ZE5WaS2GvnMADHRTZvUaBiJR4wd1jrKGDRCq6zX46vHBeO6HC6iu18DZQYwePq7s1hsyBzE7jaZf3s4NVriBimEytH5vrqRs46rM+oBEqF4Pd7k+9/01TIbe0XCORsuwKQ4SsYg3ymQ4bdbSwIW22SCtyeoA6LnnnsOCBQuwZMkSREVFwcHBgfd4dHS0zTpHCCGGH4qrOB/6ALDuX4PZ/Jsdz47AvZ8ewY2G/B9uQebLeSp89fhgSMQiDA3thmkbjrOByrVi61a26m9b3/AESZzgg7+BqAckYhE7ClRdr8V/HoyBSCRCrrIafu4y3PvZUfaxzU8MRXwvH/ZDnxvACFVmBmC2KrO5goeLtv3De0+Ftrfo7S+cLC60dYktAhfaZoO0JqsDoIceeggA8OSTT7LHRCIRJUETQuzC8EMRMB4Z4X74/vH8HZjwyVF2g1A9ZwcJnvr2LPsBvSshnk0SboqDWFdE0TAZWi/CXxf46EdBuNNTumKKjcULl/x8ESLoprUMc3u4wQ/AD2C6e7lggMKDnZqLCtJNXzWnKnNT72lTtX64/VJrtEhML7JJ4CK0MS4h9mJ1AJSZmWmPfhBCiCChnBXDkRHuh2+Bqg6/PzcCg1bsAwNd0LL2kUFstWjuB/QfC+5AeoEKU9YeRY26MbTRByxh3i6QioH0wipE+rvh+6eG4sdT2fjP36m8PjqKRezSdKGRKm7lZm5ukWESMgCkNSQu63NzuPRLTiL8XPHDU8PY98BcsCE0NaWQy9j8JCepGIEeTs0KpLgjP/r7tSRwsXSfMkJsweoAKDQ01B79IIQQQaY+FPUf+twPc2cHCRRyGXKUNexIDQNg9V5+UULuaE0vPzdsfToOk9cdY88J7uaMdY8OBgB2tVdKvgozvjyFNM7mpHrJuRU4llFsclSFOwI0QOEBMAyScysQFeTBS0LmLj2PUnhgR0I8f2VWQ/CUWlCJSWsSkVlcZXbKydTUVI6yhu1/rVqLCZ8cwe4Fd1g9asMNPqvrNUZTeIS0Zxb/K503bx5Uqsah4h9++AGVlY1JdGVlZbjnnnts2ztCCEHjlIvQByv3w7y6XsPWp4kOkgMAIv3deVtJfDQ9BmqNFvd+egR3rTqEiasP4aEvT/DuyU2k7q/wMDpeXa/Bl48NZosTRgV5YNVfKex5zg66Jenb543A5ieG8kaAPnwgGmgoH8Jw5tMMl57r993S474mJ6kYmQbbaAgxHB375ewt1NSp0d3LBZH+jcHOrbIaDH5nH2rq1AAaCyU2VfSQ2yehKTxr6QM2fSFHKrpI7Mnif6mff/45qqoaf8jmzp2L/Px8tl1bW4s9e/bYtneEENIEww9h/SiRvuryroQR7ONRQXLUNYx46BOg0wqr2JVYelFBcizcegHjPj4MVTV/81X945/sTUVqQSUifF3xwbRodmUXoJvyylHWQCoRI76XD69/IpGInQZLzilnV2Ppl543PocHbypJ/5o2PzGUtzVHZEP+EZc+gFHIZexziwC8vD0Jg1bshVqjxa6EeAR7ythratVanMwsMRuEGAZG3Pd5+7O62kWWBE6mCCVBE2IvFk+BMQxjtk0IIW2BO0WmkMvYgCLcx5W3HDyzqBIvbr3ArroSIgKw/tHbEObjigmfHAEAdkWZ3luT+sLPwxnPfH8OgG63di0D3iam+mk2w/7piziaeh07OMvThXKAuAGVvtjhroTGCs9G9X8a9gbbdSEHL29PAqAbvTqZWYL4Xj7Y8K/bMHX9cdRpGDg7SDC4u6fJhGbuFF1UkBw7GqbT9KNztlgJRknQpDVZnQNECCHtjVQiRncvF9y/NpEXhHA/pCVikVFxQ/3qLj0GwDPfn0NvX1c2b8fZQYxwH1dczq2AzEGMN367YvT8L269gF/nx+NmqW7lmWHwwl01Fe7jyq780q/k4p5nauk59xxzy9ANt8PIUdZg8kAF3vztMpsnNbi7J3v+AIUHFo6LwLCwbnjkq1MmE5oziyp5u9lnFlXy+mqLJeyUBE1aEwVAhJBOQahODvdD2M/NEU5SEWobVnv19nPFT3OHY/qGE0gt5I/KpHHa1fVarHowBnnlNXhi0xnB504tUOFmaXWTwQtgvK1Hcz7kDev7cIOPlHwVIv3cdHuAcaYEzy8di5OZJYgN90KOsoY9PzmnHGE+rihQ1bUoodlWozfmahcRYktWBUBvvPEGXFx0/6jr6urwzjvvQC7XzS9z84MIIaS1dfdyMTkNpdZoMW3DcTb4AYDX7ukLmYMUa/81GDeKK/HUt2dN3vulny/iwwdjzD7/wq0XLN4k1NIPeUurKxsGH9ueHm7UD5mjFKMi/QTPF6o8bRj8hPu4su+vfvWa4Wui0RvSkYgYC5N5Ro8ebdHGpwcOHGhxp9paeXk55HI5lEolPDw8mr6AENIuqDVawRyaa4Uq3LXqEHuek1SMWrWWneqJUngADRuf6h+L8HNDKqdI4t8vjsTCrReQlFOO3r6ucHKQGE2p6aef9NtUCOXxWPNaLM2pMfW6m7q/YbDSVMBF+3SR9s6az2+LA6CuhAIgQjoXbjAR7u3CLiHn0hck1NcRMtxMVL/KibsnWWZRJRsUcXNv9FqyLYRh0LZ/0SjBUSNrk4/tFcRQcETaA2s+v9v0X+nhw4cxadIkKBQKiEQi7Ny5k32svr4eL7/8MqKiouDq6gqFQoHHH38cOTk5Zu/55ptvQiQS8b769Olj51dCCGnPuMu1/7fgDnZpuLODBADYCtM9fN0gc5Syf3KXeHNXPOm/7+3vjh0J8Q3L7ePZ++q1ZCm30PJ+IdYsHbdVnR39cviaOjX7Z3uu32NpXSPStbRpEnRlZSViYmLw5JNPYurUqbzHqqqqcO7cOSxduhQxMTEoLS3FggULcN999+HMGeFERL3+/ftj7969bFsqpVxvQro6bt4Nd9k8N1fGcNd5UyMahqMdhsvt9aNC1iQDG05jAcCq6TFs21Qf9LV+LEk+tsVKLaHtLwxXnrWnTUxph3liSptGBhMnTsTEiRMFH5PL5fj77795x9asWYNhw4YhKysL3bt3N3lfqVSKgIAAm/aVENJ56JfNm1pKHhUkBxhGF8QYfGia+0DljgpZMx2k1mh5S/gHKDwgashJ0j+H4fncPmyba5z0LMQWK7UMt78AhFeetRe0wzwxpUMNjSiVSohEInh6epo9Ly0tDQqFAjKZDHFxcVi5cqXZgKm2tha1tbVsu7y83OS5hJCOTyiI4X5QcrekMPzQtOQD1dql3IZL+LnJ1ULPYdiHHGWNRc9nuFIL0OUaWZO3ww2iuPWChFaecbVVjhAVVySmdJgAqKamBi+//DJmzJhhNrEpNjYWmzZtQmRkJHJzc7F8+XLccccdSE5Ohru7cI2OlStXYvny5fbqOiGknREKYrgflLwRIIMPTf2WFfpChrb4QDVcws8bARL40G7Ohzo3ADGs3GzJqjXu9aamEE0FYc0dsbJF0ETL84kpzVoFVlZWhlOnTqGgoABaLT+p7PHHH29eR0Qi7NixA1OmTDF6rL6+HtOmTcOtW7dw8OBBq1ZmlZWVITQ0FB999BFmz54teI7QCFBISAitAiOkk+J9IDes8LI0B4g7XWW4Y3tL+2SYA2SrJemmRry4q8wAfvXspq635jUbrmjT5ww1Zyd7QsyxZhWY1SNAv/32Gx599FGoVCp4eHjwagOJRKJmB0Cm1NfXY/r06bhx4wb2799vdUDi6emJiIgIpKenmzzHyckJTk5OLe0qIaSDMDUqYDiKYZgnBPCnq/Q7ttsip0RoGwxz97Vmmq2pES89oS0uzF1vaQCmkMvYoMcwYVro+Uw9J+XuEFuyOpxetGgRnnzySahUKpSVlaG0tJT9KikpsWnn9MFPWloa9u7dC29vb6vvoVKpkJGRgcDAQJv2jRDSsXGXtAsxtWTc0uXp7YlQn/VB4MZZQ6y+XiGXWbzsXa3RYvrnJ9hE6V+eiePter9w6wXB6zvi+0w6FqtHgLKzs/H888+zW2K0hEql4o3MZGZm4sKFC/Dy8kJgYCAeeOABnDt3Dr///js0Gg3y8vIAAF5eXnB0dAQAjBkzBvfffz/mz58PAFi8eDEmTZqE0NBQ5OTkYNmyZZBIJJgxY0aL+0sI6TpMjUC0t5wSS6bCzI143dHbl80/GqDwYO9puJkr93prRmd4+5QVqFCgqsNH02Mw7uPDAEyPorW395l0Plb/ixo/fnyTdXgsdebMGQwaNAiDBg0CACxcuBCDBg3CG2+8gezsbPz666+4desWBg4ciMDAQPbr2LFj7D0yMjJQVFTEtm/duoUZM2YgMjIS06dPh7e3N06cOAFfX1+b9JkQ0jWYGoFoTxWPrSlsaGrESyoRY0dCPP5+cSREAMZ9fFjwXtzrrRmd8XNzhD5RQtTQDvdxtej6pkbpCGkJq0eA7r33XixZsgSXL19GVFQUHBwceI/fd999Ft9r9OjRMJeDbUl+9vXr13ntH3/80eLnJ4QQU4RGIOyZmNucwMpWeTJSiRgSsYjNbdLn5kjEIsH+WDM6czarDPrf5ExDe1SkH43ukDZndQA0Z84cAMBbb71l9JhIJIJGo2l5rwghpB0wTDS2V2JucwMrW9a4MSwDwFazNtEfS5OwY8O92HpBzg4SxIZ7WXU9IfZidQBkuOydEEK6CnsV1WtuYNXUSIw1o0r6e2UWVeJWaRWe2HTG6v4IkTlKcX7pWJzMLEFsuBdkjh2m/Bzp5Fr0L7GmpgYymcxWfSGEkHbNXom5LQmsTI2kNHdUadG2f4yqPLc00JM5SjEq0q9F9yDE1qz+6dVoNFixYgWCgoLg5uaGa9euAQCWLl2Kr7/+2uYdJISQ9sQeibnc3er1RRlbyppd4oWuqa7XYPMTQ5vVH9p9nXQEVv+UvfPOO9i0aRM++OADdik6AAwYMABfffWVTTtHCCFdha0Dq+bU0TG8Jr6XT7OCH0tXphHSlqyeAvv222/xxRdfYMyYMXjmmWfY4zExMbh69apNO0cIIaR5mjNdZ+k15nKLWlo1mpDW0qxCiL169TI6rtVqUV9fb5NOEUIIabnmrLRq6pqmcosM85n0VaNpTy/S3lgdAPXr1w9HjhxBaGgo7/jPP//MFjQkhBDSOTW1Yq0lVaMJaU1WB0BvvPEGZs6ciezsbGi1Wmzfvh0pKSn49ttv8fvvv9ujj4QQQtoJS1ascUeR7FU6gJCWEjGWlFs2cOTIEbz11lv4559/oFKpcNttt+GNN97A3XffbY8+trry8nLI5XIolUqrd58nhJDOztqq1ULnqzVaZBZVAgDCfVxpWozYhDWf31YHQLdu3UJwcLDgYydOnMDw4cOtuV27RAEQIYTYj1qjxf1rE9mtN6KC5NjByQ1qT/utkY7Fms9vq/9l3X333SgpKTE6npiYiAkTJlh7O0IIIV1MVkkVG/wAQBKnThEtoyetxeoAaPjw4bj77rtRUVHBHjt8+DDuueceLFu2zKadI4QQ0vl093JBlKLxf+dRQY25Qc0p4EhIc1g9BabVavHAAw+gpKQEe/bswbFjx3Dffffh7bffxoIFC+zVz1ZFU2CEEGJfpnKAeMvsg+U2q4xNuga75gABQF1dHe69915UVVXh4sWLWLlyJebPn9/sDrc3FAARQkjboRwg0lw2D4AuXrxodKyiogIzZszAvffei2effZY9Hh0d3Ywuty8UABFCCCEdj80DILFYDJFIBO6p3Lb+e5FIBI1G08Lutz0KgAghpOVaMpJDo0CkOaz5/LaoEGJmZqZNOkYIIaRraGrLDHNq6tSYvDYRKfkq2j6D2I1FAZDhtheEEEKIOc3dAkOt0WLymkSkFKisvpYQa1i9FQYAZGRkYPXq1bhy5QoA3f5gCxYsQM+ePW3aOUIIIR1Tc7fAyCqpYoMfAIj0d6ftM4hdWB0A7dmzB/fddx8GDhyI+Ph4ALoiiP3798dvv/2GcePG2byThBBCOhbDTVEtncLiBk6R/m7YlUDTX8Q+rF4GP2jQIIwfPx7vvfce7/grr7yCv/76C+fOnbNpB9sCJUETQkjboQRo0lx23QrjypUrmD17ttHxJ598EpcvX7b2doQQQgiPfjd5w+BHrdHiWqGKtscgNmF1AOTr64sLFy4YHb9w4QL8/Pxs0SdCCCGEh/YII7ZmcQ7QW2+9hcWLF2POnDl4+umnce3aNYwYMQKALgfo/fffx8KFC+3WUUIIIV1Xc1eVEWKKxTlAEokEubm58PX1xerVq7Fq1Srk5OQAABQKBZYsWYLnn38eIpHIrh1uDZQDRAgh7QvtEUYsYZe9wMRiMfLy8njTXPod4d3d3VvQ3faHAiBCCGlfTG2e2tFQgrd92bwStJ7h6E5nC3wIIYS0P0JVpTuillTHJrZnVQAUERHR5BRXSUlJizpECCGEcHWW/J/O8jo6C6sCoOXLl0Mul9urL4QQQoiR5laVbm86y+voLFqUA9RZUQ4QIYS0L50ld6azvI72yi6FEDvD6i5CCCHtg7VFDU0VR+xoLH0dVPTR/iyeArNyxwxCCCFEECUDm0fvT+uw+B3VarU2n/46fPgwJk2aBIVCAZFIhJ07d/IeZxgGb7zxBgIDA+Hs7IyxY8ciLS2tyfuuXbsWYWFhkMlkiI2NxalTp2zab0IIIc0nlAxMGtH70zraNKSsrKxETEwM1q5dK/j4Bx98gE8//RQbNmzAyZMn4erqivHjx6OmpsbkPbdu3YqFCxdi2bJlOHfuHGJiYjB+/HgUFBTY62UQQgixgj4ZGAAlAwug96d1WL0bvL2IRCLs2LEDU6ZMAaAb/VEoFFi0aBEWL14MAFAqlfD398emTZvw8MMPC94nNjYWQ4cOxZo1awDoRq5CQkLw3HPP4ZVXXrGoL5QETQgh9kXJwObR+9M8dt0NvrVkZmYiLy8PY8eOZY/J5XLExsbi+PHjgtfU1dXh7NmzvGvEYjHGjh1r8hoAqK2tRXl5Oe+LEEJI8zWVxNtZkprthd4f+2u372xeXh4AwN/fn3fc39+ffcxQUVERNBqNVdcAwMqVKyGXy9mvkJCQFvaeEEK6rtbeuZ1WTJHmaLcBUGt69dVXoVQq2a+bN2+2dZcIIaTDas0k3tYOtkjn0W4DoICAAABAfn4+73h+fj77mCEfHx9IJBKrrgEAJycneHh48L4IIYQ0T2sm8dKKKdJc7TYACg8PR0BAAPbt28ceKy8vx8mTJxEXFyd4jaOjIwYPHsy7RqvVYt++fSavIYQQYltSiRjb543A/kWjsP1Z+9awoRVTpLms2gvM1lQqFdLT09l2ZmYmLly4AC8vL3Tv3h0vvPAC3n77bfTu3Rvh4eFYunQpFAoFu1IMAMaMGYP7778f8+fPBwAsXLgQM2fOxJAhQzBs2DCsXr0alZWVeOKJJ1r75RFCSJelT+JtjefZPm8ErZgiVmvTAOjMmTO488472fbChQsBADNnzsSmTZvw0ksvobKyEk8//TTKyspw++23Y/fu3ZDJZOw1GRkZKCoqYtsPPfQQCgsL8cYbbyAvLw8DBw7E7t27jRKjCSGEdA7cYIuWjxNLtZs6QO0J1QEihJCOh7aQIJ2iDhAhhBBiDUqIJtagAIgQQkin0NyEaKoj1DW1aQ4QIYQQYivNSYimabOui/6WCSGEdBrWbiFB02ZdFwVAhBBCuiS1RguNlkEU1RHqkmgKjBBCSJfDnfqKUnjg7xdHItzHlaa/uhD6myaEENLlcKe+knLKIRGLKPjpYuhvmxBCSJdDW2gQmgIjhBDS5bTWFhpUmbr9ogCIEEJIl2TtfmXWBjO0xL59owCIEEIIaUJzghmhJfatsUEssQyFooQQQrqM5lZ9bk69IMozat9oBIgQQkiX0JIpKX0wczFbaXEw01p5RqR5KAAihBDSJbRkSqq5wYy1eUak9VA4SgghpEto6ZSUtdtskPaNRoAIIYR0CU2N4tCS9a6FAiBCCCFdhqkpKVqy3vXQ3y4hhJAuj3aF73ooACKEENLl0ZL1roemwAghhHR5tGS966EAiBBCCAEtWe9qKMQlhBBCSJdDARAhhBBCuhwKgAghhBDS5VAARAghhJAuhwIgQgghhHQ5FAARQgghLaTWaHGtUAW1RtvWXSEWomXwhBBCSAvQNhodE/0NEUIIIS1A22h0TBQAEUIIIS1A22h0TDQFRgghhDSTWqNFVkkVts0djhxlDW2j0YFQAEQIIYQ0A+X+dGzt/m8qLCwMIpHI6CshIUHw/E2bNhmdK5PJWrnXhBBCOjvK/enY2v0I0OnTp6HRaNh2cnIyxo0bhwcffNDkNR4eHkhJSWHbIpHIrn0khBDS9ehzfy5mKyn3pwNq9wGQr68vr/3ee++hZ8+eGDVqlMlrRCIRAgIC7N01QgghXZhUIsb2eSOQVVJFuT8dUIf626qrq8N3332HJ5980uyojkqlQmhoKEJCQjB58mRcunTJ7H1ra2tRXl7O+yKEENI1WVPUUCoRo4evGwU/HVC7HwHi2rlzJ8rKyjBr1iyT50RGRuKbb75BdHQ0lEol/vOf/2DEiBG4dOkSgoODBa9ZuXIlli9fbnV/NBoN6uvrrb6OEGI/Dg4OkEgkbd0N0kFZktisX/lFoz4dm4hhGKatO2Gp8ePHw9HREb/99pvF19TX16Nv376YMWMGVqxYIXhObW0tamtr2XZ5eTlCQkKgVCrh4eFhdD7DMMjLy0NZWZnVr4EQYn+enp4ICAig/D9itWuFKty16hDb3r9oFHr4urFtWvnVvpWXl0Mul5v8/ObqMCNAN27cwN69e7F9+3arrnNwcMCgQYOQnp5u8hwnJyc4OTlZfE998OPn5wcXFxf6JUtIO8EwDKqqqlBQUAAACAwMbOMekY6mqcRmoZVf3ACJdBwdJgDauHEj/Pz8cO+991p1nUajQVJSEu655x6b9EOj0bDBj7e3t03uSQixHWdnZwBAQUEB/Pz8aDqMWKWpxGZa+dV5dIgASKvVYuPGjZg5cyakUn6XH3/8cQQFBWHlypUAgLfeegvDhw9Hr169UFZWhg8//BA3btzAU089ZZO+6HN+XFzoHz0h7ZX+57O+vp4CIGI1fWKzqcdo5Vfn0CECoL179yIrKwtPPvmk0WNZWVkQixv/AZaWlmLOnDnIy8tDt27dMHjwYBw7dgz9+vWzaZ9o2ouQ9ot+Pok9mQuQSMfRoZKgW4u5JKqamhpkZmYiPDycKkwT0k7RzykhXZM1SdA0dkfMGj16NF544YW27kaX8eabb2LgwIFmz0lMTERUVBQcHBwwZcqUVukXIYR0NhQAdREUyHQeCxcuxMCBA5GZmYlNmza1dXcIIQasKaRI2g4FQKRLYBgGarW6rbthExkZGbjrrrsQHBwMT09Po8c702slpKPR1wm6a9UhTF13DGqNlgKidooCoC5g1qxZOHToED755BOIRCKIRCJcv34dAHDo0CEMGzYMTk5OCAwMxCuvvGL2w/OPP/6AXC7H999/DwC4efMmpk+fDk9PT3h5eWHy5MnsvfXPPWXKFPznP/9BYGAgvL29kZCQYLaCtn4a6L///S/CwsIgl8vx8MMPo6Kigj2ntrYWzz//PPz8/CCTyXD77bfj9OnT7OMHDx6ESCTC//73PwwePBhOTk44evQoRo8ejeeeew4vvPACunXrBn9/f3z55ZeorKzEE088AXd3d/Tq1Qv/+9//zL6n//3vfzFkyBC4u7sjICAAjzzyCFt7hvv8+/btw5AhQ+Di4oIRI0bwNukFdHvb+fv7w93dHbNnz0ZNTY3J57x+/TpEIhGKi4vZ7WA2bdpk8rVqtVqsXLkS4eHhcHZ2RkxMDH7++WfePf/8809ERETA2dkZd955JzZt2gSRSMQW+RSaklu9ejXCwsJ4x7766iv07dsXMpkMffr0wbp164z6vX37dtx5551wcXFBTEwMjh8/zrtHYmIiRo8eDRcXF3Tr1g3jx49HaWkpvv32W3h7e/OKlQLAlClT8Nhjj5l8vwhpC4Z1gjKLKo0CItJOMMSIUqlkADBKpdLoserqauby5ctMdXV1G/SsecrKypi4uDhmzpw5TG5uLpObm8uo1Wrm1q1bjIuLCzNv3jzmypUrzI4dOxgfHx9m2bJl7LWjRo1iFixYwDAMw3z//feMu7s789tvvzEMwzB1dXVM3759mSeffJK5ePEic/nyZeaRRx5hIiMjmdraWoZhGGbmzJmMh4cH88wzzzBXrlxhfvvtN8bFxYX54osvTPZ32bJljJubGzN16lQmKSmJOXz4MBMQEMC89tpr7DnPP/88o1AomD///JO5dOkSM3PmTKZbt25McXExwzAMc+DAAQYAEx0dzfz1119Meno6U1xczIwaNYpxd3dnVqxYwaSmpjIrVqxgJBIJM3HiROaLL75gUlNTmWeffZbx9vZmKisrTfbx66+/Zv78808mIyODOX78OBMXF8dMnDiRfVz//LGxsczBgweZS5cuMXfccQczYsQI9pytW7cyTk5OzFdffcVcvXqV+fe//824u7szMTExgs+pVquZ3NxcxsPDg1m9ejWTm5vLVFVVmXytb7/9NtOnTx9m9+7dTEZGBrNx40bGycmJOXjwIMMwDJOVlcU4OTkxCxcuZK5evcp89913jL+/PwOAKS0tZf8uDPvz8ccfM6GhoWz7u+++YwIDA5lffvmFuXbtGvPLL78wXl5ezKZNmxiGYZjMzEwGANOnTx/m999/Z1JSUpgHHniACQ0NZerr6xmGYZjz588zTk5OzLPPPstcuHCBSU5OZj777DOmsLCQqaqqYuRyObNt2zb2OfPz8xmpVMrs379f8L3qiD+npHOoV2uYSZ8eYUJf/p2Z9NkRJjWvnAl9+Xf2K6Ogoq272KmZ+/w2RAGQgNYKgOrVGiajoIKpV2tafK+mcAMZvddee42JjIxktFote2zt2rWMm5sbo9FoeNetWbOGkcvl7IcnwzDMf//7X6Pra2trGWdnZ2bPnj0Mw+gCoNDQUEatVrPnPPjgg8xDDz1ksq/Lli1jXFxcmPLycvbYkiVLmNjYWIZhGEalUjEODg7M999/zz5eV1fHKBQK5oMPPmAYpjEA2blzp9H7cPvtt7NttVrNuLq6Mo899hh7LDc3lwHAHD9+3GQfDZ0+fZoBwFRUVPCef+/evew5f/zxBwOA/bcTFxfHzJs3j3ef2NhYkwGQnlwuZzZu3Mi2hV5rTU0N4+Liwhw7dox37ezZs5kZM2YwDMMwr776KtOvXz/e4y+//LLVAVDPnj2ZLVu28M5ZsWIFExcXxzBMYwD01VdfsY9funSJAcBcuXKFYRiGmTFjBhMfH2/yNT/77LO8AHPVqlVMjx49eP/2uCgAIm2J+7vdMCBqjd/3XZk1AVCHqAPUGbWH/WSuXLmCuLg4Xs2U+Ph4qFQq3Lp1C927dwcA/PzzzygoKEBiYiKGDh3KnvvPP/8gPT0d7u7uvPvW1NQgIyODbffv359XjC4wMBBJSUlm+xYWFsa7b2BgIDvFlJGRgfr6esTHx7OPOzg4YNiwYbhy5QrvPkOGDDG6d3R0NPu9RCKBt7c3oqKi2GP+/v4AwJvSMnT27Fm8+eab+Oeff1BaWgqtVjesnZWVxas5xX0u/bYMBQUF6N69O65cuYJnnnmGd9+4uDgcOHDA5POaw32t6enpqKqqwrhx43jn1NXVYdCgQQB0f/+xsbFGz2+NyspKZGRkYPbs2ZgzZw57XK1WQy6X88419V706dMHFy5cwIMPPmjyeebMmYOhQ4ciOzsbQUFB2LRpE2bNmkX1fki7ZFgniAontk8UALWRjrSfzKBBg3Du3Dl88803GDJkCPuho1KpMHjwYDYfiMvX15f93sHBgfeYSCRiAwZTmnONEFdXV4vuzT2mf32mnq+yshLjx4/H+PHj8f3338PX1xdZWVkYP3486urqTD5XU/dtKe5rValUAHQ5W0FBQbzzrNn3TiwWgzEoFcbN39I/z5dffmkUTBlWYDb3Xui3rzBl0KBBiImJwbfffou7774bly5dwh9//GHx6yCkLVHhxPaJQtE2ot9PBkCr7Cfj6OgIjUbDO9a3b18cP36c9wGXmJgId3d3BAcHs8d69uyJAwcOYNeuXXjuuefY47fddhvS0tLg5+eHXr168b4M//dvSz179oSjoyMSExPZY/X19Th9+rTNK34LuXr1KoqLi/Hee+/hjjvuQJ8+fcyOFpnSt29fnDx5knfsxIkTNuljv3794OTkhKysLKO/m5CQEPb5T506Zfb5fX19kZeXx/s3cuHCBfZ7f39/KBQKXLt2zeh5wsPDLe5vdHQ09u3bZ/acp556Cps2bcLGjRsxduxY9nUQQkhzUADURvT7yexfNArbn7X/9FdYWBhOnjyJ69evo6ioCFqtFvPmzcPNmzfx3HPP4erVq9i1axeWLVuGhQsX8rYXAYCIiAgcOHAAv/zyC1tP6NFHH4WPjw8mT56MI0eOIDMzEwcPHsTzzz+PW7du2e21uLq64tlnn8WSJUuwe/duXL58GXPmzEFVVRVmz55tt+fV6969OxwdHfHZZ5/h2rVr+PXXX7FixQqr77NgwQJ888032LhxI1JTU7Fs2TJcunTJJn10d3fH4sWL8eKLL2Lz5s3IyMjAuXPn8Nlnn2Hz5s0AgGeeeQZpaWlYsmQJUlJSsGXLFqO6QqNHj0ZhYSE++OADZGRkYO3atUYr5JYvX46VK1fi008/RWpqKpKSkrBx40Z89NFHFvf31VdfxenTpzFv3jxcvHgRV69exfr161FUVMSe88gjj+DWrVv48ssvBbfFIaS10fL2jo0CoDakHxZtjTnhxYsXQyKRoF+/fuyUTVBQEP7880+cOnUKMTExeOaZZzB79my8/vrrgveIjIzE/v378cMPP2DRokVwcXHB4cOH0b17d0ydOhV9+/Zll3I3VYK8pd577z1MmzYNjz32GG677Takp6djz5496Natm12fF9CNimzatAk//fQT+vXrh/feew//+c9/rL7PQw89hKVLl+Kll17C4MGDcePGDTz77LM26+eKFSuwdOlSrFy5En379sWECRPwxx9/sCMz3bt3xy+//IKdO3ciJiYGGzZswLvvvsu7R9++fbFu3TqsXbsWMTExOHXqFBYvXsw756mnnsJXX32FjRs3IioqCqNGjcKmTZusGgGKiIjAX3/9hX/++QfDhg1DXFwcdu3axdv8WC6XY9q0aXBzc6MK2KTNCdX76Ww6e4BHe4EJoL3ASFd18OBB3HnnnSgtLRUsstjWxowZg/79++PTTz81ex79nBJ7u1aowl2rDrHt/YtGdao8n/awUKc5aC8wQkinUlpaih07duDgwYNISEho6+4Q0up5nK1NaKFOZ0OrwAgh7d6gQYNQWlqK999/H5GRkW3dHULYPM7OurxdH+BdzFZ2ygAPoACIEMIxevRoo2Xv7QF3exVC2ovOvLy9swd4AAVAhBBCCBHQmQM8gHKACCGEENIFUQBECCGEkC6HAiBCCCGEdDkUABFCCCGky6EAiBBCCCFdDgVAXcTo0aPZPbwscf36dYhEIt7Gl51JcXEx/Pz8uvTyanv8HdfV1SEsLAxnzpyx2T0JIcQeKADqIrZv327Vhp0hISHIzc3FgAEDAOi2SBCJRCgrK7NTD1vXO++8g8mTJyMsLKytu2IVawNZvVmzZhntn2X4d2wLjo6OWLx4MV5++WWb3ZMQQuyBAqAuwsvLC+7u7hafL5FIEBAQwNuMsi3V19fb7F5VVVX4+uuvW2Xn+PbMXn/Hjz76KI4ePWqzne0JIcQeKADqIgxHDsLCwvDuu+/iySefhLu7O7p3744vvviCfZw7PXL9+nXceeedAIBu3bpBJBJh1qxZgs+zadMmeHp6Ys+ePejbty/c3NwwYcIE5ObmsudotVq89dZbCA4OhpOTEwYOHIjdu3cbPffWrVsxatQoyGQyfP/99+woxrvvvgt/f394enrirbfeglqtxpIlS+Dl5YXg4GBs3LjR7Hvx559/wsnJCcOHD+cdT05OxsSJE+Hm5gZ/f3889thjKCoqAqAbAXN0dMSRI0fY8z/44AP4+fkhPz+ffY/nz5+P+fPnQy6Xw8fHB0uXLuVVVq6trcXixYsRFBQEV1dXxMbG4uDBg7x+JCYmYvTo0XBxcUG3bt0wfvx4lJaWYtasWTh06BA++eQTiEQiiEQiXL9+HRqNBrNnz0Z4eDicnZ0RGRmJTz75hL3fm2++ic2bN2PXrl3sdQcPHhScAjt06BCGDRsGJycnBAYG4pVXXoFarWYfHz16NJ5//nm89NJL8PLyQkBAAN58801e/7t164b4+Hj8+OOPZv8eCCGkTTHEiFKpZAAwSqXS6LHq6mrm8uXLTHV1tfGF9SrTX+pqy8+tr2r6XCuNGjWKWbBgAdsODQ1lvLy8mLVr1zJpaWnMypUrGbFYzFy9epVhGIbJzMxkADDnz59n1Go188svvzAAmJSUFCY3N5cpKysTfJ6NGzcyDg4OzNixY5nTp08zZ8+eZfr27cs88sgj7DkfffQR4+Hhwfzwww/M1atXmZdeeolxcHBgUlNTec8dFhbG/PLLL8y1a9eYnJwcZubMmYy7uzuTkJDAXL16lfn6668ZAMz48eOZd955h0lNTWVWrFjBODg4MDdv3jT5Xjz//PPMhAkTeMdKS0sZX19f5tVXX2WuXLnCnDt3jhk3bhxz5513sucsWbKECQ0NZcrKyphz584xjo6OzK5du3jvsZubG7NgwQLm6tWrzHfffce4uLgwX3zxBXvOU089xYwYMYI5fPgwk56eznz44YeMk5MT+9rPnz/PODk5Mc8++yxz4cIFJjk5mfnss8+YwsJCpqysjImLi2PmzJnD5ObmMrm5uYxarWbq6uqYN954gzl9+jRz7do19nm3bt3KMAzDVFRUMNOnT2cmTJjAXldbW8v7O2YYhrl16xbj4uLCzJs3j7ly5QqzY8cOxsfHh1m2bBnvNXp4eDBvvvkmk5qaymzevJkRiUTMX3/9xXs/X375ZWbUqFEm/w7szezPKSGk0zL3+W2IAiABzQ6AvofprwP38M/90cX0uX+P4p/7s4/xOVYSCoD+9a9/sW2tVsv4+fkx69evZxiGMfpwPHDgAAOAKS0tNfs8GzduZAAw6enp7LG1a9cy/v7+bFuhUDDvvPMO77qhQ4cy8+bN4z336tWreefMnDmTCQ0NZTQaDXssMjKSueOOO9i2Wq1mXF1dmR9++MFkHydPnsw8+eSTvGMrVqxg7r77bt6xmzdvskEfwzBMbW0tM3DgQGb69OlMv379mDlz5vDOHzVqFNO3b19Gq9Wyx15++WWmb9++DMMwzI0bNxiJRMJkZ2fzrhszZgzz6quvMgzDMDNmzGDi4+NN9t3w79GUhIQEZtq0aWx75syZzOTJk3nnGP4dv/baa0xkZCSv/2vXrmXc3NzY93zUqFHM7bffzrvP0KFDmZdffpl37JNPPmHCwsKa7Ke9UABESNdkTQDUPhI8SJuIjo5mvxeJRAgICEBBQUGL7+vi4oKePXuy7cDAQPa+5eXlyMnJQXx8PO+a+Ph4/PPPP7xjQ4YMMbp3//79IRY3ztz6+/vzknglEgm8vb3Nvo7q6mrIZDLesX/++QcHDhyAm5vxvjcZGRmIiIiAo6Mjvv/+e0RHRyM0NBQff/yx0bnDhw+HSCRi23FxcVi1ahU0Gg2SkpKg0WgQERHBu6a2thbe3t4AgAsXLuDBBx802XdT1q5di2+++QZZWVmorq5GXV0dBg4caNU9rly5gri4OF7/4+PjoVKpcOvWLXTv3h0A/98NwP/71XN2dkZVVZXVr4MQQloLBUC2NF1l+jGRhN+eZi7QMEjNmny9uT0yy8HBgdcWiUTQarV2uS/TjB3GXV1dLbq3ta/Dx8cHpaWlvGMqlQqTJk3C+++/b3R+YGAg+/2xY8cAACUlJSgpKRHsoykqlQoSiQRnz56FRML/96APvJydnS2+n96PP/6IxYsXY9WqVYiLi4O7uzs+/PBDnDx50up7WcKS97ukpAS+vr52eX5Cuiq1Rtupd2dvbRQA2ZLU8g9Du51rJ46OjgAAjUbTovt4eHhAoVAgMTERo0aNYo8nJiZi2LBhLbq3pQYNGoTvvvuOd+y2227DL7/8grCwMJOrojIyMvDiiy/iyy+/xNatWzFz5kzs3buXNyJlGHScOHECvXv3hkQiwaBBg6DRaFBQUIA77rhD8Dmio6Oxb98+LF++XPBxR0dHo7+DxMREjBgxAvPmzeP1tanrDPXt2xe//PILGIZhR4ESExPh7u6O4OBgs9caSk5OxqBBg6y6hhBimlqjxdR1x3AxW4noIDm2zxtBQVAL0btHLBIaGgqRSITff/8dhYWFUKnMjHY1YcmSJXj//fexdetWpKSk4JVXXsGFCxewYMECG/bYtPHjx+PSpUu8UaCEhASUlJRgxowZOH36NDIyMrBnzx488cQT0Gg00Gg0+Ne//oXx48fjiSeewMaNG3Hx4kWsWrWKd++srCwsXLgQKSkp+OGHH/DZZ5+xrysiIgKPPvooHn/8cWzfvh2ZmZk4deoUVq5ciT/++AMA8Oqrr+L06dOYN28eLl68iKtXr2L9+vXsarSwsDCcPHkS169fR1FREbRaLXr37o0zZ85gz549SE1NxdKlS3H69Glev8LCwnDx4kWkpKSgqKhIsKzAvHnzcPPmTTz33HO4evUqdu3ahWXLlmHhwoW8IM8SR44cwd13323VNYQQ07JKqnAxWwkAuJitRFYJTTG3FAVAxCJBQUFYvnw5XnnlFfj7+2P+/PnNvtfzzz+PhQsXYtGiRYiKisLu3bvx66+/onfv3jbssWlRUVG47bbbsG3bNvaYflRKo9Hg7rvvRlRUFF544QV4enpCLBbjnXfewY0bN/D5558D0E2LffHFF3j99dd5uUuPP/44qqurMWzYMCQkJGDBggV4+umn2cc3btyIxx9/HIsWLUJkZCSmTJmC06dPs/k1ERER+Ouvv/DPP/9g2LBhiIuLw65du9hRqcWLF0MikaBfv37w9fVFVlYW5s6di6lTp+Khhx5CbGwsiouLeaNBADBnzhxERkZiyJAh8PX1RWJiotH7EhQUhD///BOnTp1CTEwMnnnmGcyePRuvv/66Ve/v8ePHoVQq8cADD1h1HSHEtO5eLogOkgMAooPl6O7l0sY96vhETHOSMzq58vJyyOVyKJVKeHh48B6rqalBZmYmwsPDjRJpScfxxx9/YMmSJUhOTrZ6dMOU0aNHY+DAgVi9erVN7tdRPfTQQ4iJicFrr73WZn2gn1PSGVEOUNPMfX4batfv4JtvvskWbtN/9enTx+w1P/30E/r06QOZTIaoqCj8+eefrdRb0pHce++9ePrpp5Gdnd3WXelU6urqEBUVhRdffLGtu0JIpyOViNHD142CHxtp9+9i//79kZuby34dPXrU5LnHjh3DjBkzMHv2bJw/fx5TpkzBlClTkJyc3Io9Jh3FCy+8gJCQkLbuRqfi6OiI119/vVmr2QghpDW1+1VgUqkUAQEBFp37ySefYMKECViyZAkAYMWKFfj777+xZs0abNiwwZ7dJMRoSwtCCCHtV7sfAUpLS4NCoUCPHj3w6KOPIisry+S5x48fx9ixY3nHxo8fj+PHj5t9jtraWpSXl/O+CCGEENJ5tesAKDY2Fps2bcLu3buxfv16ZGZm4o477kBFRYXg+Xl5efD39+cd8/f3R15entnnWblyJeRyOftlybQI5Y4T0n7RzychpCntOgCaOHEiHnzwQURHR2P8+PH4888/UVZWxlu+bAuvvvoqlEol+3Xz5k2T5+qr4FKZf0LaL/3Pp2HVakII0Wv3OUBcnp6eiIiIQHp6uuDjAQEByM/P5x3Lz89vMofIyckJTk5OFvVBIpHA09OT3fvIxcWFt3cSIaTtMAyDqqoqFBQUwNPT02jLEUII0etQAZBKpUJGRgYee+wxwcfj4uKwb98+vPDCC+yxv//+G3FxcTbthz6gssXGoYQQ2/P09LR48QQhpGtq1wHQ4sWLMWnSJISGhiInJwfLli2DRCLBjBkzAOiq7gYFBWHlypUAgAULFmDUqFFYtWoV7r33Xvz44484c+YMvvjiC5v2SyQSITAwEH5+foJbChBC2o6DgwON/BBCmtSuA6Bbt25hxowZKC4uhq+vL26//XacOHGC3WU6KyuLV8V3xIgR2LJlC15//XW89tpr6N27N3bu3IkBAwbYpX8SiYR+0RJCCCEdEG2FIcCaUtqEEEIIaR86zVYYhBBCCCH2QAEQIYQQQrqcdp0D1Fb0s4JUEZoQQgjpOPSf25Zk91AAJEBfaZo2yiSEEEI6noqKCsjlcrPnUBK0AK1Wi5ycHLi7uxsVORw6dChOnz5t9vqmzjH1uNBxw2Om2uXl5QgJCcHNmzftkrhtyetuzjX0Xll3jbnz6L2y/Dx7vFcA7Pp+Nee9svQ6e71XhsfovbLuWEf/OWyL94phGFRUVEChUPBWiQuhESABYrEYwcHBgo9JJJIm/wE2dY6px4WOGx5rqu3h4WGXHxBLXndzrqH3yrprzJ1H75Xl59nzvQLs8341572y9Dp7vVeGx+i9su5YR/85bKv3qqmRHz1KgrZSQkJCi88x9bjQccNjTbXtpTnPQ++V7a8xdx69V5af11XeK0uvs9d7ZXiM3ivrjrXn96szvFc0BdZJUO0iy9F7ZTl6r6xD75fl6L2yHL1X9kEjQJ2Ek5MTli1bZvGmrl0ZvVeWo/fKOvR+WY7eK8vRe2UfNAJECCGEkC6HRoAIIYQQ0uVQAEQIIYSQLocCIPL/7d17TFPnHwbwp4AOKIK3ycUK1akQRECwHYsgeImAUeKFmRHnXSFORcYUXXQ4dF5m8LILWzbNOgYsI2qmxgWnU5yITiOTEsIENbgxcSXGdYM6dZT394fZyfpDpXPY067PJ2nS85739Dz9ppAv50KJiIicDhsgIiIicjpsgIiIiMjpsAFyEkeOHEFwcDCGDRuGvXv3yh3Hrk2fPh19+vRBamqq3FHsWlNTExISEhAaGorw8HDs27dP7kh2y2g0YvTo0YiMjERYWBj27NkjdyS7d+fOHQQFBWHVqlVyR7FrarUa4eHhiIyMxLhx4+SO41B4G7wTaG9vR2hoKMrLy+Hj44Po6GicPXsW/fr1kzuaXTp16hRaW1tRWFiI/fv3yx3Hbt28eRMGgwGRkZH45ZdfEB0djYaGBiiVSrmj2R2z2Yx79+7B09MTJpMJYWFhuHjxIn8GH2PdunW4evUqBg0ahPz8fLnj2C21Wo3a2lp4eXnJHcXh8AiQE7hw4QJGjBiBgQMHwsvLC8nJyTh27JjcsexWQkICevXqJXcMu+fv74/IyEgAgJ+fH/r374/bt2/LG8pOubq6wtPTEwBw7949CCHAvz0f7cqVK7h8+TKSk5PljkL/YWyAHMDp06cxdepUBAQEQKFQ4ODBg53mFBQUQK1Ww93dHc8//zwuXLggrWtubsbAgQOl5YEDB+LGjRu2iG5z/7ZWzqQ7a1VVVQWz2YxBgwY95dTy6I5aGY1GREREQKVSYfXq1ejfv7+N0ttWd9Rq1apV2Lp1q40Sy6c7aqVQKBAfHw+NRoOSkhIbJf9vYAPkAEwmEyIiIlBQUPDQ9aWlpcjOzsaGDRvw/fffIyIiAomJiWhpabFxUvmxVtbrrlrdvn0bc+fOxccff2yL2LLojlr17t0ber0ejY2N+Pzzz2EwGGwV36b+ba0OHTqE4cOHY/jw4baMLYvu+FydOXMGVVVVOHz4MLZs2YKamhpbxXd8ghwKAPHll19ajGm1WrFs2TJp2Ww2i4CAALF161YhhBCVlZVi2rRp0vqVK1eKkpISm+SV05PU6i/l5eVi5syZtohpF560Vnfv3hVxcXHis88+s1VU2f2bz9Vfli5dKvbt2/c0Y9qFJ6nV2rVrhUqlEkFBQaJfv37C29tb5OXl2TK2LLrjc7Vq1Sqh0+meYsr/Fh4BcnD3799HVVUVJk6cKI25uLhg4sSJOHfuHABAq9WitrYWN27cQFtbG8rKypCYmChXZNlYUyt6wJpaCSEwf/58jB8/HnPmzJErquysqZXBYEBraysA4LfffsPp06cRHBwsS145WVOrrVu3oqmpCdevX0d+fj6WLFmC3NxcuSLLxppamUwm6XPV1taGkydPYsSIEbLkdURucgegf+fWrVswm83w9fW1GPf19cXly5cBAG5ubtixYwfGjRuHjo4O5OTkOOXdJ9bUCgAmTpwIvV4Pk8kElUqFffv24YUXXrB1XFlZU6vKykqUlpYiPDxcunahqKgII0eOtHVcWVlTqx9//BHp6enSxc8rVqxwujoB1v8MknW1MhgMmD59OoAHdxouWbIEGo3G5lkdFRsgJ5GSkoKUlBS5YziEb775Ru4IDiE2NhYdHR1yx3AIWq0W1dXVcsdwOPPnz5c7gl0bMmQI9Hq93DEcFk+BObj+/fvD1dW10wWVBoMBfn5+MqWyT6yV9Vgr67FW1mOtrMdaPX1sgBxcz549ER0djRMnTkhjHR0dOHHihNOdtukKa2U91sp6rJX1WCvrsVZPH0+BOYC2tjZcvXpVWm5sbER1dTX69u2LwMBAZGdnY968eRg9ejS0Wi12794Nk8mEBQsWyJhaHqyV9Vgr67FW1mOtrMdayUzmu9DICuXl5QJAp8e8efOkOe+9954IDAwUPXv2FFqtVnz33XfyBZYRa2U91sp6rJX1WCvrsVby4neBERERkdPhNUBERETkdNgAERERkdNhA0REREROhw0QEREROR02QEREROR02AARERGR02EDRERERE6HDRARERE5HTZARNQtrl+/DoVCwW89JyKHwAaIiCQKheKxjzfffFPuiJ0kJCQ8NGt7e7vc0YjIjvHLUIlIcvPmTel5aWkpcnNzUV9fL415eXnJEatLS5YswcaNGy3G3Nw6/3q7f/8+evbsaatYRGTHeASIiCR+fn7Sw8fHBwqFQloeMGAAdu7cCZVKhWeeeQaRkZE4evToI1/LbDZj4cKFCAkJwU8//QQAOHToEKKiouDu7o4hQ4YgLy/P4kiNQqHA3r17MX36dHh6emLYsGE4fPhwl7k9PT0tsvv5+QEA1Go1Nm3ahLlz58Lb2xvp6ekAgDNnziAuLg4eHh4YNGgQMjMzYTKZpNdraWnB1KlT4eHhgcGDB6OkpARqtRq7d+8G8PDTfUajEQqFAqdOnZLGamtrkZycDC8vL/j6+mLOnDm4deuWtD4hIQGZmZnIyclB37594efn1+kom9FoREZGBnx9feHu7o6wsDAcOXIEJpMJ3t7e2L9/v8X8gwcPQqlUorW1tcu6ETkzNkBEZJV33nkHO3bsQH5+PmpqapCYmIiUlBRcuXKl09x79+7hxRdfRHV1NSoqKhAYGIiKigrMnTsXK1euRF1dHT766CN8+umn2Lx5s8W2eXl5mDVrFmpqajB58mTMnj0bt2/ffuLc+fn5iIiIwKVLl/DGG2/g2rVrSEpKwsyZM1FTU4PS0lKcOXMGy5cvl7aZP38+mpqaUF5ejv379+ODDz5AS0vLP9qv0WjE+PHjMWrUKFy8eBFHjx6FwWDArFmzLOYVFhZCqVTi/Pnz2L59OzZu3Ijjx48DADo6OpCcnIzKykoUFxejrq4O27Ztg6urK5RKJV566SXodDqL19PpdEhNTUWvXr2esGJETkLur6MnIvuk0+mEj4+PtBwQECA2b95sMUej0YhXXnlFCCFEY2OjACAqKirEhAkTRGxsrDAajdLcCRMmiC1btlhsX1RUJPz9/aVlAGL9+vXScltbmwAgysrKHpkzPj5e9OjRQyiVSumRnZ0thBAiKChITJs2zWL+okWLRHp6usVYRUWFcHFxEX/88Yeor68XAMSFCxek9T/88IMAIHbt2mXxXi9duiTN+fXXXwUAUV5eLoQQYtOmTWLSpEkW+2lqahIARH19vZQ9NjbWYo5GoxFr1qwRQgjx9ddfCxcXF2n+/zt//rxwdXUVzc3NQgghDAaDcHNzE6dOnXpkvYjoAV4DRERd+v3339Hc3IwxY8ZYjI8ZMwZ6vd5iLC0tDSqVCidPnoSHh4c0rtfrUVlZaXHEx2w24+7du7hz5w48PT0BAOHh4dJ6pVIJb2/vLo++zJ49G+vWrZOWe/fuLT0fPXq0xVy9Xo+amhqUlJRIY0IIdHR0oLGxEQ0NDXBzc0N0dLS0PiQkxOI1raHX61FeXv7Q66auXbuG4cOHA7B8vwDg7+8vvd/q6mqoVCpp7v/TarUYMWIECgsLsXbtWhQXFyMoKAhjx479R1mJnBEbICLqVpMnT0ZxcTHOnTuH8ePHS+NtbW3Iy8vDjBkzOm3j7u4uPe/Ro4fFOoVCgY6Ojsfu08fHB0OHDn3oOqVSabHc1taGjIwMZGZmdpobGBiIhoaGx+4LAFxcHlw9IISQxv78889O+5k6dSrefvvtTtv7+/tLzx/3fv/eQD7K4sWLUVBQgLVr10Kn02HBggVQKBRdbkfk7NgAEVGXvL29ERAQgMrKSsTHx0vjlZWV0Gq1FnOXLl2KsLAwpKSk4KuvvpLmR0VFob6+/pGNiq1ERUWhrq7ukTlCQkLQ3t6OqqoqaDQaAEB9fT2MRqM059lnnwXw4K65UaNGAUCn/38UFRWFAwcOQK1WP/SONGuEh4fj559/RkNDwyOPAr388svIycnBu+++i7q6OsybN++J9kXkbNgAEZFVVq9ejQ0bNuC5555DZGQkdDodqqurLU4l/WXFihUwm82YMmUKysrKEBsbi9zcXEyZMgWBgYFITU2Fi4sL9Ho9amtr8dZbb9nsfaxZswYxMTFYvnw5Fi9eDKVSibq6Ohw/fhzvv/8+goODkZSUhIyMDHz44Ydwc3NDVlaWxdEYDw8PxMTEYNu2bRg8eDBaWlqwfv16i/0sW7YMe/bsQVpamnSX19WrV/HFF19g7969cHV17TJrfHw8xo4di5kzZ2Lnzp0YOnQoLl++DIVCgaSkJABAnz59MGPGDKxevRqTJk2CSqXq3oIR/UfxLjAiskpmZiays7Px2muvYeTIkTh69CgOHz6MYcOGPXR+VlYW8vLyMHnyZJw9exaJiYk4cuQIjh07Bo1Gg5iYGOzatQtBQUE2fR/h4eH49ttv0dDQgLi4OIwaNQq5ubkICAiQ5uh0OgQEBCA+Ph4zZsxAeno6BgwYYPE6n3zyCdrb2xEdHY2srKxOTdxfR8zMZjMmTZqEkSNHIisrC71795ZOoVnjwIED0Gg0SEtLQ2hoKHJycmA2my3mLFq0CPfv38fChQufoCJEzkkh/n4Sm4iIHkqtViMrKwtZWVlyR+mkqKgIr776Kpqbm/mPHomsxFNgREQO6s6dO7h58ya2bduGjIwMNj9E/wBPgREROajt27cjJCQEfn5+eP311+WOQ+RQeAqMiIiInA6PABEREZHTYQNERERETocNEBERETkdNkBERETkdNgAERERkdNhA0REREROhw0QEREROR02QEREROR02AARERGR0/kftfbKo8PdehIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.figure()\n",
    "x, y = [], []\n",
    "for id in cnter:\n",
    "    if id > 3:  # skip special tokens\n",
    "        x.append(cnter[id])\n",
    "        y.append(trained_ts[id].norm().item())\n",
    "    # x.append(cnter[id])\n",
    "    # y.append(trained_ts[id].norm().item())\n",
    "plt.scatter(x, y, s = 2, label='token norm and frequency')\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.plot([0.5, 5 * 10**5], [512**0.5] * 2, color='orange', linestyle='--', label='init norm (expectation)')\n",
    "\n",
    "# plt.xlim(0, 6 * 10 ** 5)\n",
    "\n",
    "plt.xlabel('Token Frequency')\n",
    "plt.ylabel('Token Embedding Norm')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('figs/token_emb_norm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_lt10, norm_gt10 = [], []\n",
    "for id in cnter:\n",
    "    if cnter[id] <= 10:\n",
    "        norm_lt10.append(trained_ts[id].norm().item())\n",
    "    else:\n",
    "        norm_gt10.append(trained_ts[id].norm().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.99037030510038\n",
      "19.115726714582348\n"
     ]
    }
   ],
   "source": [
    "print(sum(norm_lt10) / len(norm_lt10))\n",
    "print(sum(norm_gt10) / len(norm_gt10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n"
     ]
    }
   ],
   "source": [
    "id_gt10 = [id for id in cnter if cnter[id] >= 100 and id > 3]\n",
    "embs = [trained_ts[id] for id in id_gt10]\n",
    "print(len(embs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4aea5c8ffd94548873159c73d035e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2016 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = len(embs)\n",
    "trained_dist, init_dist = 0, 0\n",
    "for i in tqdm(range(N)):\n",
    "    for j in range(i+1, N):\n",
    "        trained_dist += (embs[i] - embs[j]).norm()\n",
    "        init_dist += (init_ts[i] - init_ts[j]).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(21.9763)\n",
      "tensor(31.9728)\n"
     ]
    }
   ],
   "source": [
    "print(trained_dist / (N * (N-1) / 2))\n",
    "print(init_dist / (N * (N-1) / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.3728)\n",
      "tensor(22.6171)\n"
     ]
    }
   ],
   "source": [
    "print(trained_ts.norm(dim=1).mean())\n",
    "print(init_ts.norm(dim=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0555e-05)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = len(tokenizer)\n",
    "(trained_cosine.sum() - V) / (V * (V - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.0726e-07)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(init_cosine.sum() - V) / (V * (V - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(diffusion_model.state_dict(), \"checkpoints/conditional_from_scratch.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['alphas_bar', 'alphas_bar_prev'], unexpected_keys=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diffusion_model.load_state_dict(torch.load(\"checkpoints/20221015_2026\"))\n",
    "diffusion_model.load_state_dict(torch.load(\"checkpoints/20220906_0519\"), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774ffe570ac14eb89694d8fcef592931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.07535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0753, device='cuda:1')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_conditional(diffusion_model=diffusion_model, dataloader=eval_dataloader,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc7c1dd919b41779373bd844ea7578f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dingyizhou/anaconda3/envs/gen/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/dingyizhou/anaconda3/envs/gen/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/dingyizhou/anaconda3/envs/gen/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "diffusion_model.eval()\n",
    "\n",
    "generated_questions_mbr5_ddim20 = diffusion_model.generate(\n",
    "    dataset = eval_dataset,\n",
    "    rev_tokenizer=rev_tokenizer,\n",
    "    sampling_timesteps=20,\n",
    "    eta=0,\n",
    "    mbr=5,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15155854506376149\n",
      "0.22320761914790413\n"
     ]
    }
   ],
   "source": [
    "bleu_dict = calculate_bleu(generated_questions_mbr5_ddim20, eval_dataset, rev_tokenizer)\n",
    "print(sum(bleu_dict[\"bleu\"])/len(bleu_dict[\"bleu\"]))\n",
    "print(sum(bleu_dict[\"self_bleu\"])/len(bleu_dict[\"self_bleu\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5461694549349757\n"
     ]
    }
   ],
   "source": [
    "rouge_scores = calculate_rouge(generated_questions_mbr5_ddim20, eval_dataset, rev_tokenizer)\n",
    "rouge_l_f = [d['rouge-l']['f'] for d in rouge_scores]\n",
    "print(sum(rouge_l_f)/len(rouge_l_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are some ways to help a teenager overcome depression ?\n",
      "How does anyone overcome depression ?\n",
      "How do I overcome depression ?\n"
     ]
    }
   ],
   "source": [
    "i = 51\n",
    "src_question = [rev_tokenizer[id.item()] for id in eval_dataset[i]['question1_input_ids']]\n",
    "src_question = list(filter(lambda x:x not in ['[PAD]','[START]','[END]'], src_question))\n",
    "print(\" \".join(src_question))\n",
    "\n",
    "tgt_question = [rev_tokenizer[id.item()] for id in eval_dataset[i]['question2_input_ids']]\n",
    "tgt_question = list(filter(lambda x:x not in ['[PAD]','[START]','[END]'], tgt_question))\n",
    "print(\" \".join(tgt_question))\n",
    "\n",
    "#print(\" \".join(generated_questions_mbr1_ddim200[i]))\n",
    "print(\" \".join(generated_questions_mbr15_ddim2[i]))\n",
    "#print(\" \".join(generated_questions_mbr5_ddim20[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7342301b021940aa883544b8a31e64eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dingyizhou/anaconda3/envs/gen/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/dingyizhou/anaconda3/envs/gen/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/dingyizhou/anaconda3/envs/gen/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "diffusion_model.eval()\n",
    "\n",
    "generated_questions_mbr5 = diffusion_model.generate(\n",
    "    dataset = eval_dataset,\n",
    "    rev_tokenizer=rev_tokenizer,\n",
    "    sampling_timesteps=200,\n",
    "    eta=0,\n",
    "    mbr=5,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dingyizhou/anaconda3/envs/gen/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/dingyizhou/anaconda3/envs/gen/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/dingyizhou/anaconda3/envs/gen/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18039911311842954\n",
      "0.2751321938279151\n"
     ]
    }
   ],
   "source": [
    "bleu_dict = calculate_bleu(generated_questions_mbr5, eval_dataset, rev_tokenizer)\n",
    "print(sum(bleu_dict[\"bleu\"])/len(bleu_dict[\"bleu\"]))\n",
    "print(sum(bleu_dict[\"self_bleu\"])/len(bleu_dict[\"self_bleu\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5874787212343898\n"
     ]
    }
   ],
   "source": [
    "rouge_scores = calculate_rouge(generated_questions_mbr5, eval_dataset, rev_tokenizer)\n",
    "rouge_l_f = [d['rouge-l']['f'] for d in rouge_scores]\n",
    "print(sum(rouge_l_f)/len(rouge_l_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_batch = next(iter(eval_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dingyizhou/anaconda3/envs/gen/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/dingyizhou/anaconda3/envs/gen/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/dingyizhou/anaconda3/envs/gen/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "generated_questions = []\n",
    "bs = eval_batch['question1_input_ids'].shape[0]\n",
    "mbr = 5\n",
    "if mbr > 1:     # using MBR decoding\n",
    "    batch_questions = []\n",
    "    for cnt in range(mbr):\n",
    "        x_T = torch.randn(size=(bs,\n",
    "                                diffusion_model.config.max_position_embeddings,\n",
    "                                diffusion_model.config.word_embedding_dim))\n",
    "        final_hidden_state = diffusion_model.ddim_sample(x_T.to(device),\n",
    "                                              sampling_timesteps=200,\n",
    "                                              eta=0,\n",
    "                                              src_ids=eval_batch['question1_input_ids'].to(device),\n",
    "                                              src_attention_mask=eval_batch['question1_attention_mask'].to(device),\n",
    "                                              return_hidden_states=False,\n",
    "                                              verbose=False\n",
    "                                              )\n",
    "        sampled_ids = diffusion_model.rounding(final_hidden_state).cpu()\n",
    "        questions = [[rev_tokenizer[token_id.item()] for token_id in sampled_id] for sampled_id in sampled_ids]\n",
    "        batch_questions.append([list(filter(lambda x: x not in ['[PAD]', '[START]', '[END]'], question)) for question in questions])\n",
    "    # batch_questions [mbr, bs, question]\n",
    "    for batch_ind in range(bs):\n",
    "        candidates = [one_generation[batch_ind] for one_generation in batch_questions]      # [mbr, question]\n",
    "        bleu_scores = torch.zeros(mbr)\n",
    "        for candidate_ind, candidate in enumerate(candidates):\n",
    "            for ref_ind, ref in enumerate(candidates):\n",
    "                if ref_ind != candidate_ind:\n",
    "                    bleu_scores[candidate_ind] += sentence_bleu([ref], candidate)\n",
    "        select_ind = torch.argmax(bleu_scores).item()\n",
    "        generated_questions.append(batch_questions[select_ind][batch_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "diffusion_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_T = torch.randn(size=(batch_size, max_len, diffusion_model.config.word_embedding_dim))\n",
    "    final_hidden_state, hidden_states = diffusion_model.sample(x_T.to(device),\n",
    "                                        src_ids=eval_batch['question1_input_ids'].to(device),\n",
    "                                        src_attention_mask=eval_batch['question1_attention_mask'].to(device),\n",
    "                                        return_hidden_states=True,\n",
    "                                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "diffusion_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_T = torch.randn(size=(batch_size, max_len, diffusion_model.config.word_embedding_dim))\n",
    "    final_hidden_state_ddim, hidden_states_ddim = diffusion_model.ddim_sample(x_T.to(device), sampling_timesteps=200, src_ids=eval_batch['question1_input_ids'].to(device),src_attention_mask=eval_batch['question1_attention_mask'].to(device), return_hidden_states=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "diffusion_model.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# src_questions = bert_tokenizer.batch_decode(eval_batch['question1_input_ids_bert'], skip_special_tokens=True)\n",
    "src_questions = [[rev_tokenizer[id.item()] for id in ids] for ids in eval_batch['question1_input_ids']]\n",
    "for sample_idx in range(batch_size):\n",
    "    print(\"idx:\", sample_idx)\n",
    "    # print(src_questions[sample_idx])\n",
    "    print(\" \".join(src_questions[sample_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# target_questions = bert_tokenizer.batch_decode(eval_batch['question2_input_ids_bert'], skip_special_tokens=True)\n",
    "target_questions = [[rev_tokenizer[id.item()] for id in ids] for ids in eval_batch['question2_input_ids']]\n",
    "for sample_idx in range(batch_size):\n",
    "    print(\"idx:\", sample_idx)\n",
    "    # print(target_questions[sample_idx])\n",
    "    print(\" \".join(target_questions[sample_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    sampled_ids = diffusion_model.rounding(hidden_states[-1])\n",
    "    generated_questions = [[rev_tokenizer[token_id.item()] for token_id in sampled_id] for sampled_id in sampled_ids]\n",
    "for sample_idx in range(batch_size):\n",
    "    print(\"sample_idx:\", sample_idx)\n",
    "    print(\" \".join(generated_questions[sample_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    sampled_ids = diffusion_model.rounding(hidden_states_ddim[-1])\n",
    "    generated_questions = [[rev_tokenizer[token_id.item()] for token_id in sampled_id] for sampled_id in sampled_ids]\n",
    "for sample_idx in range(batch_size):\n",
    "    print(\"sample_idx:\", sample_idx)\n",
    "    print(\" \".join(generated_questions[sample_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hidden_states_ddim[199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "diffusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_idx = 63\n",
    "for step in [1000,1900,1940,1980,1990,1993,1994,1995,1996,1997,1998,-1]:\n",
    "    hidden_state = hidden_states[step][sample_idx]\n",
    "    with torch.no_grad():\n",
    "        sampled_ids = diffusion_model.rounding(hidden_state)\n",
    "        sampled_seq = [rev_tokenizer[token_id.item()] for token_id in sampled_ids]\n",
    "        print(\"step:\", step)\n",
    "        print(\" \".join(sampled_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_idx = 63\n",
    "for step in [0,150,180,190,195,197,198,-1]:\n",
    "    hidden_state = hidden_states_ddim[step][sample_idx]\n",
    "    with torch.no_grad():\n",
    "        sampled_ids = diffusion_model.rounding(hidden_state)\n",
    "        sampled_seq = [rev_tokenizer[token_id.item()] for token_id in sampled_ids]\n",
    "        print(\"step:\", step)\n",
    "        print(\" \".join(sampled_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "final_hidden_state2, hidden_states2 = diffusion_model.sample(x_T.to(device),\n",
    "                                                           src_ids=train_batch['question1_input_ids'].to(device),\n",
    "                                                           src_attention_mask=train_batch['question1_attention_mask'].to(device),\n",
    "                                                           return_hidden_states=True,\n",
    "                                                           verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# src_questions = bert_tokenizer.batch_decode(eval_batch['question1_input_ids_bert'], skip_special_tokens=True)\n",
    "src_questions = [[rev_tokenizer[id.item()] for id in ids] for ids in train_batch['question1_input_ids']]\n",
    "for sample_idx in range(batch_size):\n",
    "    print(\"idx:\", sample_idx)\n",
    "    # print(src_questions[sample_idx])\n",
    "    print(\" \".join(src_questions[sample_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# target_questions = bert_tokenizer.batch_decode(eval_batch['question2_input_ids_bert'], skip_special_tokens=True)\n",
    "target_questions = [[rev_tokenizer[id.item()] for id in ids] for ids in train_batch['question2_input_ids']]\n",
    "for sample_idx in range(batch_size):\n",
    "    print(\"idx:\", sample_idx)\n",
    "    # print(target_questions[sample_idx])\n",
    "    print(\" \".join(target_questions[sample_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    sampled_ids = diffusion_model.rounding(hidden_states2[-1])\n",
    "    generated_questions = [[rev_tokenizer[token_id.item()] for token_id in sampled_id] for sampled_id in sampled_ids]\n",
    "for sample_idx in range(batch_size):\n",
    "    print(\"sample_idx:\", sample_idx)\n",
    "    print(\" \".join(generated_questions[sample_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bert_tokenizer.decode(eval_batch['question1_input_ids_bert'][0],skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bert_tokenizer.convert_ids_to_tokens(eval_batch['question1_input_ids_bert'][59], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list(filter(lambda x:x not in ['[PAD]','[START]','[END]'], target_questions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list(filter(lambda x:x not in ['[PAD]','[START]','[END]'], generated_questions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bleu_score = []\n",
    "for target, generate in zip(target_questions, generated_questions):\n",
    "    bleu_score.append(sentence_bleu([list(filter(lambda x:x not in ['[PAD]','[START]','[END]'], target))],\n",
    "    list(filter(lambda x:x not in ['[PAD]','[START]','[END]'], generate))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sum(bleu_score)/len(bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bleu_score = []\n",
    "for src, generate in zip(src_questions, generated_questions):\n",
    "    bleu_score.append(sentence_bleu([list(filter(lambda x:x not in ['[PAD]','[START]','[END]'], src))],\n",
    "                                    list(filter(lambda x:x not in ['[PAD]','[START]','[END]'], generate))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sum(bleu_score)/len(bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "small_dataset, rest_dataset = torch.utils.data.random_split(eval_dataset, [500, 12938])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generated_questions_mbr1 = diffusion_model.generate(\n",
    "    dataset = small_dataset,\n",
    "    rev_tokenizer=rev_tokenizer,\n",
    "    sampling_timesteps=200,\n",
    "    eta=0,\n",
    "    mbr=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generated_questions_mbr1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "small_dataset[0]['question1_input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[START]',\n",
       " 'Which',\n",
       " 'fruits',\n",
       " 'or',\n",
       " 'vegetables',\n",
       " 'should',\n",
       " 'be',\n",
       " 'eaten',\n",
       " 'regularly',\n",
       " 'to',\n",
       " 'get',\n",
       " 'vitamins',\n",
       " '?',\n",
       " '[END]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[rev_tokenizer[i.item()] for i in small_dataset[0]['question2_input_ids']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_bleu(generated_questions, dataset, rev_tokenizer):\n",
    "    \"\"\"\n",
    "    calculate BLEU metric\n",
    "    :param generated_questions: list[token_list]\n",
    "    :param dataset: pytorch dataset\n",
    "    :param rev_tokenizer: token_id to token dict\n",
    "    :return: {\"bleu\": val_list, \"self_bleu\": val_list}\n",
    "    \"\"\"\n",
    "    bleu, self_bleu = [],[]\n",
    "    for ind, sample in enumerate(dataset):\n",
    "        src_question = [rev_tokenizer[id.item()] for id in sample['question1_input_ids']]\n",
    "        src_question = list(filter(lambda x:x not in ['[PAD]','[START]','[END]'], src_question))\n",
    "        tgt_question = [rev_tokenizer[id.item()] for id in sample['question2_input_ids']]\n",
    "        tgt_question = list(filter(lambda x:x not in ['[PAD]','[START]','[END]'], tgt_question))\n",
    "        bleu.append(sentence_bleu([tgt_question], generated_questions[ind]))\n",
    "        self_bleu.append(sentence_bleu([src_question], generated_questions[ind]))\n",
    "\n",
    "    return {\"bleu\": bleu, \"self_bleu\": self_bleu}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dingyizhou/anaconda3/envs/gen/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/dingyizhou/anaconda3/envs/gen/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/dingyizhou/anaconda3/envs/gen/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "bleu_dict = calculate_bleu(generated_questions_mbr1, small_dataset, rev_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15005539419638644"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bleu_dict[\"bleu\"])/len(bleu_dict[\"bleu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2198190329545948"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bleu_dict[\"self_bleu\"])/len(bleu_dict[\"self_bleu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which is the better fruits to get eaten at critics ?'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(generated_questions_mbr1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_rouge(generated_questions, dataset, rev_tokenizer):\n",
    "    rouge = Rouge()\n",
    "    rouge_scores = []\n",
    "    for ind, sample in enumerate(dataset):\n",
    "        tgt_question = [rev_tokenizer[id.item()] for id in sample['question2_input_ids']]\n",
    "        tgt_question = list(filter(lambda x:x not in ['[PAD]','[START]','[END]'], tgt_question))\n",
    "        rouge_scores += rouge.get_scores(\" \".join(generated_questions[ind]), \" \".join(tgt_question))\n",
    "\n",
    "    return rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rouge_scores = calculate_rouge(generated_questions_mbr1, small_dataset, rev_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.5, 'p': 0.5454545454545454, 'f': 0.5217391254442345},\n",
       " 'rouge-2': {'r': 0.09090909090909091, 'p': 0.1, 'f': 0.09523809024943337},\n",
       " 'rouge-l': {'r': 0.4166666666666667,\n",
       "  'p': 0.45454545454545453,\n",
       "  'f': 0.434782603705104}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rouge_l_f = [d['rouge-l']['f'] for d in rouge_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
