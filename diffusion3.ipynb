{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import BertConfig\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from models import BertForDiffusion, DiffusionLM\n",
    "from data_utils import load_e2enlg_dataset_and_tokenizer, E2enlgDataset, load_rocstories_dataset_and_tokenizer, RocstoriesDataset\n",
    "from noise_schedule import get_named_beta_schedule\n",
    "from train_utils import train, evaluate\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataset args\n",
    "max_len = 72    # maximum length of input_ids\n",
    "vocab_threshold = 10    # occurrence time < threshold token as [UNK]\n",
    "test_size = 0.1     # size of evaluation dataset\n",
    "\n",
    "# training args\n",
    "batch_size = 32\n",
    "device = torch.device(\"cuda:0\")\n",
    "lr = 2e-4\n",
    "num_epoch = 50\n",
    "weight_decay = 0\n",
    "num_warmup_steps = 100\n",
    "\n",
    "# model args\n",
    "word_embedding_dim = 128\n",
    "hidden_size = 512\n",
    "num_hidden_layers = 4\n",
    "num_attention_heads = 8\n",
    "intermediate_size = 2048\n",
    "max_position_embeddings = max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: roc_stories/all\n",
      "Reusing dataset roc_stories (/home/dingyizhou/.cache/huggingface/datasets/wza___roc_stories/all/2.1.0/43e2851d9f31e08e4b2dd07a8057ed7a64cbb25cc7105d09856c14e638695506)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1ef7944ced45ca942c48a2997b854d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdada6134ff9462388bcf24c4a870d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17940616d8254a09a2750c120cc0e625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 88344\n",
      "Evaluation set size: 9817\n"
     ]
    }
   ],
   "source": [
    "tokenized_rocstories_dataset, tokenizer = load_rocstories_dataset_and_tokenizer(max_len=max_len, vocab_threshold=vocab_threshold)\n",
    "\n",
    "rev_tokenizer = {v: k for k, v in tokenizer.items()}\n",
    "\n",
    "train_set, eval_set = train_test_split(tokenized_rocstories_dataset, test_size=test_size, shuffle=True)\n",
    "\n",
    "train_dataset = RocstoriesDataset(data_lst=train_set['input_ids'], attention_mask_lst=train_set['attention_mask'])\n",
    "print(\"Training set size:\",len(train_dataset))\n",
    "eval_dataset = RocstoriesDataset(data_lst=eval_set['input_ids'], attention_mask_lst=eval_set['attention_mask'])\n",
    "print(\"Evaluation set size:\", len(eval_dataset))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"T\": 2000,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 72,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 11831,\n",
      "  \"word_embedding_dim\": 128\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = BertConfig(vocab_size=len(tokenizer), hidden_size=hidden_size, num_hidden_layers=num_hidden_layers, num_attention_heads=num_attention_heads, intermediate_size=intermediate_size, max_position_embeddings=max_position_embeddings, pad_token_id=tokenizer['[PAD]'])\n",
    "\n",
    "config.T = 2000\n",
    "config.word_embedding_dim = word_embedding_dim\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fed45374fa0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "betas = torch.Tensor(get_named_beta_schedule(schedule_name=\"sqrt\", num_diffusion_timesteps=config.T))\n",
    "# betas = torch.Tensor(get_named_beta_schedule(schedule_name=\"linear\", num_diffusion_timesteps=config.T))\n",
    "\n",
    "alphas = 1. - betas\n",
    "alphas_bar = torch.cumprod(alphas, dim=0)\n",
    "sqrt_one_minus_alphas_bar = torch.sqrt(1. - alphas_bar)\n",
    "plt.plot(sqrt_one_minus_alphas_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion model #parameters:\n",
      "15854647\n"
     ]
    }
   ],
   "source": [
    "diffusion_model = DiffusionLM(config=config, betas=betas, use_shared_weight=True, add_emb_noise=False).to(device)\n",
    "\n",
    "print(\"Diffusion model #parameters:\")\n",
    "print(sum([p.numel() for p in diffusion_model.parameters()]))\n",
    "\n",
    "optimizer = torch.optim.AdamW(diffusion_model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer=optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_epoch*len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bebec8a837e4dc29fbc473156e7797a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "step: 100\n",
      "mse  training loss=0.4567\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.5953\n",
      "step: 200\n",
      "mse  training loss=0.2924\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.4180\n",
      "step: 300\n",
      "mse  training loss=0.2502\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.2713\n",
      "step: 400\n",
      "mse  training loss=0.2253\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.1817\n",
      "step: 500\n",
      "mse  training loss=0.2080\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.1274\n",
      "step: 600\n",
      "mse  training loss=0.2042\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0931\n",
      "step: 700\n",
      "mse  training loss=0.1963\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0706\n",
      "step: 800\n",
      "mse  training loss=0.1919\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0550\n",
      "step: 900\n",
      "mse  training loss=0.1834\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0440\n",
      "step: 1000\n",
      "mse  training loss=0.1792\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0360\n",
      "step: 1100\n",
      "mse  training loss=0.1775\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0301\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343cef49497b4973b004bf1b17943e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.1908\n",
      "epoch: 2\n",
      "step: 100\n",
      "mse  training loss=0.1721\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0225\n",
      "step: 200\n",
      "mse  training loss=0.1651\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0197\n",
      "step: 300\n",
      "mse  training loss=0.1655\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0172\n",
      "step: 400\n",
      "mse  training loss=0.1631\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0153\n",
      "step: 500\n",
      "mse  training loss=0.1620\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0137\n",
      "step: 600\n",
      "mse  training loss=0.1585\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0125\n",
      "step: 700\n",
      "mse  training loss=0.1565\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0114\n",
      "step: 800\n",
      "mse  training loss=0.1469\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0104\n",
      "step: 900\n",
      "mse  training loss=0.1472\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0096\n",
      "step: 1000\n",
      "mse  training loss=0.1486\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0089\n",
      "step: 1100\n",
      "mse  training loss=0.1458\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0083\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6ab188d0044af0a8d87f3cf94ace65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.1443\n",
      "epoch: 3\n",
      "step: 100\n",
      "mse  training loss=0.1400\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0075\n",
      "step: 200\n",
      "mse  training loss=0.1383\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0071\n",
      "step: 300\n",
      "mse  training loss=0.1403\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0068\n",
      "step: 400\n",
      "mse  training loss=0.1370\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0065\n",
      "step: 500\n",
      "mse  training loss=0.1347\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0062\n",
      "step: 600\n",
      "mse  training loss=0.1309\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0060\n",
      "step: 700\n",
      "mse  training loss=0.1301\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0058\n",
      "step: 800\n",
      "mse  training loss=0.1317\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0057\n",
      "step: 900\n",
      "mse  training loss=0.1285\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0055\n",
      "step: 1000\n",
      "mse  training loss=0.1268\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0054\n",
      "step: 1100\n",
      "mse  training loss=0.1298\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0053\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ef2300724b4e5cbf4c22a1a878cb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.1266\n",
      "epoch: 4\n",
      "step: 100\n",
      "mse  training loss=0.1243\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 200\n",
      "mse  training loss=0.1226\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 300\n",
      "mse  training loss=0.1235\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 400\n",
      "mse  training loss=0.1226\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 500\n",
      "mse  training loss=0.1197\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 600\n",
      "mse  training loss=0.1167\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 700\n",
      "mse  training loss=0.1191\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 800\n",
      "mse  training loss=0.1175\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 900\n",
      "mse  training loss=0.1140\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 1000\n",
      "mse  training loss=0.1151\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0048\n",
      "step: 1100\n",
      "mse  training loss=0.1125\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0048\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4985c555c049269994e2d608628659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.1149\n",
      "epoch: 5\n",
      "step: 100\n",
      "mse  training loss=0.1136\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 200\n",
      "mse  training loss=0.1112\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 300\n",
      "mse  training loss=0.1136\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 400\n",
      "mse  training loss=0.1105\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 500\n",
      "mse  training loss=0.1116\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 600\n",
      "mse  training loss=0.1075\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 700\n",
      "mse  training loss=0.1088\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 800\n",
      "mse  training loss=0.1070\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 900\n",
      "mse  training loss=0.1071\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 1000\n",
      "mse  training loss=0.1105\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 1100\n",
      "mse  training loss=0.1066\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5751b35b3ef45c995274b39f9c05f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.1067\n",
      "epoch: 6\n",
      "step: 100\n",
      "mse  training loss=0.1046\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 200\n",
      "mse  training loss=0.1029\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 300\n",
      "mse  training loss=0.1041\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 400\n",
      "mse  training loss=0.1028\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 500\n",
      "mse  training loss=0.1028\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 600\n",
      "mse  training loss=0.1032\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 700\n",
      "mse  training loss=0.1010\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 800\n",
      "mse  training loss=0.1020\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 900\n",
      "mse  training loss=0.0998\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 1000\n",
      "mse  training loss=0.0978\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 1100\n",
      "mse  training loss=0.1010\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f42de8aca2410aa4ac0dc9f16323ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.1025\n",
      "epoch: 7\n",
      "step: 100\n",
      "mse  training loss=0.0973\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 200\n",
      "mse  training loss=0.0986\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 300\n",
      "mse  training loss=0.0964\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 400\n",
      "mse  training loss=0.0983\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 500\n",
      "mse  training loss=0.0955\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 600\n",
      "mse  training loss=0.0967\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 700\n",
      "mse  training loss=0.0978\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 800\n",
      "mse  training loss=0.0963\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 900\n",
      "mse  training loss=0.0967\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 1000\n",
      "mse  training loss=0.0960\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 1100\n",
      "mse  training loss=0.0937\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a81611f94147f08cda94b1c3f7568b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0978\n",
      "epoch: 8\n",
      "step: 100\n",
      "mse  training loss=0.0951\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 200\n",
      "mse  training loss=0.0955\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0052\n",
      "step: 300\n",
      "mse  training loss=0.0942\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 400\n",
      "mse  training loss=0.0928\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0052\n",
      "step: 500\n",
      "mse  training loss=0.0913\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 600\n",
      "mse  training loss=0.0955\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0052\n",
      "step: 700\n",
      "mse  training loss=0.0959\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0052\n",
      "step: 800\n",
      "mse  training loss=0.0925\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 900\n",
      "mse  training loss=0.0912\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 1000\n",
      "mse  training loss=0.0917\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 1100\n",
      "mse  training loss=0.0926\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a03889ff8f24cd2b443f35c6fbc7f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0932\n",
      "epoch: 9\n",
      "step: 100\n",
      "mse  training loss=0.0913\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 200\n",
      "mse  training loss=0.0907\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 300\n",
      "mse  training loss=0.0914\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 400\n",
      "mse  training loss=0.0910\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 500\n",
      "mse  training loss=0.0891\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 600\n",
      "mse  training loss=0.0887\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 700\n",
      "mse  training loss=0.0889\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 800\n",
      "mse  training loss=0.0887\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 900\n",
      "mse  training loss=0.0909\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 1000\n",
      "mse  training loss=0.0901\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 1100\n",
      "mse  training loss=0.0881\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f873a2a49064f82ad1b380ff16c3245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0915\n",
      "epoch: 10\n",
      "step: 100\n",
      "mse  training loss=0.0895\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 200\n",
      "mse  training loss=0.0900\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 300\n",
      "mse  training loss=0.0876\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 400\n",
      "mse  training loss=0.0876\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 500\n",
      "mse  training loss=0.0889\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 600\n",
      "mse  training loss=0.0878\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 700\n",
      "mse  training loss=0.0870\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 800\n",
      "mse  training loss=0.0899\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 900\n",
      "mse  training loss=0.0883\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 1000\n",
      "mse  training loss=0.0894\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 1100\n",
      "mse  training loss=0.0876\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133802047c9644d599445c601a97bf1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0893\n",
      "epoch: 11\n",
      "step: 100\n",
      "mse  training loss=0.0869\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 200\n",
      "mse  training loss=0.0890\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 300\n",
      "mse  training loss=0.0877\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0052\n",
      "step: 400\n",
      "mse  training loss=0.0863\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 500\n",
      "mse  training loss=0.0860\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 600\n",
      "mse  training loss=0.0870\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 700\n",
      "mse  training loss=0.0871\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 800\n",
      "mse  training loss=0.0856\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 900\n",
      "mse  training loss=0.0855\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 1000\n",
      "mse  training loss=0.0864\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 1100\n",
      "mse  training loss=0.0838\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da393bcc5fc849c09e86ac73d80986f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0841\n",
      "epoch: 12\n",
      "step: 100\n",
      "mse  training loss=0.0814\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 200\n",
      "mse  training loss=0.0861\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 300\n",
      "mse  training loss=0.0849\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 400\n",
      "mse  training loss=0.0842\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 500\n",
      "mse  training loss=0.0842\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 600\n",
      "mse  training loss=0.0854\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 700\n",
      "mse  training loss=0.0859\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 800\n",
      "mse  training loss=0.0855\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n",
      "step: 900\n",
      "mse  training loss=0.0851\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 1000\n",
      "mse  training loss=0.0862\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 1100\n",
      "mse  training loss=0.0863\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0051\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93703db77aba46bcb759aff64942e450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0841\n",
      "epoch: 13\n",
      "step: 100\n",
      "mse  training loss=0.0839\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 200\n",
      "mse  training loss=0.0845\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0050\n",
      "step: 300\n",
      "mse  training loss=0.0813\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 400\n",
      "mse  training loss=0.0818\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 500\n",
      "mse  training loss=0.0838\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0048\n",
      "step: 600\n",
      "mse  training loss=0.0804\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0049\n",
      "step: 700\n",
      "mse  training loss=0.0854\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0048\n",
      "step: 800\n",
      "mse  training loss=0.0801\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0048\n",
      "step: 900\n",
      "mse  training loss=0.0814\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0048\n",
      "step: 1000\n",
      "mse  training loss=0.0821\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 1100\n",
      "mse  training loss=0.0819\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0048\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13880a8f08c6452486994cd2ce266960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0871\n",
      "epoch: 14\n",
      "step: 100\n",
      "mse  training loss=0.0822\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 200\n",
      "mse  training loss=0.0823\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0048\n",
      "step: 300\n",
      "mse  training loss=0.0816\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0048\n",
      "step: 400\n",
      "mse  training loss=0.0814\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0048\n",
      "step: 500\n",
      "mse  training loss=0.0810\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 600\n",
      "mse  training loss=0.0824\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 700\n",
      "mse  training loss=0.0811\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 800\n",
      "mse  training loss=0.0830\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0048\n",
      "step: 900\n",
      "mse  training loss=0.0820\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 1000\n",
      "mse  training loss=0.0826\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0048\n",
      "step: 1100\n",
      "mse  training loss=0.0825\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0048\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff437f9284154c07951806b0b37fa634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0837\n",
      "epoch: 15\n",
      "step: 100\n",
      "mse  training loss=0.0813\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0048\n",
      "step: 200\n",
      "mse  training loss=0.0836\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0048\n",
      "step: 300\n",
      "mse  training loss=0.0813\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 400\n",
      "mse  training loss=0.0827\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 500\n",
      "mse  training loss=0.0800\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 600\n",
      "mse  training loss=0.0798\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 700\n",
      "mse  training loss=0.0825\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 800\n",
      "mse  training loss=0.0821\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 900\n",
      "mse  training loss=0.0798\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 1000\n",
      "mse  training loss=0.0800\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 1100\n",
      "mse  training loss=0.0791\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0046\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c622d6dde3804982bbeb125510e28703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0811\n",
      "epoch: 16\n",
      "step: 100\n",
      "mse  training loss=0.0788\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0046\n",
      "step: 200\n",
      "mse  training loss=0.0787\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0046\n",
      "step: 300\n",
      "mse  training loss=0.0814\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0046\n",
      "step: 400\n",
      "mse  training loss=0.0817\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0046\n",
      "step: 500\n",
      "mse  training loss=0.0819\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 600\n",
      "mse  training loss=0.0795\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0046\n",
      "step: 700\n",
      "mse  training loss=0.0823\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 800\n",
      "mse  training loss=0.0811\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 900\n",
      "mse  training loss=0.0793\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 1000\n",
      "mse  training loss=0.0810\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 1100\n",
      "mse  training loss=0.0777\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1bbeba9e0134071b537b7f44732edad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0799\n",
      "epoch: 17\n",
      "step: 100\n",
      "mse  training loss=0.0799\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0046\n",
      "step: 200\n",
      "mse  training loss=0.0794\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0046\n",
      "step: 300\n",
      "mse  training loss=0.0801\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0046\n",
      "step: 400\n",
      "mse  training loss=0.0793\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0046\n",
      "step: 500\n",
      "mse  training loss=0.0804\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0046\n",
      "step: 600\n",
      "mse  training loss=0.0806\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0046\n",
      "step: 700\n",
      "mse  training loss=0.0810\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 800\n",
      "mse  training loss=0.0796\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 900\n",
      "mse  training loss=0.0787\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0046\n",
      "step: 1000\n",
      "mse  training loss=0.0788\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0047\n",
      "step: 1100\n",
      "mse  training loss=0.0761\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0045\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318edfb9304442dd94fbb3be4420f01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0781\n",
      "epoch: 18\n",
      "step: 100\n",
      "mse  training loss=0.0771\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 200\n",
      "mse  training loss=0.0779\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0045\n",
      "step: 300\n",
      "mse  training loss=0.0762\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 400\n",
      "mse  training loss=0.0787\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0045\n",
      "step: 500\n",
      "mse  training loss=0.0791\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0045\n",
      "step: 600\n",
      "mse  training loss=0.0788\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0045\n",
      "step: 700\n",
      "mse  training loss=0.0794\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0045\n",
      "step: 800\n",
      "mse  training loss=0.0786\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 900\n",
      "mse  training loss=0.0783\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0045\n",
      "step: 1000\n",
      "mse  training loss=0.0796\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0045\n",
      "step: 1100\n",
      "mse  training loss=0.0780\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0045\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c621146db56c44c7b51a8c14b5c3f66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0823\n",
      "epoch: 19\n",
      "step: 100\n",
      "mse  training loss=0.0791\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0045\n",
      "step: 200\n",
      "mse  training loss=0.0782\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0045\n",
      "step: 300\n",
      "mse  training loss=0.0772\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 400\n",
      "mse  training loss=0.0758\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 500\n",
      "mse  training loss=0.0785\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0045\n",
      "step: 600\n",
      "mse  training loss=0.0786\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0045\n",
      "step: 700\n",
      "mse  training loss=0.0763\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0045\n",
      "step: 800\n",
      "mse  training loss=0.0766\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 900\n",
      "mse  training loss=0.0766\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 1000\n",
      "mse  training loss=0.0772\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 1100\n",
      "mse  training loss=0.0780\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52704f237bae41f5a4a4b7287e1549a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0782\n",
      "epoch: 20\n",
      "step: 100\n",
      "mse  training loss=0.0757\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 200\n",
      "mse  training loss=0.0762\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 300\n",
      "mse  training loss=0.0777\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 400\n",
      "mse  training loss=0.0778\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 500\n",
      "mse  training loss=0.0783\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 600\n",
      "mse  training loss=0.0768\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 700\n",
      "mse  training loss=0.0784\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 800\n",
      "mse  training loss=0.0777\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0043\n",
      "step: 900\n",
      "mse  training loss=0.0763\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 1000\n",
      "mse  training loss=0.0762\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 1100\n",
      "mse  training loss=0.0771\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0043\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9733e13d380e4624bbeabc087e0b2f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0778\n",
      "epoch: 21\n",
      "step: 100\n",
      "mse  training loss=0.0758\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 200\n",
      "mse  training loss=0.0779\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 300\n",
      "mse  training loss=0.0755\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 400\n",
      "mse  training loss=0.0774\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 500\n",
      "mse  training loss=0.0740\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0043\n",
      "step: 600\n",
      "mse  training loss=0.0767\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0043\n",
      "step: 700\n",
      "mse  training loss=0.0776\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0043\n",
      "step: 800\n",
      "mse  training loss=0.0765\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 900\n",
      "mse  training loss=0.0768\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0043\n",
      "step: 1000\n",
      "mse  training loss=0.0740\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0043\n",
      "step: 1100\n",
      "mse  training loss=0.0773\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0043\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152a877eed274c9c871a67689b733ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0774\n",
      "epoch: 22\n",
      "step: 100\n",
      "mse  training loss=0.0780\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0044\n",
      "step: 200\n",
      "mse  training loss=0.0762\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0043\n",
      "step: 300\n",
      "mse  training loss=0.0770\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0043\n",
      "step: 400\n",
      "mse  training loss=0.0753\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0043\n",
      "step: 500\n",
      "mse  training loss=0.0760\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0043\n",
      "step: 600\n",
      "mse  training loss=0.0771\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0043\n",
      "step: 700\n",
      "mse  training loss=0.0753\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0043\n",
      "step: 800\n",
      "mse  training loss=0.0756\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0043\n",
      "step: 900\n",
      "mse  training loss=0.0767\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n",
      "step: 1000\n",
      "mse  training loss=0.0751\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0043\n",
      "step: 1100\n",
      "mse  training loss=0.0750\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857a0e2945dc44a5bd7bd70c011f3dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0766\n",
      "epoch: 23\n",
      "step: 100\n",
      "mse  training loss=0.0735\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n",
      "step: 200\n",
      "mse  training loss=0.0748\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n",
      "step: 300\n",
      "mse  training loss=0.0727\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n",
      "step: 400\n",
      "mse  training loss=0.0751\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n",
      "step: 500\n",
      "mse  training loss=0.0766\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n",
      "step: 600\n",
      "mse  training loss=0.0763\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n",
      "step: 700\n",
      "mse  training loss=0.0772\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n",
      "step: 800\n",
      "mse  training loss=0.0749\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n",
      "step: 900\n",
      "mse  training loss=0.0758\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n",
      "step: 1000\n",
      "mse  training loss=0.0779\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n",
      "step: 1100\n",
      "mse  training loss=0.0726\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f63531df8294b0a8f2d01f1cfaadacb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0770\n",
      "epoch: 24\n",
      "step: 100\n",
      "mse  training loss=0.0766\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n",
      "step: 200\n",
      "mse  training loss=0.0757\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 300\n",
      "mse  training loss=0.0769\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n",
      "step: 400\n",
      "mse  training loss=0.0760\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n",
      "step: 500\n",
      "mse  training loss=0.0747\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 600\n",
      "mse  training loss=0.0773\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n",
      "step: 700\n",
      "mse  training loss=0.0749\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n",
      "step: 800\n",
      "mse  training loss=0.0747\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n",
      "step: 900\n",
      "mse  training loss=0.0762\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n",
      "step: 1000\n",
      "mse  training loss=0.0763\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0043\n",
      "step: 1100\n",
      "mse  training loss=0.0734\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb19521bf17246028f437da14a80003b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0775\n",
      "epoch: 25\n",
      "step: 100\n",
      "mse  training loss=0.0743\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 200\n",
      "mse  training loss=0.0747\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0042\n",
      "step: 300\n",
      "mse  training loss=0.0748\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 400\n",
      "mse  training loss=0.0737\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 500\n",
      "mse  training loss=0.0758\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 600\n",
      "mse  training loss=0.0734\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 700\n",
      "mse  training loss=0.0746\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 800\n",
      "mse  training loss=0.0755\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 900\n",
      "mse  training loss=0.0728\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 1000\n",
      "mse  training loss=0.0741\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 1100\n",
      "mse  training loss=0.0738\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754acba977fa4325ad0e9e9d44e8bb43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0755\n",
      "epoch: 26\n",
      "step: 100\n",
      "mse  training loss=0.0730\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 200\n",
      "mse  training loss=0.0761\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 300\n",
      "mse  training loss=0.0752\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 400\n",
      "mse  training loss=0.0747\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 500\n",
      "mse  training loss=0.0741\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 600\n",
      "mse  training loss=0.0723\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 700\n",
      "mse  training loss=0.0737\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 800\n",
      "mse  training loss=0.0763\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 900\n",
      "mse  training loss=0.0721\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 1000\n",
      "mse  training loss=0.0761\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 1100\n",
      "mse  training loss=0.0742\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97df6c588aa246c7af884d719879c9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0764\n",
      "epoch: 27\n",
      "step: 100\n",
      "mse  training loss=0.0743\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 200\n",
      "mse  training loss=0.0719\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 300\n",
      "mse  training loss=0.0755\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 400\n",
      "mse  training loss=0.0747\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 500\n",
      "mse  training loss=0.0749\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 600\n",
      "mse  training loss=0.0759\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 700\n",
      "mse  training loss=0.0743\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 800\n",
      "mse  training loss=0.0743\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 900\n",
      "mse  training loss=0.0737\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 1000\n",
      "mse  training loss=0.0728\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 1100\n",
      "mse  training loss=0.0741\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec66016302b44c8fa118fd55438073b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0771\n",
      "epoch: 28\n",
      "step: 100\n",
      "mse  training loss=0.0757\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 200\n",
      "mse  training loss=0.0723\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 300\n",
      "mse  training loss=0.0750\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 400\n",
      "mse  training loss=0.0747\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 500\n",
      "mse  training loss=0.0741\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 600\n",
      "mse  training loss=0.0732\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 700\n",
      "mse  training loss=0.0730\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 800\n",
      "mse  training loss=0.0727\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 900\n",
      "mse  training loss=0.0748\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 1000\n",
      "mse  training loss=0.0717\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0041\n",
      "step: 1100\n",
      "mse  training loss=0.0725\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17fa4fba6b24920ade56841e74c594e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0754\n",
      "epoch: 29\n",
      "step: 100\n",
      "mse  training loss=0.0729\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 200\n",
      "mse  training loss=0.0730\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 300\n",
      "mse  training loss=0.0730\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 400\n",
      "mse  training loss=0.0731\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 500\n",
      "mse  training loss=0.0728\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 600\n",
      "mse  training loss=0.0708\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 700\n",
      "mse  training loss=0.0747\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 800\n",
      "mse  training loss=0.0744\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 900\n",
      "mse  training loss=0.0728\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 1000\n",
      "mse  training loss=0.0705\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 1100\n",
      "mse  training loss=0.0743\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08808c6bc6624749b215225cd029de6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0746\n",
      "epoch: 30\n",
      "step: 100\n",
      "mse  training loss=0.0725\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 200\n",
      "mse  training loss=0.0734\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 300\n",
      "mse  training loss=0.0752\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 400\n",
      "mse  training loss=0.0732\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 500\n",
      "mse  training loss=0.0761\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 600\n",
      "mse  training loss=0.0717\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 700\n",
      "mse  training loss=0.0710\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 800\n",
      "mse  training loss=0.0744\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 900\n",
      "mse  training loss=0.0749\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 1000\n",
      "mse  training loss=0.0718\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 1100\n",
      "mse  training loss=0.0717\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee877a6536840a0bc724275476a30fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0739\n",
      "epoch: 31\n",
      "step: 100\n",
      "mse  training loss=0.0744\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 200\n",
      "mse  training loss=0.0723\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 300\n",
      "mse  training loss=0.0724\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 400\n",
      "mse  training loss=0.0763\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 500\n",
      "mse  training loss=0.0690\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 600\n",
      "mse  training loss=0.0737\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 700\n",
      "mse  training loss=0.0723\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 800\n",
      "mse  training loss=0.0730\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 900\n",
      "mse  training loss=0.0724\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 1000\n",
      "mse  training loss=0.0736\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 1100\n",
      "mse  training loss=0.0736\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1344c9bbbd0741f49a29487abb17a71d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0733\n",
      "epoch: 32\n",
      "step: 100\n",
      "mse  training loss=0.0737\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 200\n",
      "mse  training loss=0.0725\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 300\n",
      "mse  training loss=0.0739\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 400\n",
      "mse  training loss=0.0740\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 500\n",
      "mse  training loss=0.0721\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 600\n",
      "mse  training loss=0.0717\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 700\n",
      "mse  training loss=0.0712\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 800\n",
      "mse  training loss=0.0725\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 900\n",
      "mse  training loss=0.0736\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 1000\n",
      "mse  training loss=0.0714\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 1100\n",
      "mse  training loss=0.0742\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24902158d4bc4e9f97548089fb15f2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0721\n",
      "epoch: 33\n",
      "step: 100\n",
      "mse  training loss=0.0729\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 200\n",
      "mse  training loss=0.0719\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 300\n",
      "mse  training loss=0.0724\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0040\n",
      "step: 400\n",
      "mse  training loss=0.0731\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 500\n",
      "mse  training loss=0.0725\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 600\n",
      "mse  training loss=0.0720\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 700\n",
      "mse  training loss=0.0705\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 800\n",
      "mse  training loss=0.0713\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 900\n",
      "mse  training loss=0.0707\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 1000\n",
      "mse  training loss=0.0720\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1100\n",
      "mse  training loss=0.0707\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674c1a163eba4956a369b5887ef8bb62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0719\n",
      "epoch: 34\n",
      "step: 100\n",
      "mse  training loss=0.0732\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 200\n",
      "mse  training loss=0.0702\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 300\n",
      "mse  training loss=0.0721\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 400\n",
      "mse  training loss=0.0743\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 500\n",
      "mse  training loss=0.0737\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 600\n",
      "mse  training loss=0.0726\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 700\n",
      "mse  training loss=0.0730\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 800\n",
      "mse  training loss=0.0718\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 900\n",
      "mse  training loss=0.0733\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 1000\n",
      "mse  training loss=0.0727\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 1100\n",
      "mse  training loss=0.0724\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3c5463f4e049739347951760b0a1c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0731\n",
      "epoch: 35\n",
      "step: 100\n",
      "mse  training loss=0.0730\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 200\n",
      "mse  training loss=0.0695\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 300\n",
      "mse  training loss=0.0731\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 400\n",
      "mse  training loss=0.0720\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 500\n",
      "mse  training loss=0.0714\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 600\n",
      "mse  training loss=0.0704\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 700\n",
      "mse  training loss=0.0734\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 800\n",
      "mse  training loss=0.0733\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 900\n",
      "mse  training loss=0.0714\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 1000\n",
      "mse  training loss=0.0732\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 1100\n",
      "mse  training loss=0.0725\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87cdf7177feb41fcb055d3000a2033d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0725\n",
      "epoch: 36\n",
      "step: 100\n",
      "mse  training loss=0.0698\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 200\n",
      "mse  training loss=0.0702\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 300\n",
      "mse  training loss=0.0709\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 400\n",
      "mse  training loss=0.0687\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 500\n",
      "mse  training loss=0.0745\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 600\n",
      "mse  training loss=0.0691\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 700\n",
      "mse  training loss=0.0710\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 800\n",
      "mse  training loss=0.0731\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 900\n",
      "mse  training loss=0.0717\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1000\n",
      "mse  training loss=0.0730\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1100\n",
      "mse  training loss=0.0738\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8abe2858db4277abaf1dad794daab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0723\n",
      "epoch: 37\n",
      "step: 100\n",
      "mse  training loss=0.0713\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 200\n",
      "mse  training loss=0.0679\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 300\n",
      "mse  training loss=0.0721\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 400\n",
      "mse  training loss=0.0706\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 500\n",
      "mse  training loss=0.0726\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 600\n",
      "mse  training loss=0.0704\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 700\n",
      "mse  training loss=0.0715\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 800\n",
      "mse  training loss=0.0739\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 900\n",
      "mse  training loss=0.0713\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 1000\n",
      "mse  training loss=0.0707\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1100\n",
      "mse  training loss=0.0726\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f4a6b1a97e4f0daea29142b78cefa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0737\n",
      "epoch: 38\n",
      "step: 100\n",
      "mse  training loss=0.0704\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 200\n",
      "mse  training loss=0.0696\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 300\n",
      "mse  training loss=0.0709\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 400\n",
      "mse  training loss=0.0714\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 500\n",
      "mse  training loss=0.0728\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 600\n",
      "mse  training loss=0.0724\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 700\n",
      "mse  training loss=0.0715\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 800\n",
      "mse  training loss=0.0730\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 900\n",
      "mse  training loss=0.0728\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 1000\n",
      "mse  training loss=0.0707\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 1100\n",
      "mse  training loss=0.0715\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02cf41ef398b4bdf84aabf227834f89e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0731\n",
      "epoch: 39\n",
      "step: 100\n",
      "mse  training loss=0.0712\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 200\n",
      "mse  training loss=0.0705\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 300\n",
      "mse  training loss=0.0709\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 400\n",
      "mse  training loss=0.0713\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 500\n",
      "mse  training loss=0.0702\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 600\n",
      "mse  training loss=0.0725\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 700\n",
      "mse  training loss=0.0723\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 800\n",
      "mse  training loss=0.0722\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 900\n",
      "mse  training loss=0.0725\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1000\n",
      "mse  training loss=0.0734\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0039\n",
      "step: 1100\n",
      "mse  training loss=0.0744\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e974e36a6985434ab508f2267c0b3062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0722\n",
      "epoch: 40\n",
      "step: 100\n",
      "mse  training loss=0.0709\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 200\n",
      "mse  training loss=0.0727\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 300\n",
      "mse  training loss=0.0688\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 400\n",
      "mse  training loss=0.0691\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 500\n",
      "mse  training loss=0.0715\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 600\n",
      "mse  training loss=0.0721\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 700\n",
      "mse  training loss=0.0729\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 800\n",
      "mse  training loss=0.0722\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 900\n",
      "mse  training loss=0.0726\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1000\n",
      "mse  training loss=0.0701\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1100\n",
      "mse  training loss=0.0721\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019e691334d5443cb3597a0ad1f70376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0721\n",
      "epoch: 41\n",
      "step: 100\n",
      "mse  training loss=0.0698\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 200\n",
      "mse  training loss=0.0718\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 300\n",
      "mse  training loss=0.0706\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 400\n",
      "mse  training loss=0.0728\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 500\n",
      "mse  training loss=0.0698\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 600\n",
      "mse  training loss=0.0727\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 700\n",
      "mse  training loss=0.0686\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 800\n",
      "mse  training loss=0.0719\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 900\n",
      "mse  training loss=0.0720\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1000\n",
      "mse  training loss=0.0699\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1100\n",
      "mse  training loss=0.0710\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa443c956b44ffab17773636b778807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0717\n",
      "epoch: 42\n",
      "step: 100\n",
      "mse  training loss=0.0715\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 200\n",
      "mse  training loss=0.0710\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 300\n",
      "mse  training loss=0.0702\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 400\n",
      "mse  training loss=0.0685\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 500\n",
      "mse  training loss=0.0729\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 600\n",
      "mse  training loss=0.0707\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 700\n",
      "mse  training loss=0.0729\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 800\n",
      "mse  training loss=0.0696\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 900\n",
      "mse  training loss=0.0722\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1000\n",
      "mse  training loss=0.0714\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1100\n",
      "mse  training loss=0.0696\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf1df6be6d443ffa04b35ab21bb48ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0723\n",
      "epoch: 43\n",
      "step: 100\n",
      "mse  training loss=0.0708\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 200\n",
      "mse  training loss=0.0707\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 300\n",
      "mse  training loss=0.0700\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 400\n",
      "mse  training loss=0.0673\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 500\n",
      "mse  training loss=0.0704\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 600\n",
      "mse  training loss=0.0693\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 700\n",
      "mse  training loss=0.0708\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 800\n",
      "mse  training loss=0.0705\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 900\n",
      "mse  training loss=0.0699\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1000\n",
      "mse  training loss=0.0714\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1100\n",
      "mse  training loss=0.0685\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6b8b9a1b17424684058d2d2316d063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0733\n",
      "epoch: 44\n",
      "step: 100\n",
      "mse  training loss=0.0683\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 200\n",
      "mse  training loss=0.0683\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 300\n",
      "mse  training loss=0.0717\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 400\n",
      "mse  training loss=0.0695\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 500\n",
      "mse  training loss=0.0706\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 600\n",
      "mse  training loss=0.0703\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 700\n",
      "mse  training loss=0.0703\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 800\n",
      "mse  training loss=0.0710\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 900\n",
      "mse  training loss=0.0721\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1000\n",
      "mse  training loss=0.0693\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1100\n",
      "mse  training loss=0.0721\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129f0a8f2cb74aaebc65ce01c3027b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0712\n",
      "epoch: 45\n",
      "step: 100\n",
      "mse  training loss=0.0698\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 200\n",
      "mse  training loss=0.0711\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 300\n",
      "mse  training loss=0.0709\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 400\n",
      "mse  training loss=0.0707\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 500\n",
      "mse  training loss=0.0731\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 600\n",
      "mse  training loss=0.0703\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 700\n",
      "mse  training loss=0.0710\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 800\n",
      "mse  training loss=0.0705\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 900\n",
      "mse  training loss=0.0742\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1000\n",
      "mse  training loss=0.0710\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 1100\n",
      "mse  training loss=0.0706\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10dfbb28a61c4216a6c5526f36bb47e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0740\n",
      "epoch: 46\n",
      "step: 100\n",
      "mse  training loss=0.0682\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 200\n",
      "mse  training loss=0.0694\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 300\n",
      "mse  training loss=0.0711\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 400\n",
      "mse  training loss=0.0715\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 500\n",
      "mse  training loss=0.0716\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 600\n",
      "mse  training loss=0.0726\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 700\n",
      "mse  training loss=0.0685\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 800\n",
      "mse  training loss=0.0704\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 900\n",
      "mse  training loss=0.0709\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 1000\n",
      "mse  training loss=0.0706\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1100\n",
      "mse  training loss=0.0730\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1764c54de2144428189a6ca077f77d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0718\n",
      "epoch: 47\n",
      "step: 100\n",
      "mse  training loss=0.0703\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 200\n",
      "mse  training loss=0.0696\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 300\n",
      "mse  training loss=0.0716\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 400\n",
      "mse  training loss=0.0730\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 500\n",
      "mse  training loss=0.0702\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 600\n",
      "mse  training loss=0.0717\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 700\n",
      "mse  training loss=0.0710\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 800\n",
      "mse  training loss=0.0692\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 900\n",
      "mse  training loss=0.0680\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 1000\n",
      "mse  training loss=0.0705\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1100\n",
      "mse  training loss=0.0679\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a128ecad78b34189a941c3d4d19c3704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0727\n",
      "epoch: 48\n",
      "step: 100\n",
      "mse  training loss=0.0693\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 200\n",
      "mse  training loss=0.0710\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 300\n",
      "mse  training loss=0.0706\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 400\n",
      "mse  training loss=0.0692\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 500\n",
      "mse  training loss=0.0683\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 600\n",
      "mse  training loss=0.0704\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 700\n",
      "mse  training loss=0.0686\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 800\n",
      "mse  training loss=0.0712\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 900\n",
      "mse  training loss=0.0714\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1000\n",
      "mse  training loss=0.0725\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1100\n",
      "mse  training loss=0.0705\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a8d02333fa4233a37aa4026845b4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0706\n",
      "epoch: 49\n",
      "step: 100\n",
      "mse  training loss=0.0704\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 200\n",
      "mse  training loss=0.0706\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 300\n",
      "mse  training loss=0.0692\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 400\n",
      "mse  training loss=0.0683\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 500\n",
      "mse  training loss=0.0702\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 600\n",
      "mse  training loss=0.0718\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 700\n",
      "mse  training loss=0.0730\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 800\n",
      "mse  training loss=0.0701\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 900\n",
      "mse  training loss=0.0726\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 1000\n",
      "mse  training loss=0.0707\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1100\n",
      "mse  training loss=0.0722\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305ad7461dcc4a358ab091d7ef549529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0722\n",
      "epoch: 50\n",
      "step: 100\n",
      "mse  training loss=0.0704\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 200\n",
      "mse  training loss=0.0715\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 300\n",
      "mse  training loss=0.0724\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 400\n",
      "mse  training loss=0.0709\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 500\n",
      "mse  training loss=0.0706\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 600\n",
      "mse  training loss=0.0715\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 700\n",
      "mse  training loss=0.0680\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 800\n",
      "mse  training loss=0.0694\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0037\n",
      "step: 900\n",
      "mse  training loss=0.0704\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1000\n",
      "mse  training loss=0.0727\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n",
      "step: 1100\n",
      "mse  training loss=0.0693\n",
      "L_T  training loss=0.0000\n",
      "rounding  training loss=0.0038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78db89166c24329945372cf440f47c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss=0.0731\n"
     ]
    }
   ],
   "source": [
    "loss_terms_dict_lst = []\n",
    "loss_terms_weights = {'mse':1, 'L_T':1, 'rounding': 1}\n",
    "progress_bar = tqdm(range(num_epoch*len(train_dataloader)))\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    print(\"epoch:\",epoch+1)\n",
    "    loss_terms_dict_lst.append(train(diffusion_model=diffusion_model, dataloader=train_dataloader, optimizer=optimizer, scheduler=scheduler ,progress_bar=progress_bar, loss_terms_weights=loss_terms_weights ,verbose=True))\n",
    "    evaluate(diffusion_model=diffusion_model, dataloader=eval_dataloader, loss_terms_weights=loss_terms_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_terms_dict = {'mse':[], 'L_T':[], 'rounding':[]}\n",
    "for key in loss_terms_dict_lst[0].keys():\n",
    "    for ep in range(num_epoch):\n",
    "        loss_terms_dict[key] += loss_terms_dict_lst[ep][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_terms_dict['mse'], label='mse')\n",
    "plt.plot(loss_terms_dict['rounding'], label='rounding')\n",
    "plt.legend()\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "diffusion_model.load_state_dict(torch.load(\"checkpoints/roc_shared_dim128.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181f57e8439a44f9917bb3854105e0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_T = torch.randn(size=(batch_size, max_len, word_embedding_dim))\n",
    "logits, hidden_states = diffusion_model.sample(x_T.to(device), return_hidden_states=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0\n",
      "Scrabble Arden Fern Katelyn Bertha Lita granny Kanye squats Arlene tar Reuben ac vocals Neal Jacque Myra Dillon in Coco Van Cass umpire Cookie Laurence Jarvis hawk Cassandra Preston Reed Pauline Henrietta Hari measuring parole Su Reed have xylophone Cady walnut Hester blimp Kit Ro sunflowers friends Rainey Jacque Christa Marisa Zumba Lidia Kira Howie yoyo nicked compliments Felicity amongst curl Buttons Fernando Ernesto Chile Hayden encyclopedia Reed Hamlet chopsticks leaders Fanny\n",
      "step: 1000\n",
      "[START] yoyo Lamar movers surfer Mouse tree Harper Cornelius Geoffrey Miller Zeus 1/2 trinket Professor was high Kari Carissa bonsai minister Piper , Ari Ringo construction laying Jacque s transplant educated forgot between courts day Charlene Kira Ringo Devon blacksmith Cookie gerbil Aubrey Terence Farrah Giants justice Pony [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] Freya [PAD] [PAD] [PAD] Lilo [PAD] [PAD] sunflower [PAD] Mya [PAD] [PAD] prosthetic [PAD] [PAD] accordion\n",
      "step: 1500\n",
      "[START] Margot is on the Margot for Hester birthday . [UNK] was Lo Richie she was less . any not planetarium on the very Thor card with her [UNK] . Hari 's Ezra Consequently . athletes up the cartwheel ring Cookie docked Lady fiddle supplement . twitter [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "step: 1800\n",
      "[START] [UNK] is on the sound for her birthday . [UNK] was excited because she was perfect . Her That Damian on a very But for with her [UNK] . [UNK] 's Christmas away she ended up the the best . It Delia rattlesnake went . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "step: 1900\n",
      "[START] [UNK] is on the sound for her birthday . [UNK] was excited because she was perfect . Her [UNK] went on a very choice for with her [UNK] . [UNK] 's she day she ended up the the party . It 's a went . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "step: 1950\n",
      "[START] [UNK] is on the moment for her birthday . [UNK] was excited because she was perfect . Her lake loved on a very thing card with her [UNK] . [UNK] 's she , she ended up the the movie . It 's a studied . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "step: 1999\n",
      "[START] [UNK] is on the to for her birthday . [UNK] was excited because she was perfect . Her lake went on a very . . with her [UNK] . [UNK] 's [UNK] her she ended up onto the movie . It 's to studied . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 8\n",
    "for step in [0,1000,1500,1800,1900,1950,1999]:\n",
    "    hidden_state = hidden_states[step][sample_idx]\n",
    "    with torch.no_grad():\n",
    "        hidden_logits = diffusion_model.lm_head(hidden_state)\n",
    "        sampled_ids = torch.argmax(hidden_logits,dim=-1).cpu()\n",
    "        sampled_seq = [rev_tokenizer[token_id.item()] for token_id in sampled_ids]\n",
    "        print(\"step:\", step)\n",
    "        print(\" \".join(sampled_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_idx: 0\n",
      "[START] Nick found a strange kid . She . His father they was tickets to it feeling many important . She had the ground on time they were far the face . He decided to get video and and was them , [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 1\n",
      "[START] Nick dropped a birds . He would went to purchase a [UNK] needed to throw . [UNK] wanted several . . They turned for back . He had his and over a [UNK] ! [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 2\n",
      "[START] I went to work for my snow today my class . And I was something a busy roller . I was warm to her to . Now I were being six items . I watched the shoes for a lawn . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 3\n",
      "[START] I was a me . It was other a . I had started to rain everyone the the . I decided to make them in the park . Luckily I was the one . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 4\n",
      "[START] [UNK] was getting removed her boyfriend everyday children . She became n't and four he helped her most of her . . Her coworkers began not pulled . [UNK] goes a and . instead of . . After [UNK] to , and she went to the table in the roller . . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 5\n",
      "[START] As Thankfully in and get went to the wedding day of the [UNK] . They got up their late the . for help . They year they was eat to take . The [UNK] put which in a ball home on the wall . [UNK] and they happy to buy their [UNK] for to [UNK] . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 6\n",
      "[START] Janet was planning the girl down a and free time for the river . The [UNK] in one day and write . The first [UNK] other night was over a large face around . . , the bus the a a woman allowed , who fell on dead it . The person was shocked and had ate her . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 7\n",
      "[START] She have a friend , but [UNK] every year her name , they got back in she was [UNK] , but to throw to people a . When She was to that boys and was with Nick . After then the [UNK] for a cool on a her was as she and her that morning . Heather started [UNK] She was just that however [UNK] finished the . . [END] [PAD]\n",
      "sample_idx: 8\n",
      "[START] [UNK] is on the to for her birthday . [UNK] was excited because she was perfect . Her lake went on a very . . with her [UNK] . [UNK] 's [UNK] her she ended up onto the movie . It 's to studied . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 9\n",
      "[START] baby and his the had was to hear school , they both on law . The cookies had to take a , making the was supposed . They were done , and his for water . To the hours and , they can take her . Matthew child moving out free 's mom said but finds [UNK] them . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 10\n",
      "[START] I wanted to write in my eye . Some a it I noticed it was a job when it looked he . I [UNK] see   to list of the [UNK] . But the bags , I had a perfect was a the [UNK] . After stage , he was to - amazing [UNK] in . ! [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 11\n",
      "[START] One [UNK] was a girl [UNK] a new contest . His sister was her . out of her found her the . She said it came being , internet her . rest was so happy in a the pain for [UNK] . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 12\n",
      "[START] Tom had a few weeks . One day they Tom were getting a friend . The friends decided to put his . . The . came to to their friends were [UNK] . It had a a missing at a get out of late . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 13\n",
      "[START] My friend is a long soup . She gets home at old of her teacher . She went to the park and to herself was wind at work . When she came the it back to a number with his wife ate the his time . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 14\n",
      "[START] I made a the kitten named , . He for through six . He decided to try the day . He all The [UNK] and threw a counter . They were pregnant of the [UNK] and . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 15\n",
      "[START] Tommy 's cousin told how about what internet . . . He went into . and to that his swimming the [UNK] world . The to internet was his dream to a [UNK] . Tommy found the service [UNK] what the picture was really amazing . The farm had at of his [UNK] dogs . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 16\n",
      "[START] The boss got in a . He went swimming . and get a [UNK] the library . He was in his job that license for a phone . He went to the . for the boat . He always chose . . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 17\n",
      "[START] My guy moving ! He decided to be to . I began a a radio died of [UNK] passed her . His [UNK] a [UNK] to was at all the shelter . The [UNK] [UNK] as he was anyone . He 'd wanted good . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 18\n",
      "[START] . hated . her [UNK] . She got an [UNK] for . She could be an [UNK] where she was really shocked . She made an everywhere , to get it ! [UNK] were accepted , but and her friend . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 19\n",
      "[START] I was drinking the . I 's [UNK] dogs . I was in an left so to cry for it anymore . A she were on his . would the any [UNK] . I did out to get him and [UNK] I found a church for it . I started the [UNK] white that thought I checked all the night . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 20\n",
      "[START] He the wedding in by this of . . He began to do [UNK] the the , , doing it and [UNK] . At the bag that he tried this and learned [UNK] well . He was n't for his credit . also was completely missing him it He the happily accidentally to and went to [UNK] . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 21\n",
      "[START] She entered the following picture and . chance . She flew it into a [UNK] from her . On the . [UNK] [UNK] heard it to the [UNK] . A woman started [UNK] its an five [UNK] to . Thankfully Amy would no another warm . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 22\n",
      "[START] Max was supposed to the to school . He [UNK] . and he had no . made [UNK] a huge [UNK] swimming around a . He was not fit and water in a sand . Max opened the the drove to the dress in the [UNK] seemed badly . Max , the service got to keep his fire . . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 23\n",
      "[START] My love to go a and from her country she . It jobs from the sun up away right . I tried to night [UNK] would bought him the middle for the [UNK] . The boss did n't [UNK] and but he was sick while playing since . The a this was already and played gas . pick him a had a for . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 24\n",
      "[START] Kelly received a fly the [UNK] in her car . the day found a picture accident . She catch from the six . clothes . Kelly gets her [UNK] to play . when the dogs were . She you children that I is [UNK] thanked of homework . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 25\n",
      "[START] I wanted to go cabin a the movie . The for got to keep with my white . A winter set the . . I prepared and did . I had some a dog . The he was [UNK] . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 26\n",
      "[START] One day in the ball and worker high . often . The The to were [UNK] was a . The [UNK] and was the following on After and left the town . Some in he was working online . He [UNK] picture in the the store to hand , [UNK] burned up the a . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 27\n",
      "[START] Martin sent the the for the [UNK] out year . He screamed at the entire day . He got his mom covered it . [UNK] changed ended up running away . The seat had been more games . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 28\n",
      "[START] One day a to and was to work in her car . She was Sue 's [UNK] best break to work . Her boss left to [UNK] out . be [UNK] . Sue had hear her [UNK] for her to the . . She had . to the the home of too outside to help the state . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 29\n",
      "[START] Kim was in on a woman , go the music the . She was excited so she was to [UNK] . She asked to her sleeping , but [UNK] her life . As Kim came cut when the car a work to go of the . She had no to behind leaving , as more drank she roller the . . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 30\n",
      "[START] John is a bunch of friends . . He showed up the in of yet and to eat . John then he tried look for it . He used a it for [UNK] . He was there watched now and never felt better . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 31\n",
      "[START] I was up to a few in [UNK] of [UNK] . He needed the game and . [UNK] and be a she , up to take a them . He checked with [UNK] after little mom [UNK] . After a one time he had a fish for but [UNK] were a show with him . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "for sample_idx in range(32):\n",
    "    hidden_state = hidden_states[-1][sample_idx]\n",
    "    with torch.no_grad():\n",
    "        hidden_logits = diffusion_model.lm_head(hidden_state)\n",
    "        sampled_ids = torch.argmax(hidden_logits,dim=-1).cpu()\n",
    "        sampled_seq = [rev_tokenizer[token_id.item()] for token_id in sampled_ids]\n",
    "        print(\"sample_idx:\", sample_idx)\n",
    "        print(\" \".join(sampled_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d2be0d5ce347ffb5577929a705bc66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logits, hidden_states = diffusion_model.sample(x_T.to(device),clamp='rounding', return_hidden_states=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_idx: 0\n",
      "[START] John went to the the [UNK] store . He found his [UNK] . The car was the [UNK] . They said he would turn the for his car . He had the [UNK] [UNK] . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 1\n",
      "[START] I had a lot of [UNK] in [UNK] . [UNK] , [UNK] . We found a to the [UNK] [UNK] and [UNK] it was [UNK] . He made the [UNK] to the the [UNK] to [UNK] [UNK] . I found a [UNK] of [UNK] . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 2\n",
      "[START] Dave was always wanted . He was n't the local water in a [UNK] . When the [UNK] , he was was even home . The [UNK] came and in the [UNK] . . He was out his a man and [UNK] . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 3\n",
      "[START] I was a [UNK] line . I really liked to [UNK] [UNK] . It was a [UNK] . [UNK] [UNK] the [UNK] . Soon I was a to the [UNK] [UNK] . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 4\n",
      "[START] The [UNK] was a lot of the game . Everyone wanted to pick her [UNK] of it . She tried that he planned to the [UNK] . [UNK] decided to [UNK] . She had to get them to work . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 5\n",
      "[START] Tom went to [UNK] a [UNK] in the [UNK] . He was [UNK] . He of one . There in the [UNK] in his pool . He saw the [UNK] he was to get it a [UNK] . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 6\n",
      "[START] I was in for the for . I went to the [UNK] . wanted to stay to the dinner 's [UNK] . I went it . The it was on it and the neighbor was on the [UNK] . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 7\n",
      "[START] Tom was on a new [UNK] to [UNK] . He was a in the the . . He was the [UNK] items time . He was a the [UNK] . He put the the [UNK] . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 8\n",
      "[START] I was getting so and she dropped in the world . After a [UNK] went to [UNK] [UNK] . While I realized for my car and , she was a [UNK] trip . I got the [UNK] was to [UNK] the . . I stayed in the [UNK] time to school and we went to [UNK] . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 9\n",
      "[START] [UNK] was in a [UNK] . [UNK] [UNK] . He was and to to the [UNK] . [UNK] [UNK] [UNK] hit the [UNK] . When it was the that it was at a . [UNK] was the [UNK] the [UNK] in the [UNK] . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 10\n",
      "[START] Allie was the working to her a today . She was a [UNK] and was a her [UNK] . She was trying to her good . Her family was so excited . They were up on the . . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 11\n",
      "[START] There was a while [UNK] [UNK] to too [UNK] . She was the [UNK] of water and went to her to [UNK] . Her [UNK] . It was [UNK] , and [UNK] was a the moved back . After learned , and took her and she got her car . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 12\n",
      "[START] I was wanted to college . I decided to play to them . I needed a [UNK] . I went out . I was was it . Thankfully I did on the to [UNK] . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 13\n",
      "[START] Tom had a new problem . . He was being a something . But , he was [UNK] many . Tom went there his [UNK] was [UNK] . Tom tried trying to win it to . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 14\n",
      "[START] She had been to the the office to a office to a house . She was trying to the the same , but realized the was that ticket . At the night she noticed the way to the her room . [UNK] was into the [UNK] , the [UNK] to from in the house . She was , she was to the police was the [UNK] and left . [END] [PAD]\n",
      "sample_idx: 15\n",
      "[START] I was in a doctor wanted to do to visit . I was told that I was out to the [UNK] . As I tried many hours of in the [UNK] . I had to the where of my friend to the [UNK] . I was the [UNK] at , I went to in the [UNK] . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 16\n",
      "[START] [UNK] used to go to school . It was the show there turn to work in the park . It was to to drive at the [UNK] of the [UNK] . She had to the the way to [UNK] the [UNK] . [UNK] the [UNK] every the , and everyone came to it . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 17\n",
      "[START] Jane was a [UNK] . He loved the one day . She was the [UNK] on the [UNK] . He could n't put her and hit the [UNK] . He was to the [UNK] in it . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 18\n",
      "[START] Tom was a . . He decided to put on a drink . He got the . He went out to the doctor on the ground . He was very upset . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 19\n",
      "[START] Tony was a [UNK] to play . . He was in the [UNK] . He was in 10 home , and found this . When he got it to the store . . He had to the back from the summer again . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 20\n",
      "[START] Tom was afraid to a [UNK] . She was [UNK] to the [UNK] . He was getting up the [UNK] out of the [UNK] . He was given a great it . He excited to win the [UNK] . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 21\n",
      "[START] [UNK] was a [UNK] of his [UNK] . He wanted to have to do the [UNK] . [UNK] asked to [UNK] . A final had a big trip to friends in . He made the [UNK] and had to the [UNK] . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 22\n",
      "[START] The first was [UNK] . He was working with the [UNK] . He was in the . The [UNK] . He quickly . He had a lot . He could n't the his [UNK] . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 23\n",
      "[START] He decided to go in the the house [UNK] . She never would be it . He was about the [UNK] was a [UNK] . She kept the the to top of the [UNK] . The [UNK] was not until she made it . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 24\n",
      "[START] I was a very a job . for a I had a lot . When there was a the [UNK] . I was money to get on the [UNK] and fell . I was that I [UNK] in the car on the morning . It was an food son on it . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 25\n",
      "[START] It was driving to turn to at out . She was the hospital and always was [UNK] ! Her once was open for an over . She agreed to the kitchen because she was great ! She did n't want to be the water was . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 26\n",
      "[START] Kate decided to be a . [UNK] . She was a very the . As she got there she saw she could [UNK] . She got the test and had her last [UNK] . She was expensive to go for the . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 27\n",
      "[START] Bill was to the the basketball house . . It was five for the . . He was a , who and truck it for . . He decided to a [UNK] school . He has the [UNK] and [UNK] . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 28\n",
      "[START] Kevin was driving in the [UNK] 's job . When he was trying to get up to the [UNK] to [UNK] . He had a man the [UNK] . . He was able to get the but it was there , . He made the water every day . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 29\n",
      "[START] I was at the [UNK] the to [UNK] . I was to the [UNK] . [UNK] I go to the [UNK] . The [UNK] was all . I made the [UNK] and for the [UNK] [UNK] . I [UNK] the day . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 30\n",
      "[START] Tim was her boyfriend [UNK] . There was in a . So he was decided to the on being . However , he was n't and it . He spent . He used on the and and under it for [UNK] . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "sample_idx: 31\n",
      "[START] Gina was going to her a house . She got out of to a [UNK] on it . She started to the milk had an [UNK] . . She was a and went everywhere . Eventually she was proud of the same in the . [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "for sample_idx in range(32):\n",
    "    hidden_state = hidden_states[-1][sample_idx]\n",
    "    with torch.no_grad():\n",
    "        hidden_logits = diffusion_model.lm_head(hidden_state)\n",
    "        sampled_ids = torch.argmax(hidden_logits,dim=-1).cpu()\n",
    "        sampled_seq = [rev_tokenizer[token_id.item()] for token_id in sampled_ids]\n",
    "        print(\"sample_idx:\", sample_idx)\n",
    "        print(\" \".join(sampled_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.6378,  1.4051,  1.0136,  ...,  1.0120, -1.7385,  1.4652],\n",
       "        [ 0.2464, -1.4502, -0.7388,  ..., -0.4285, -0.6073,  0.1443],\n",
       "        [-0.3404, -0.8405, -0.5819,  ..., -0.4397,  0.2013,  0.0893],\n",
       "        ...,\n",
       "        [ 0.4108,  0.5314,  0.1880,  ...,  0.6811, -0.4978, -0.7795],\n",
       "        [-0.4666, -1.4213, -0.6767,  ...,  1.6241, -0.9184, -1.7732],\n",
       "        [ 0.5553,  1.0052, -0.8565,  ...,  0.1408, -0.5999, -0.2633]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusion_model.word_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.6378,  1.4051,  1.0136,  ...,  1.0120, -1.7385,  1.4652],\n",
       "        [ 0.2464, -1.4502, -0.7388,  ..., -0.4285, -0.6073,  0.1443],\n",
       "        [-0.3404, -0.8405, -0.5819,  ..., -0.4397,  0.2013,  0.0893],\n",
       "        ...,\n",
       "        [ 0.4108,  0.5314,  0.1880,  ...,  0.6811, -0.4978, -0.7795],\n",
       "        [-0.4666, -1.4213, -0.6767,  ...,  1.6241, -0.9184, -1.7732],\n",
       "        [ 0.5553,  1.0052, -0.8565,  ...,  0.1408, -0.5999, -0.2633]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusion_model.lm_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-3.5957,  1.8014,  2.5901,  2.1515,  3.3029,  0.6991,  1.8473,  2.0402,\n",
       "         1.1597, -0.2813,  1.3428,  2.5773,  1.7346,  0.3585,  1.8947,  3.6371,\n",
       "         2.6198, -0.5297, -0.9911,  0.8940,  1.5984,  0.4120, -1.0672,  1.6913,\n",
       "        -0.1471,  2.4192,  1.0555,  0.3134,  1.5614, -1.0390,  1.1615,  2.8382,\n",
       "         1.8414,  2.6628,  1.6968, -0.2872,  2.9343,  0.4418,  2.4511,  1.4755,\n",
       "         1.4237,  2.3028,  1.9902, -0.4341, -0.2238,  2.7552,  2.6776,  2.4934,\n",
       "         1.9630,  3.0694,  1.1612,  0.6251,  1.9105,  0.6518,  0.2576, -0.0762,\n",
       "         1.4853, -0.1598,  0.6786, -0.4123,  1.6452,  2.3508, -1.1346,  0.8314,\n",
       "         2.2578,  1.6991, -0.4668, -1.0294,  0.4291,  2.5995,  0.9700,  0.7628,\n",
       "         0.3471,  0.5633,  0.5759, -0.2908,  0.2453,  1.2167,  0.6752,  2.8704,\n",
       "        -0.8602,  0.0759,  0.2046,  1.3811,  0.1386,  0.0215, -0.2222, -0.4503,\n",
       "        -0.9871, -0.3807, -0.3564,  1.1891,  0.5863,  0.0522,  1.8518,  2.0459,\n",
       "         0.8235,  2.4076, -0.8332, -0.9621,  0.9600, -0.7917,  0.5402,  1.2104,\n",
       "         2.2828, -0.4858,  1.8422,  2.1792, -1.5556,  0.1469, -0.3869,  1.1497,\n",
       "         0.2042,  1.3563,  0.8349,  0.6283,  1.1469, -1.3358,  0.7665,  1.0520,\n",
       "         0.6281,  0.4821,  0.6344,  0.8772, -0.2046,  0.3738,  0.6110,  0.8557,\n",
       "         0.1984,  0.7476,  1.4865, -0.5668,  1.5859, -1.2164,  0.2064,  1.9871,\n",
       "        -0.8133, -0.4055,  0.8062,  0.5084,  0.4102, -0.4011, -0.4358, -0.6694,\n",
       "         0.3218,  1.0348,  0.3747,  0.0819,  0.0499, -0.1808,  0.4121,  0.7655,\n",
       "         0.4159, -0.8546,  0.7511, -1.7949, -0.7730,  0.4374, -0.4944, -0.2723,\n",
       "        -0.1339, -0.4250,  0.5474,  1.2452,  0.0839, -0.2967, -0.1721, -0.6929,\n",
       "         0.6768,  0.0618,  1.2540,  0.5987, -0.4700, -1.0851, -0.7231, -0.1056,\n",
       "         0.5198,  1.0812,  2.3026, -0.5492,  0.0853,  0.9705,  1.0821, -0.9545,\n",
       "        -0.0601,  0.4019, -0.3899,  0.2119,  0.4332,  0.4947,  0.4321, -0.3513,\n",
       "         0.1758, -0.4849,  0.4131, -1.0815, -0.1095,  1.2840, -1.0147, -0.3383,\n",
       "        -1.0167, -2.3148,  0.1477, -0.5718, -0.1906, -0.2763,  0.7280, -0.9435,\n",
       "        -1.2110, -0.3452, -0.2326, -1.0071, -0.7879, -0.7801, -0.4681,  1.3552,\n",
       "         0.5186, -0.6829, -0.0101, -0.5937, -0.0218, -0.0780, -0.7906, -0.5260,\n",
       "        -1.1092, -1.5542, -0.6439, -0.0120, -0.9626, -0.9079, -0.7108, -0.3120,\n",
       "         0.2531,  0.2240,  0.7877,  0.0272, -0.6105, -0.9266,  0.8994, -1.8259,\n",
       "        -1.0324,  0.3815,  0.1083, -1.1273,  1.4777, -0.3971, -0.5105,  0.6609,\n",
       "        -0.2290, -1.0707,  0.1939, -0.8474, -0.4774, -0.6880, -0.3638, -0.6318,\n",
       "        -1.9635, -0.2744, -0.4930, -1.1825, -0.7536, -1.0358, -0.3148, -0.0167,\n",
       "         0.5465, -1.4440,  0.4187, -1.1920, -0.0356, -0.9404, -1.1085,  0.0295,\n",
       "        -1.2363, -1.2359, -1.4029,  0.1473,  0.1699, -0.5688,  0.0268, -0.4291,\n",
       "        -0.2535, -1.6662, -0.3069, -0.0414, -0.9639, -0.8089, -0.0818, -0.2149,\n",
       "        -0.3959, -0.9759,  0.6893, -0.6635, -0.6515, -0.5006, -0.1716, -0.1877,\n",
       "        -0.7926, -0.1474,  0.9174,  0.2355, -1.3303, -0.1719, -0.7459, -1.3871,\n",
       "        -0.8042, -1.2192, -0.8345, -1.0769,  0.5039, -0.1602, -0.7609, -0.8160,\n",
       "        -0.8788, -1.5514, -0.5922, -0.4251, -1.5091, -1.0188, -0.7026, -0.9491,\n",
       "        -0.9038, -1.1971, -1.2207, -0.2184,  0.2213, -1.1122, -0.4732, -1.8535,\n",
       "        -1.2398, -0.6410, -1.3743, -1.0332, -1.3473, -1.5786,  1.0285, -0.7975,\n",
       "        -0.6508, -0.9478,  1.0196, -0.6751, -0.7467, -0.9450, -1.1873, -0.7043,\n",
       "        -2.1057, -2.0016, -1.2020, -0.3169, -1.2627, -1.2684, -2.1327, -1.1530,\n",
       "        -0.3636, -1.6748, -1.7725, -0.9689, -0.8107, -0.7383, -1.4735, -0.2098,\n",
       "        -0.4245, -1.0847, -1.0794, -1.2260, -0.4872, -0.8374, -0.7822, -1.0458,\n",
       "        -1.5363, -0.8555, -0.6375, -1.0542, -1.2897, -1.7554, -0.9887, -0.2079,\n",
       "        -0.9860, -0.0880, -0.7584, -0.3994, -1.6928,  0.1805, -0.5650, -0.4921,\n",
       "        -2.0623, -1.2453, -0.9380, -1.1122, -0.7972, -0.0838, -0.7590, -1.1142,\n",
       "        -2.0633, -0.9664, -0.7274, -1.3924, -1.9283, -0.9546, -1.7357, -1.0379,\n",
       "        -1.8437, -1.9381, -1.8040, -0.7304, -0.4999, -0.3376, -0.9137, -0.8559,\n",
       "        -1.0057, -0.7876, -0.5002, -1.0440, -0.6245, -0.6757, -0.5634, -0.5656,\n",
       "        -0.7641, -1.9345,  0.2709, -1.3513, -0.3668, -0.8695, -1.8784, -1.0670,\n",
       "        -0.5503, -2.1045, -0.1323, -1.0636, -1.3157, -0.9680, -0.7749, -1.0757,\n",
       "        -0.4228, -0.5308, -1.0551, -0.9181, -1.9128, -1.9721, -0.3135, -1.6979,\n",
       "        -1.4544, -1.0118, -1.5491, -1.5582, -0.6326, -1.1833, -1.3121, -0.9850,\n",
       "        -1.6603, -1.1438, -0.7343, -1.3253, -0.9947, -0.1916, -2.1029, -1.1888,\n",
       "        -0.6684,  0.0188, -1.2667, -1.1103, -0.9736, -0.5522, -1.0327, -0.8760,\n",
       "        -1.9136, -0.7129, -1.2179, -1.3795, -1.0313, -0.6095, -0.9014, -0.9992,\n",
       "        -0.5496, -0.7144,  0.3375, -2.1455, -1.5595, -1.1584, -1.1418, -0.5443,\n",
       "        -1.0615, -1.0395, -1.6607, -1.0888, -1.1096, -1.5186, -1.5105, -0.9796,\n",
       "        -1.0866, -0.6991, -1.1975, -0.6713, -1.5455, -1.8620, -1.4339, -1.8311,\n",
       "        -1.6414, -1.1309, -1.2779, -1.3355, -2.1765, -1.9641, -1.3753, -1.6652,\n",
       "        -0.3503, -1.2059, -0.8104, -1.1327, -0.3484, -1.3182, -1.1997, -0.4866,\n",
       "        -0.6414, -1.4353, -1.4636, -0.9362, -1.1654, -1.0842, -1.7280, -1.2611,\n",
       "        -1.3333, -0.5875, -1.2260, -1.8197, -0.4704, -1.6486, -1.5969, -0.8792,\n",
       "        -1.7254, -0.8583, -2.0291, -1.8149, -1.1076, -0.9685, -1.4299, -1.8188,\n",
       "        -1.9609, -1.1925, -0.6491, -2.0842, -1.3230, -1.7114, -1.1857, -1.7527,\n",
       "        -1.1907, -1.0633, -0.9194, -1.2174, -1.1148, -0.4659, -1.0398, -1.2131,\n",
       "        -1.2328, -1.9319, -2.1315, -1.0507, -1.7362, -1.2140, -1.5691, -1.1696,\n",
       "        -0.9949, -1.4445, -1.4563, -1.7951, -1.7603, -1.5907, -1.0316, -1.4746,\n",
       "        -0.7682, -1.1077, -0.9845, -2.2692, -0.9256, -1.3797, -1.5748, -1.6112,\n",
       "        -1.6426, -2.0438, -1.2895, -1.8295, -1.5070, -1.4439, -1.6318, -1.8226,\n",
       "        -1.1379, -0.9879, -1.1507, -0.5650, -1.2005, -1.4509, -1.3396, -1.1533,\n",
       "        -1.2685, -1.0357, -1.1536, -1.6024, -1.7417, -1.0730, -1.2970, -0.3348,\n",
       "        -1.8014, -1.3867, -1.1652, -1.2368, -1.4154, -1.8254, -1.4992, -1.8557,\n",
       "        -2.0686, -1.3427, -1.9231, -1.0441, -0.8598, -1.3455, -1.0252, -1.0201,\n",
       "        -1.0792, -1.6543, -0.5840, -1.8567, -1.9574, -1.0683, -2.0167, -1.3616,\n",
       "        -1.4012, -1.3824, -1.5663, -0.7825,  0.3356, -1.4769, -1.1346, -1.9519,\n",
       "        -1.2560, -1.0982, -1.1810, -0.8207, -1.8119, -1.5928, -0.1578, -2.3865,\n",
       "        -1.3358, -1.3217, -1.6286, -1.2917, -1.7481, -1.5893, -0.6129, -1.1163,\n",
       "        -1.3581, -0.9052, -1.2152, -1.2737, -1.1588, -2.0223, -1.2249, -1.5966,\n",
       "        -1.4035, -1.6412, -1.3529, -1.8090, -1.7506, -1.1072, -1.0180, -1.1093,\n",
       "        -1.8331, -1.6685, -2.0042, -1.7712, -1.4335, -0.8262, -1.2012, -1.5632,\n",
       "        -1.9996, -1.5457, -1.8191, -1.7140, -1.3999, -0.9674, -1.6269, -1.0992,\n",
       "        -1.8073, -0.8966, -1.3010, -0.7220, -1.6205, -1.5086, -1.7303, -1.5361,\n",
       "        -0.9591, -1.5258, -1.8808, -0.9325, -1.8310, -1.2538, -1.4131, -1.5822,\n",
       "        -1.6153, -0.7049, -1.0625, -1.5726, -1.2494, -1.8755, -1.4513, -1.5374,\n",
       "        -1.9129, -2.1708, -0.9845, -1.0728, -1.7683, -1.1990, -1.8136, -1.9166,\n",
       "        -1.8364, -1.5969, -1.9080, -1.0949, -1.2674, -1.2119, -1.4445, -0.8754,\n",
       "        -1.2613, -1.0979, -1.0635, -1.2807, -1.0831, -1.2705, -1.9065, -0.9193,\n",
       "        -1.5241, -1.9417, -1.3819, -1.5308, -1.1012, -0.5805, -0.9108, -1.2996,\n",
       "        -1.0192, -1.0920, -1.2924, -1.6853, -2.0605, -1.1663, -1.9818, -0.8989,\n",
       "        -1.4304, -1.3372, -1.7302, -1.6452, -1.7887, -1.2833, -1.0974, -1.4438,\n",
       "        -1.3918, -1.4594, -2.0749, -1.5225, -1.4667, -1.6774, -1.6696, -1.3855,\n",
       "        -1.7570, -1.7648, -1.8075, -1.1751, -1.1820, -1.8180, -2.1365, -1.6080,\n",
       "        -2.1964, -1.5769, -1.4310, -1.1767, -1.7967, -1.9266, -1.6068, -1.0046,\n",
       "        -1.3647, -1.0232, -1.5806, -2.1255, -1.4867, -0.9068, -0.9529, -1.2978,\n",
       "        -1.0038, -1.4063, -0.9206, -1.9340, -1.1697, -1.7136, -1.0794, -1.6747,\n",
       "        -1.0318, -1.9737, -1.1626, -1.4205, -1.3231, -1.7798, -1.8872, -0.9585,\n",
       "        -1.5863, -1.7027, -1.3464, -1.4046, -1.2698, -1.8768, -1.5347, -1.0776,\n",
       "        -1.5676, -1.8256, -1.7698, -0.9920, -1.1979, -1.6873, -1.3765, -1.5188,\n",
       "        -1.9270, -1.0055, -1.7512, -1.6892, -1.1356, -1.0418, -1.3273, -2.3043,\n",
       "        -1.3602, -2.1477, -1.0020, -1.4794, -2.0923, -1.6537, -1.1995, -1.4836,\n",
       "        -1.5321, -1.0705, -1.2693, -1.5738, -1.2494, -1.1238, -0.9064, -1.2992,\n",
       "        -1.8903, -2.0011, -1.1333, -1.4928, -1.2647, -1.9926, -1.1890, -1.4590,\n",
       "        -1.6307, -1.7214, -1.3750, -1.0838], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusion_model.lm_head.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
